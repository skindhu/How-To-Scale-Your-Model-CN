#!/usr/bin/env python3
"""
ä¸»ç¨‹åºå…¥å£
æ•´åˆæ‰€æœ‰ç¿»è¯‘æµç¨‹æ¨¡å—ï¼šçˆ¬è™« â†’ ç¿»è¯‘ â†’ é“¾æ¥æœ¬åœ°åŒ– â†’ é¡µå¤´ä¿¡æ¯æ·»åŠ 

åˆ›å»ºæ—¶é—´ï¼š2024-12-19
é¡¹ç›®ï¼šç³»åˆ—æŠ€æœ¯æ–‡ç« ç¿»è¯‘
"""

import asyncio
import logging
import sys
import time
from pathlib import Path
from typing import Dict, List, Optional

# æ·»åŠ srcç›®å½•åˆ°Pythonè·¯å¾„
sys.path.insert(0, 'src')

# å¯¼å…¥å„ä¸ªæ¨¡å—
from crawler import WebCrawler, crawl_from_file
from translator import HTMLTranslator, translate_html_file
from link_localizer import LinkLocalizer
from header_info_adder import HeaderInfoAdder
from config.logging_config import setup_logging
from config.settings import Config


class TranslationPipeline:
    """ç¿»è¯‘æµæ°´çº¿ï¼Œæ•´åˆæ‰€æœ‰å¤„ç†æ­¥éª¤"""

    def __init__(self, config: Config = None):
        """
        åˆå§‹åŒ–ç¿»è¯‘æµæ°´çº¿

        Args:
            config (Config): é…ç½®å¯¹è±¡ï¼Œå¦‚æœæœªæä¾›åˆ™ä½¿ç”¨é»˜è®¤é…ç½®
        """
        self.config = config or Config()
        self.logger = logging.getLogger(__name__)

        # åˆå§‹åŒ–å„ä¸ªç»„ä»¶
        self.crawler = None
        self.translator = None
        self.link_localizer = None
        self.header_adder = None

        # æµç¨‹ç»Ÿè®¡ä¿¡æ¯
        self.stats = {
            'crawl_success': 0,
            'crawl_failed': 0,
            'translate_success': 0,
            'translate_failed': 0,
            'translate_skipped': 0,
            'localize_links': 0,
            'add_headers': 0,
            'total_time': 0
        }

        self.logger.info("ç¿»è¯‘æµæ°´çº¿åˆå§‹åŒ–å®Œæˆ")

    async def initialize_components(self):
        """åˆå§‹åŒ–æ‰€æœ‰ç»„ä»¶"""
        try:
            self.logger.info("æ­£åœ¨åˆå§‹åŒ–å„ä¸ªç»„ä»¶...")

            # åˆå§‹åŒ–çˆ¬è™«
            self.crawler = WebCrawler()
            self.logger.info("âœ… çˆ¬è™«ç»„ä»¶åˆå§‹åŒ–å®Œæˆ")

            # åˆå§‹åŒ–ç¿»è¯‘å™¨
            self.translator = HTMLTranslator()
            self.logger.info("âœ… ç¿»è¯‘å™¨ç»„ä»¶åˆå§‹åŒ–å®Œæˆ")

            # åˆå§‹åŒ–é“¾æ¥æœ¬åœ°åŒ–å™¨
            self.link_localizer = LinkLocalizer()
            self.logger.info("âœ… é“¾æ¥æœ¬åœ°åŒ–å™¨åˆå§‹åŒ–å®Œæˆ")

            # åˆå§‹åŒ–é¡µå¤´ä¿¡æ¯æ·»åŠ å™¨
            self.header_adder = HeaderInfoAdder()
            self.logger.info("âœ… é¡µå¤´ä¿¡æ¯æ·»åŠ å™¨åˆå§‹åŒ–å®Œæˆ")

            self.logger.info("ğŸ‰ æ‰€æœ‰ç»„ä»¶åˆå§‹åŒ–å®Œæˆ")

        except Exception as e:
            self.logger.error(f"ç»„ä»¶åˆå§‹åŒ–å¤±è´¥: {str(e)}")
            raise

    async def step1_crawl_pages(self, urls_file: str = "src/config/urls.txt") -> bool:
        """
        æ­¥éª¤1ï¼šçˆ¬å–ç½‘é¡µå†…å®¹

        Args:
            urls_file (str): URLé…ç½®æ–‡ä»¶è·¯å¾„

        Returns:
            bool: æ˜¯å¦æˆåŠŸ
        """
        self.logger.info("=" * 60)
        self.logger.info("ğŸ“¡ æ­¥éª¤1ï¼šå¼€å§‹çˆ¬å–ç½‘é¡µå†…å®¹")
        self.logger.info("=" * 60)

        try:
            # æ£€æŸ¥URLæ–‡ä»¶æ˜¯å¦å­˜åœ¨
            if not Path(urls_file).exists():
                self.logger.error(f"URLé…ç½®æ–‡ä»¶ä¸å­˜åœ¨: {urls_file}")
                return False

            # ä»æ–‡ä»¶è¯»å–URLå¹¶æ‰¹é‡çˆ¬å–
            results = await crawl_from_file(urls_file)

            if not results:
                self.logger.error("æœªèƒ½çˆ¬å–åˆ°ä»»ä½•å†…å®¹")
                return False

            # ç»Ÿè®¡ç»“æœ
            success_count = sum(1 for r in results if r.get('success', False))
            failed_count = len(results) - success_count

            self.stats['crawl_success'] = success_count
            self.stats['crawl_failed'] = failed_count

            self.logger.info(f"âœ… çˆ¬å–å®Œæˆ: æˆåŠŸ {success_count} ä¸ªï¼Œå¤±è´¥ {failed_count} ä¸ª")

            return success_count > 0

        except Exception as e:
            self.logger.error(f"çˆ¬å–é˜¶æ®µå¤±è´¥: {str(e)}")
            return False

    async def step2_translate_pages(self, force_translate: bool = False) -> bool:
        """
        æ­¥éª¤2ï¼šç¿»è¯‘çˆ¬å–çš„HTMLé¡µé¢

        Args:
            force_translate (bool): æ˜¯å¦å¼ºåˆ¶ç¿»è¯‘ï¼Œå³ä½¿ç¿»è¯‘æ–‡ä»¶å·²å­˜åœ¨

        Returns:
            bool: æ˜¯å¦æˆåŠŸ
        """
        self.logger.info("=" * 60)
        self.logger.info("ğŸŒ æ­¥éª¤2ï¼šå¼€å§‹ç¿»è¯‘HTMLé¡µé¢")
        self.logger.info("=" * 60)

        try:
            # è·å–æ‰€æœ‰åŸå§‹HTMLæ–‡ä»¶
            origin_dir = Path(self.config.ORIGIN_DIR)
            html_files = list(origin_dir.glob("*.html"))

            if not html_files:
                self.logger.error(f"æœªæ‰¾åˆ°åŸå§‹HTMLæ–‡ä»¶åœ¨ç›®å½•: {origin_dir}")
                return False

            self.logger.info(f"æ‰¾åˆ° {len(html_files)} ä¸ªHTMLæ–‡ä»¶éœ€è¦ç¿»è¯‘")

            success_count = 0
            failed_count = 0
            skipped_count = 0

            # é€ä¸ªç¿»è¯‘æ–‡ä»¶
            for html_file in html_files:
                try:
                    self.logger.info(f"å¤„ç†æ–‡ä»¶: {html_file.name}")

                    # ä½¿ç”¨translate_html_fileå‡½æ•°ï¼Œå®ƒä¼šè‡ªåŠ¨æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å·²å­˜åœ¨
                    result = await translate_html_file(str(html_file), force_translate)

                    if result:
                        # æ£€æŸ¥æ˜¯å¦æ˜¯è·³è¿‡çš„æ–‡ä»¶
                        trans_dir = Path(self.config.TRANS_DIR)
                        target_file = trans_dir / html_file.name
                        if target_file.exists() and not force_translate:
                            if "è·³è¿‡å·²ç¿»è¯‘æ–‡ä»¶" in str(result) or result == str(target_file):
                                skipped_count += 1
                                self.logger.info(f"â­ï¸  {html_file.name} å·²å­˜åœ¨ï¼Œè·³è¿‡ç¿»è¯‘")
                            else:
                                success_count += 1
                                self.logger.info(f"âœ… {html_file.name} ç¿»è¯‘å®Œæˆ")
                        else:
                            success_count += 1
                            self.logger.info(f"âœ… {html_file.name} ç¿»è¯‘å®Œæˆ")
                    else:
                        failed_count += 1
                        self.logger.error(f"âŒ {html_file.name} ç¿»è¯‘å¤±è´¥")

                except Exception as e:
                    failed_count += 1
                    self.logger.error(f"âŒ {html_file.name} ç¿»è¯‘å‡ºé”™: {str(e)}")

            self.stats['translate_success'] = success_count
            self.stats['translate_failed'] = failed_count
            self.stats['translate_skipped'] = skipped_count

            self.logger.info(f"âœ… ç¿»è¯‘é˜¶æ®µå®Œæˆ:")
            self.logger.info(f"   ğŸ“ æ€»æ–‡ä»¶æ•°: {len(html_files)}")
            self.logger.info(f"   âœ… ç¿»è¯‘æˆåŠŸ: {success_count}")
            self.logger.info(f"   â­ï¸  è·³è¿‡æ–‡ä»¶: {skipped_count}")
            self.logger.info(f"   âŒ ç¿»è¯‘å¤±è´¥: {failed_count}")

            # åªè¦æœ‰æ–‡ä»¶è¢«å¤„ç†ï¼ˆç¿»è¯‘æˆ–è·³è¿‡ï¼‰å°±è®¤ä¸ºæˆåŠŸ
            return (success_count + skipped_count) > 0

        except Exception as e:
            self.logger.error(f"ç¿»è¯‘é˜¶æ®µå¤±è´¥: {str(e)}")
            return False

    async def step3_localize_links(self) -> bool:
        """
        æ­¥éª¤3ï¼šæœ¬åœ°åŒ–é“¾æ¥

        Returns:
            bool: æ˜¯å¦æˆåŠŸ
        """
        self.logger.info("=" * 60)
        self.logger.info("ğŸ”— æ­¥éª¤3ï¼šå¼€å§‹æœ¬åœ°åŒ–é“¾æ¥")
        self.logger.info("=" * 60)

        try:
            # æ„å»ºURLæ˜ å°„
            self.link_localizer.build_url_mapping()

            # å¤„ç†æ‰€æœ‰æ–‡ä»¶
            stats = self.link_localizer.process_all_files()

            self.stats['localize_links'] = stats.get('links_converted', 0)

            self.logger.info(f"âœ… é“¾æ¥æœ¬åœ°åŒ–å®Œæˆ:")
            self.logger.info(f"   ğŸ“ å¤„ç†æ–‡ä»¶: {stats.get('files_processed', 0)} ä¸ª")
            self.logger.info(f"   ğŸ”— è½¬æ¢é“¾æ¥: {stats.get('links_converted', 0)} ä¸ª")

            return True

        except Exception as e:
            self.logger.error(f"é“¾æ¥æœ¬åœ°åŒ–é˜¶æ®µå¤±è´¥: {str(e)}")
            return False

    async def step4_add_headers(self) -> bool:
        """
        æ­¥éª¤4ï¼šæ·»åŠ é¡µå¤´ä¿¡æ¯

        Returns:
            bool: æ˜¯å¦æˆåŠŸ
        """
        self.logger.info("=" * 60)
        self.logger.info("ğŸ“ æ­¥éª¤4ï¼šå¼€å§‹æ·»åŠ é¡µå¤´ä¿¡æ¯")
        self.logger.info("=" * 60)

        try:
            # å¤„ç†æ‰€æœ‰æ–‡ä»¶
            stats = self.header_adder.process_all_files()

            self.stats['add_headers'] = stats.get('headers_added', 0)

            self.logger.info(f"âœ… é¡µå¤´ä¿¡æ¯æ·»åŠ å®Œæˆ:")
            self.logger.info(f"   ğŸ“ å¤„ç†æ–‡ä»¶: {stats.get('files_processed', 0)} ä¸ª")
            self.logger.info(f"   ğŸ·ï¸  æ·»åŠ é¡µå¤´: {stats.get('headers_added', 0)} ä¸ª")

            return True

        except Exception as e:
            self.logger.error(f"é¡µå¤´ä¿¡æ¯æ·»åŠ é˜¶æ®µå¤±è´¥: {str(e)}")
            return False

    async def run_full_pipeline(self, urls_file: str = "src/config/urls.txt") -> Dict:
        """
        è¿è¡Œå®Œæ•´çš„ç¿»è¯‘æµæ°´çº¿

        Args:
            urls_file (str): URLé…ç½®æ–‡ä»¶è·¯å¾„

        Returns:
            Dict: æµç¨‹ç»Ÿè®¡ä¿¡æ¯
        """
        start_time = time.time()

        self.logger.info("ğŸš€ å¼€å§‹è¿è¡Œå®Œæ•´ç¿»è¯‘æµæ°´çº¿")
        self.logger.info("æµç¨‹ï¼šçˆ¬è™« â†’ ç¿»è¯‘ â†’ é“¾æ¥æœ¬åœ°åŒ– â†’ é¡µå¤´ä¿¡æ¯æ·»åŠ ")

        try:
            # åˆå§‹åŒ–æ‰€æœ‰ç»„ä»¶
            await self.initialize_components()

            # æ­¥éª¤1ï¼šçˆ¬å–ç½‘é¡µ
            if not await self.step1_crawl_pages(urls_file):
                self.logger.error("âŒ çˆ¬å–é˜¶æ®µå¤±è´¥ï¼Œç»ˆæ­¢æµç¨‹")
                return self.stats

            # æ­¥éª¤2ï¼šç¿»è¯‘é¡µé¢
            if not await self.step2_translate_pages():
                self.logger.error("âŒ ç¿»è¯‘é˜¶æ®µå¤±è´¥ï¼Œç»ˆæ­¢æµç¨‹")
                return self.stats

            # æ­¥éª¤3ï¼šæœ¬åœ°åŒ–é“¾æ¥
            if not await self.step3_localize_links():
                self.logger.error("âŒ é“¾æ¥æœ¬åœ°åŒ–å¤±è´¥ï¼Œç»ˆæ­¢æµç¨‹")
                return self.stats

            # æ­¥éª¤4ï¼šæ·»åŠ é¡µå¤´ä¿¡æ¯
            if not await self.step4_add_headers():
                self.logger.error("âŒ é¡µå¤´ä¿¡æ¯æ·»åŠ å¤±è´¥ï¼Œç»ˆæ­¢æµç¨‹")
                return self.stats

            # è®¡ç®—æ€»è€—æ—¶
            self.stats['total_time'] = time.time() - start_time

            # æ˜¾ç¤ºæœ€ç»ˆç»Ÿè®¡
            self.show_final_stats()

            return self.stats

        except Exception as e:
            self.logger.error(f"æµæ°´çº¿æ‰§è¡Œå¤±è´¥: {str(e)}")
            return self.stats

    def show_final_stats(self):
        """æ˜¾ç¤ºæœ€ç»ˆç»Ÿè®¡ä¿¡æ¯"""
        self.logger.info("=" * 80)
        self.logger.info("ğŸ‰ ç¿»è¯‘æµæ°´çº¿æ‰§è¡Œå®Œæˆï¼")
        self.logger.info("=" * 80)

        self.logger.info("ğŸ“Š æ‰§è¡Œç»Ÿè®¡:")
        self.logger.info(f"   ğŸ“¡ çˆ¬å–æˆåŠŸ: {self.stats['crawl_success']} ä¸ªé¡µé¢")
        self.logger.info(f"   ğŸ“¡ çˆ¬å–å¤±è´¥: {self.stats['crawl_failed']} ä¸ªé¡µé¢")
        self.logger.info(f"   ğŸŒ ç¿»è¯‘æˆåŠŸ: {self.stats['translate_success']} ä¸ªé¡µé¢")
        self.logger.info(f"   â­ï¸  ç¿»è¯‘è·³è¿‡: {self.stats['translate_skipped']} ä¸ªé¡µé¢")
        self.logger.info(f"   ğŸŒ ç¿»è¯‘å¤±è´¥: {self.stats['translate_failed']} ä¸ªé¡µé¢")
        self.logger.info(f"   ğŸ”— æœ¬åœ°åŒ–é“¾æ¥: {self.stats['localize_links']} ä¸ª")
        self.logger.info(f"   ğŸ“ æ·»åŠ é¡µå¤´: {self.stats['add_headers']} ä¸ª")
        self.logger.info(f"   â±ï¸  æ€»è€—æ—¶: {self.stats['total_time']:.2f} ç§’")

        # è®¡ç®—æˆåŠŸç‡
        total_pages = self.stats['crawl_success'] + self.stats['crawl_failed']
        if total_pages > 0:
            success_rate = (self.stats['translate_success'] / total_pages) * 100
            self.logger.info(f"   ğŸ“ˆ æˆåŠŸç‡: {success_rate:.1f}%")

        self.logger.info("=" * 80)

        # æ£€æŸ¥è¾“å‡ºç›®å½•
        trans_dir = Path(self.config.TRANS_DIR)
        if trans_dir.exists():
            html_files = list(trans_dir.glob("*.html"))
            self.logger.info(f"âœ¨ ç¿»è¯‘å®Œæˆçš„æ–‡ä»¶ä½äº: {trans_dir}")
            self.logger.info(f"ğŸ“ å…±ç”Ÿæˆ {len(html_files)} ä¸ªç¿»è¯‘æ–‡ä»¶")


# ä¾¿æ·å‡½æ•°
async def run_full_translation(urls_file: str = "src/config/urls.txt") -> Dict:
    """
    ä¾¿æ·å‡½æ•°ï¼šè¿è¡Œå®Œæ•´ç¿»è¯‘æµç¨‹

    Args:
        urls_file (str): URLé…ç½®æ–‡ä»¶è·¯å¾„

    Returns:
        Dict: æ‰§è¡Œç»Ÿè®¡ä¿¡æ¯
    """
    pipeline = TranslationPipeline()
    return await pipeline.run_full_pipeline(urls_file)


async def run_single_step(step: str, **kwargs) -> bool:
    """
    ä¾¿æ·å‡½æ•°ï¼šè¿è¡Œå•ä¸ªæ­¥éª¤

    Args:
        step (str): æ­¥éª¤åç§° ('crawl', 'translate', 'localize', 'headers')
        **kwargs: æ­¥éª¤å‚æ•°

    Returns:
        bool: æ˜¯å¦æˆåŠŸ
    """
    pipeline = TranslationPipeline()
    await pipeline.initialize_components()

    if step == 'crawl':
        return await pipeline.step1_crawl_pages(kwargs.get('urls_file', 'src/config/urls.txt'))
    elif step == 'translate':
        return await pipeline.step2_translate_pages()
    elif step == 'localize':
        return await pipeline.step3_localize_links()
    elif step == 'headers':
        return await pipeline.step4_add_headers()
    else:
        raise ValueError(f"æœªçŸ¥æ­¥éª¤: {step}")


async def main():
    """ä¸»å‡½æ•°"""
    # è®¾ç½®æ—¥å¿—
    setup_logging('INFO')

    print("=" * 80)
    print("ğŸŒ JAX Scaling Book ç¿»è¯‘æµæ°´çº¿")
    print("=" * 80)
    print("æµç¨‹ï¼šçˆ¬è™« â†’ ç¿»è¯‘ â†’ é“¾æ¥æœ¬åœ°åŒ– â†’ é¡µå¤´ä¿¡æ¯æ·»åŠ ")
    print()

    # æ£€æŸ¥å¿…è¦æ–‡ä»¶
    urls_file = "src/config/urls.txt"
    if not Path(urls_file).exists():
        print(f"âŒ é”™è¯¯: URLé…ç½®æ–‡ä»¶ä¸å­˜åœ¨: {urls_file}")
        print("è¯·ç¡®ä¿è¯¥æ–‡ä»¶å­˜åœ¨å¹¶åŒ…å«è¦çˆ¬å–çš„URLåˆ—è¡¨")
        return

    try:
        # è¿è¡Œå®Œæ•´æµæ°´çº¿
        stats = await run_full_translation(urls_file)

        if stats['translate_success'] > 0:
            print("\nğŸ‰ ç¿»è¯‘æµæ°´çº¿æ‰§è¡ŒæˆåŠŸï¼")
            print("æ‚¨å¯ä»¥åœ¨ output/trans/ ç›®å½•ä¸­æŸ¥çœ‹ç¿»è¯‘ç»“æœ")
        else:
            print("\nâš ï¸  ç¿»è¯‘æµæ°´çº¿æ‰§è¡Œå®Œæˆï¼Œä½†æ²¡æœ‰æˆåŠŸç¿»è¯‘ä»»ä½•é¡µé¢")
            print("è¯·æ£€æŸ¥æ—¥å¿—ä»¥äº†è§£è¯¦ç»†ä¿¡æ¯")

    except KeyboardInterrupt:
        print("\n\nâ¹ï¸  ç”¨æˆ·ä¸­æ–­æ‰§è¡Œ")
    except Exception as e:
        print(f"\nâŒ æ‰§è¡Œå¤±è´¥: {str(e)}")
        import traceback
        traceback.print_exc()


if __name__ == "__main__":
    asyncio.run(main())
