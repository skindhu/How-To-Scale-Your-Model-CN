<!DOCTYPE html>

<html class="" data-theme="light" data-theme-setting="system" lang="zh-CN">
<head><link href="https://giscus.app/default.css" id="giscus-css" rel="stylesheet"/><style>#back-to-top{background:#000;-webkit-border-radius:50%;-moz-border-radius:50%;border-radius:50%;bottom:20px;-webkit-box-shadow:0 2px 5px 0 rgba(0,0,0,.26);-moz-box-shadow:0 2px 5px 0 rgba(0,0,0,.26);box-shadow:0 2px 5px 0 rgba(0,0,0,.26);color:#fff;cursor:pointer;display:block;height:56px;opacity:1;outline:0;position:fixed;right:20px;-webkit-tap-highlight-color:transparent;-webkit-touch-callout:none;-webkit-transition:bottom .2s,opacity .2s;-o-transition:bottom .2s,opacity .2s;-moz-transition:bottom .2s,opacity .2s;transition:bottom .2s,opacity .2s;-webkit-user-select:none;-moz-user-select:none;-ms-user-select:none;user-select:none;width:56px;z-index:1}#back-to-top svg{display:block;fill:currentColor;height:20px;margin:11px auto 0;width:20px}#back-to-top.hidden{bottom:-56px;opacity:0}</style> <meta content="text/html; charset=utf-8" http-equiv="Content-Type"/> <meta charset="utf-8"/> <meta content="width=device-width, initial-scale=1, shrink-to-fit=no" name="viewport"/> <meta content="IE=edge" http-equiv="X-UA-Compatible"/> <title>如何理解 GPU | 如何扩展您的模型</title> <meta content=" " name="author"/> <meta content="在谷歌，我们非常喜欢 TPU，但 GPU 同样很棒。本章将深入探讨 NVIDIA GPU 的世界——每个芯片的工作原理、它们如何互连，以及这对大型语言模型 (LLM) 意味着什么，特别是与 TPU 相比。本节内容基于&lt;a href='https://jax-ml.github.io/scaling-book/tpus/'&gt;第 2 章&lt;/a&gt;和&lt;a href='https://jax-ml.github.io/scaling-book/training'&gt;第 5 章&lt;/a&gt;，因此建议您先阅读这些章节。" name="description"/> <meta content="scaling, jax, llms, transformers, tpus, google, deepmind, parallelism, pallas" name="keywords"/> <link href="https://jax-ml.github.io/scaling-book/assets/css/bootstrap.min.css?a4b3f509e79c54a512b890d73235ef04" rel="stylesheet"/> <link crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" rel="stylesheet"/> <link defer="" href="https://jax-ml.github.io/scaling-book/assets/css/academicons.min.css?f0b7046b84e425c55f3463ac249818f5" rel="stylesheet"/> <link defer="" href="https://jax-ml.github.io/scaling-book/assets/css/scholar-icons.css?62b2ac103a88034e6882a5be5f3e2772" rel="stylesheet"/> <link defer="" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons&amp;display=swap" rel="stylesheet" type="text/css"/> <link defer="" href="https://jax-ml.github.io/scaling-book/assets/css/jekyll-pygments-themes-vs.css?4ee1a2facd1a8a76347f4bd43a740500" id="highlight_theme_light" media="" rel="stylesheet"/> <link href="https://jax-ml.github.io/scaling-book/assets/img/favicon.png?fddbd8c2ec231ba2060e67c85de32a55" rel="shortcut icon"/> <link href="https://jax-ml.github.io/scaling-book/assets/css/main.css?d41d8cd98f00b204e9800998ecf8427e" rel="stylesheet"/> <link href="gpus.html" rel="canonical"/> <style id="distill-prerendered-styles" type="text/css">/*
 * Copyright 2018 The Distill Template Authors
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 *      http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

html {
  font-size: 14px;
	line-height: 1.6em;
  /* font-family: "Libre Franklin", "Helvetica Neue", sans-serif; */
  font-family: -apple-system, BlinkMacSystemFont, "Segoe UI", Roboto, Oxygen, Ubuntu, Cantarell, "Fira Sans", "Droid Sans", "Helvetica Neue", Arial, sans-serif;
  /*, "Apple Color Emoji", "Segoe UI Emoji", "Segoe UI Symbol";*/
  text-size-adjust: 100%;
  -ms-text-size-adjust: 100%;
  -webkit-text-size-adjust: 100%;
}

@media(min-width: 768px) {
  html {
    font-size: 16px;
  }
}

body {
  margin: 0;
}

a {
  color: #004276;
}

figure {
  margin: 0;
}

table {
	border-collapse: collapse;
	border-spacing: 0;
}

table th {
	text-align: left;
}

table thead {
  border-bottom: 1px solid rgba(0, 0, 0, 0.05);
}

table thead th {
  padding-bottom: 0.5em;
}

table tbody :first-child td {
  padding-top: 0.5em;
}

pre {
  overflow: auto;
  max-width: 100%;
}

p {
  margin-top: 0;
  margin-bottom: 1em;
}

sup, sub {
  vertical-align: baseline;
  position: relative;
  top: -0.4em;
  line-height: 1em;
}

sub {
  top: 0.4em;
}

.kicker,
.marker {
  font-size: 15px;
  font-weight: 600;
  color: rgba(0, 0, 0, 0.5);
}


/* Headline */

@media(min-width: 1024px) {
  d-title h1 span {
    display: block;
  }
}

/* Figure */

figure {
  position: relative;
  margin-bottom: 2.5em;
  margin-top: 1.5em;
}

figcaption+figure {

}

figure img {
  width: 100%;
}

figure svg text,
figure svg tspan {
}

figcaption,
.figcaption {
  color: rgba(0, 0, 0, 0.6);
  font-size: 12px;
  line-height: 1.5em;
}

@media(min-width: 1024px) {
figcaption,
.figcaption {
    font-size: 13px;
  }
}

figure.external img {
  background: white;
  border: 1px solid rgba(0, 0, 0, 0.1);
  box-shadow: 0 1px 8px rgba(0, 0, 0, 0.1);
  padding: 18px;
  box-sizing: border-box;
}

figcaption a {
  color: rgba(0, 0, 0, 0.6);
}

figcaption b,
figcaption strong, {
  font-weight: 600;
  color: rgba(0, 0, 0, 1.0);
}
/*
 * Copyright 2018 The Distill Template Authors
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 *      http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

@supports not (display: grid) {
  .base-grid,
  distill-header,
  d-title,
  d-abstract,
  d-article,
  d-appendix,
  distill-appendix,
  d-byline,
  d-footnote-list,
  d-citation-list,
  distill-footer {
    display: block;
    padding: 8px;
  }
}

.base-grid,
distill-header,
d-title,
d-abstract,
d-article,
d-appendix,
distill-appendix,
d-byline,
d-footnote-list,
d-citation-list,
distill-footer {
  display: grid;
  justify-items: stretch;
  grid-template-columns: [screen-start] 8px [page-start kicker-start text-start gutter-start middle-start] 1fr 1fr 1fr 1fr 1fr 1fr 1fr 1fr [text-end page-end gutter-end kicker-end middle-end] 8px [screen-end];
  grid-column-gap: 8px;
}

.grid {
  display: grid;
  grid-column-gap: 8px;
}

@media(min-width: 768px) {
  .base-grid,
  distill-header,
  d-title,
  d-abstract,
  d-article,
  d-appendix,
  distill-appendix,
  d-byline,
  d-footnote-list,
  d-citation-list,
  distill-footer {
    grid-template-columns: [screen-start] 1fr [page-start kicker-start middle-start text-start] 45px 45px 45px 45px 45px 45px 45px 45px [ kicker-end text-end gutter-start] 45px [middle-end] 45px [page-end gutter-end] 1fr [screen-end];
    grid-column-gap: 16px;
  }

  .grid {
    grid-column-gap: 16px;
  }
}

@media(min-width: 1000px) {
  .base-grid,
  distill-header,
  d-title,
  d-abstract,
  d-article,
  d-appendix,
  distill-appendix,
  d-byline,
  d-footnote-list,
  d-citation-list,
  distill-footer {
    grid-template-columns: [screen-start] 1fr [page-start kicker-start] 50px [middle-start] 50px [text-start kicker-end] 50px 50px 50px 50px 50px 50px 50px 50px [text-end gutter-start] 50px [middle-end] 50px [page-end gutter-end] 1fr [screen-end];
    grid-column-gap: 16px;
  }

  .grid {
    grid-column-gap: 16px;
  }
}

@media(min-width: 1180px) {
  .base-grid,
  distill-header,
  d-title,
  d-abstract,
  d-article,
  d-appendix,
  distill-appendix,
  d-byline,
  d-footnote-list,
  d-citation-list,
  distill-footer {
    grid-template-columns: [screen-start] 1fr [page-start kicker-start] 60px [middle-start] 60px [text-start kicker-end] 60px 60px 60px 60px 60px 60px 60px 60px [text-end gutter-start] 60px [middle-end] 60px [page-end gutter-end] 1fr [screen-end];
    grid-column-gap: 32px;
  }

  .grid {
    grid-column-gap: 32px;
  }
}




.base-grid {
  grid-column: screen;
}

/* .l-body,
d-article > *  {
  grid-column: text;
}

.l-page,
d-title > *,
d-figure {
  grid-column: page;
} */

.l-gutter {
  grid-column: gutter;
}

.l-text,
.l-body {
  grid-column: text;
}

.l-page {
  grid-column: page;
}

.l-body-outset {
  grid-column: middle;
}

.l-page-outset {
  grid-column: page;
}

.l-screen {
  grid-column: screen;
}

.l-screen-inset {
  grid-column: screen;
  padding-left: 16px;
  padding-left: 16px;
}


/* Aside */

d-article aside {
  grid-column: gutter;
  font-size: 12px;
  line-height: 1.6em;
  color: rgba(0, 0, 0, 0.6)
}

@media(min-width: 768px) {
  aside {
    grid-column: gutter;
  }

  .side {
    grid-column: gutter;
  }
}
/*
 * Copyright 2018 The Distill Template Authors
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 *      http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

d-title {
  padding: 2rem 0 1.5rem;
  contain: layout style;
  overflow-x: hidden;
}

@media(min-width: 768px) {
  d-title {
    padding: 4rem 0 1.5rem;
  }
}

d-title h1 {
  grid-column: text;
  font-size: 40px;
  font-weight: 700;
  line-height: 1.1em;
  margin: 0 0 0.5rem;
}

@media(min-width: 768px) {
  d-title h1 {
    font-size: 50px;
  }
}

d-title p {
  font-weight: 300;
  font-size: 1.2rem;
  line-height: 1.55em;
  grid-column: text;
}

d-title .status {
  margin-top: 0px;
  font-size: 12px;
  color: #009688;
  opacity: 0.8;
  grid-column: kicker;
}

d-title .status span {
  line-height: 1;
  display: inline-block;
  padding: 6px 0;
  border-bottom: 1px solid #80cbc4;
  font-size: 11px;
  text-transform: uppercase;
}
/*
 * Copyright 2018 The Distill Template Authors
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 *      http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

d-byline {
  contain: style;
  overflow: hidden;
  border-top: 1px solid rgba(0, 0, 0, 0.1);
  font-size: 0.8rem;
  line-height: 1.8em;
  padding: 1.5rem 0;
  min-height: 1.8em;
}


d-byline .byline {
  grid-template-columns: 1fr 1fr;
  grid-column: text;
}

@media(min-width: 768px) {
  d-byline .byline {
    grid-template-columns: 1fr 1fr 1fr 1fr;
  }
}

d-byline .authors-affiliations {
  grid-column-end: span 3;
  grid-template-columns: 1fr 1fr 1fr;
  margin-bottom: 1em;
}

@media(min-width: 768px) {
  d-byline .authors-affiliations {
    margin-bottom: 0;
  }
}

d-byline h3 {
  font-size: 0.6rem;
  font-weight: 400;
  color: rgba(0, 0, 0, 0.5);
  margin: 0;
  text-transform: uppercase;
}

d-byline p {
  margin: 0;
}

d-byline a,
d-article d-byline a {
  color: rgba(0, 0, 0, 0.8);
  text-decoration: none;
  border-bottom: none;
}

d-article d-byline a:hover {
  text-decoration: underline;
  border-bottom: none;
}

d-byline p.author {
  font-weight: 500;
}

d-byline .affiliations {

}
/*
 * Copyright 2018 The Distill Template Authors
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 *      http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

d-article {
  contain: layout style;
 border-top: 1px solid rgba(0, 0, 0, 0.1);
  padding-top: 2rem;
  color: rgba(0, 0, 0, 0.8);
}

d-article > * {
  grid-column: text;
}

@media(min-width: 768px) {
  d-article {
    font-size: 16px;
  }
}

@media(min-width: 1024px) {
  d-article {
    font-size: 1.06rem;
    line-height: 1.7em;
  }
}


/* H2 */


d-article .marker {
  text-decoration: none;
  border: none;
  counter-reset: section;
  grid-column: kicker;
  line-height: 1.7em;
}

d-article .marker:hover {
  border: none;
}

d-article .marker span {
  padding: 0 3px 4px;
  border-bottom: 1px solid rgba(0, 0, 0, 0.2);
  position: relative;
  top: 4px;
}

d-article .marker:hover span {
  color: rgba(0, 0, 0, 0.7);
  border-bottom: 1px solid rgba(0, 0, 0, 0.7);
}

d-article h2 {
  font-weight: 600;
  font-size: 24px;
  line-height: 1.25em;
  margin: 2rem 0 1.5rem 0;
  border-bottom: 1px solid rgba(0, 0, 0, 0.1);
  padding-bottom: 1rem;
}

@media(min-width: 1024px) {
  d-article h2 {
    font-size: 36px;
  }
}

/* H3 */

d-article h3 {
  font-weight: 700;
  font-size: 18px;
  line-height: 1.4em;
  margin-bottom: 1em;
  margin-top: 2em;
}

@media(min-width: 1024px) {
  d-article h3 {
    font-size: 20px;
  }
}

/* H4 */

d-article h4 {
  font-weight: 600;
  text-transform: uppercase;
  font-size: 14px;
  line-height: 1.4em;
}

d-article a {
  color: inherit;
}

d-article p,
d-article ul,
d-article ol,
d-article blockquote {
  margin-top: 0;
  margin-bottom: 1em;
  margin-left: 0;
  margin-right: 0;
}

d-article blockquote {
  border-left: 2px solid rgba(0, 0, 0, 0.2);
  padding-left: 2em;
  font-style: italic;
  color: rgba(0, 0, 0, 0.6);
}

d-article a {
  border-bottom: 1px solid var(--global-underline-color);
  text-decoration: none;
}

d-article a:hover {
  border-bottom: 1px solid rgba(0, 0, 0, 0.8);
}

d-article .link {
  text-decoration: underline;
  cursor: pointer;
}

d-article ul,
d-article ol {
  padding-left: 24px;
}

d-article li {
  margin-bottom: 1em;
  margin-left: 0;
  padding-left: 0;
}

d-article li:last-child {
  margin-bottom: 0;
}

d-article pre {
  font-size: 14px;
  margin-bottom: 20px;
}

d-article hr {
  grid-column: screen;
  width: 100%;
  border: none;
  border-bottom: 1px solid rgba(0, 0, 0, 0.1);
  margin-top: 60px;
  margin-bottom: 60px;
}

d-article section {
  margin-top: 60px;
  margin-bottom: 60px;
}

d-article span.equation-mimic {
  font-family: georgia;
  font-size: 115%;
  font-style: italic;
}

d-article > d-code,
d-article section > d-code  {
  display: block;
}

d-article > d-math[block],
d-article section > d-math[block]  {
  display: block;
}

@media (max-width: 768px) {
  d-article > d-code,
  d-article section > d-code,
  d-article > d-math[block],
  d-article section > d-math[block] {
      overflow-x: scroll;
      -ms-overflow-style: none;  // IE 10+
      overflow: -moz-scrollbars-none;  // Firefox
  }

  d-article > d-code::-webkit-scrollbar,
  d-article section > d-code::-webkit-scrollbar,
  d-article > d-math[block]::-webkit-scrollbar,
  d-article section > d-math[block]::-webkit-scrollbar {
    display: none;  // Safari and Chrome
  }
}

d-article .citation {
  color: #668;
  cursor: pointer;
}

d-include {
  width: auto;
  display: block;
}

d-figure {
  contain: layout style;
}

/* KaTeX */

.katex, .katex-prerendered {
  contain: style;
  display: inline-block;
}

/* Tables */

d-article table {
  border-collapse: collapse;
  margin-bottom: 1.5rem;
  border-bottom: 1px solid rgba(0, 0, 0, 0.2);
}

d-article table th {
  border-bottom: 1px solid rgba(0, 0, 0, 0.2);
}

d-article table td {
  border-bottom: 1px solid rgba(0, 0, 0, 0.05);
}

d-article table tr:last-of-type td {
  border-bottom: none;
}

d-article table th,
d-article table td {
  font-size: 15px;
  padding: 2px 8px;
}

d-article table tbody :first-child td {
  padding-top: 2px;
}
/*
 * Copyright 2018 The Distill Template Authors
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 *      http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

span.katex-display {
  text-align: left;
  padding: 8px 0 8px 0;
  margin: 0.5em 0 0.5em 1em;
}

span.katex {
  -webkit-font-smoothing: antialiased;
;
  font-size: 1.18em;
}

/*
 * Copyright 2018 The Distill Template Authors
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 *      http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

@media print {

  @page {
    size: 8in 11in;
    @bottom-right {
      content: counter(page) " of " counter(pages);
    }
  }

  html {
    /* no general margins -- CSS Grid takes care of those */
  }

  p, code {
    page-break-inside: avoid;
  }

  h2, h3 {
    page-break-after: avoid;
  }

  d-header {
    visibility: hidden;
  }

  d-footer {
    display: none!important;
  }

}
</style><script src="https://jax-ml.github.io/scaling-book/assets/js/theme.js?9a0c749ec5240d9cda97bc72359a72c0"></script> <link defer="" href="https://jax-ml.github.io/scaling-book/assets/css/jekyll-pygments-themes-native.css?5847e5ed4a4568527aa6cfab446049ca" id="highlight_theme_dark" media="none" rel="stylesheet"/> <script>
    initTheme();
  </script> <script src="https://jax-ml.github.io/scaling-book/assets/js/distillpub/template.v2.js"></script> <script src="https://jax-ml.github.io/scaling-book/assets/js/distillpub/transforms.v2.js"></script> <style type="text/css">{{page._styles}}</style> <style type="text/css">/* Chart.js */
@-webkit-keyframes chartjs-render-animation{from{opacity:0.99}to{opacity:1}}@keyframes chartjs-render-animation{from{opacity:0.99}to{opacity:1}}.chartjs-render-monitor{-webkit-animation:chartjs-render-animation 0.001s;animation:chartjs-render-animation 0.001s;}</style><style type="text/css">.medium-zoom-overlay{position:fixed;top:0;right:0;bottom:0;left:0;opacity:0;transition:opacity .3s;will-change:opacity}.medium-zoom--opened .medium-zoom-overlay{cursor:pointer;cursor:zoom-out;opacity:1}.medium-zoom-image{cursor:pointer;cursor:zoom-in;transition:transform .3s cubic-bezier(.2,0,.2,1)!important}.medium-zoom-image--hidden{visibility:hidden}.medium-zoom-image--opened{position:relative;cursor:pointer;cursor:zoom-out;will-change:transform}</style><style type="text/css">.CtxtMenu_InfoClose {  top:.2em; right:.2em;}
.CtxtMenu_InfoContent {  overflow:auto; text-align:left; font-size:80%;  padding:.4em .6em; border:1px inset; margin:1em 0px;  max-height:20em; max-width:30em; background-color:#EEEEEE;  white-space:normal;}
.CtxtMenu_Info.CtxtMenu_MousePost {outline:none;}
.CtxtMenu_Info {  position:fixed; left:50%; width:auto; text-align:center;  border:3px outset; padding:1em 2em; background-color:#DDDDDD;  color:black;  cursor:default; font-family:message-box; font-size:120%;  font-style:normal; text-indent:0; text-transform:none;  line-height:normal; letter-spacing:normal; word-spacing:normal;  word-wrap:normal; white-space:nowrap; float:none; z-index:201;  border-radius: 15px;                     /* Opera 10.5 and IE9 */  -webkit-border-radius:15px;               /* Safari and Chrome */  -moz-border-radius:15px;                  /* Firefox */  -khtml-border-radius:15px;                /* Konqueror */  box-shadow:0px 10px 20px #808080;         /* Opera 10.5 and IE9 */  -webkit-box-shadow:0px 10px 20px #808080; /* Safari 3 & Chrome */  -moz-box-shadow:0px 10px 20px #808080;    /* Forefox 3.5 */  -khtml-box-shadow:0px 10px 20px #808080;  /* Konqueror */  filter:progid:DXImageTransform.Microsoft.dropshadow(OffX=2, OffY=2, Color="gray", Positive="true"); /* IE */}
</style><style type="text/css">.CtxtMenu_MenuClose {  position:absolute;  cursor:pointer;  display:inline-block;  border:2px solid #AAA;  border-radius:18px;  -webkit-border-radius: 18px;             /* Safari and Chrome */  -moz-border-radius: 18px;                /* Firefox */  -khtml-border-radius: 18px;              /* Konqueror */  font-family: "Courier New", Courier;  font-size:24px;  color:#F0F0F0}
.CtxtMenu_MenuClose span {  display:block; background-color:#AAA; border:1.5px solid;  border-radius:18px;  -webkit-border-radius: 18px;             /* Safari and Chrome */  -moz-border-radius: 18px;                /* Firefox */  -khtml-border-radius: 18px;              /* Konqueror */  line-height:0;  padding:8px 0 6px     /* may need to be browser-specific */}
.CtxtMenu_MenuClose:hover {  color:white!important;  border:2px solid #CCC!important}
.CtxtMenu_MenuClose:hover span {  background-color:#CCC!important}
.CtxtMenu_MenuClose:hover:focus {  outline:none}
</style><style type="text/css">.CtxtMenu_Menu {  position:absolute;  background-color:white;  color:black;  width:auto; padding:5px 0px;  border:1px solid #CCCCCC; margin:0; cursor:default;  font: menu; text-align:left; text-indent:0; text-transform:none;  line-height:normal; letter-spacing:normal; word-spacing:normal;  word-wrap:normal; white-space:nowrap; float:none; z-index:201;  border-radius: 5px;                     /* Opera 10.5 and IE9 */  -webkit-border-radius: 5px;             /* Safari and Chrome */  -moz-border-radius: 5px;                /* Firefox */  -khtml-border-radius: 5px;              /* Konqueror */  box-shadow:0px 10px 20px #808080;         /* Opera 10.5 and IE9 */  -webkit-box-shadow:0px 10px 20px #808080; /* Safari 3 & Chrome */  -moz-box-shadow:0px 10px 20px #808080;    /* Forefox 3.5 */  -khtml-box-shadow:0px 10px 20px #808080;  /* Konqueror */}
.CtxtMenu_MenuItem {  padding: 1px 2em;  background:transparent;}
.CtxtMenu_MenuArrow {  position:absolute; right:.5em; padding-top:.25em; color:#666666;  font-family: null; font-size: .75em}
.CtxtMenu_MenuActive .CtxtMenu_MenuArrow {color:white}
.CtxtMenu_MenuArrow.CtxtMenu_RTL {left:.5em; right:auto}
.CtxtMenu_MenuCheck {  position:absolute; left:.7em;  font-family: null}
.CtxtMenu_MenuCheck.CtxtMenu_RTL { right:.7em; left:auto }
.CtxtMenu_MenuRadioCheck {  position:absolute; left: .7em;}
.CtxtMenu_MenuRadioCheck.CtxtMenu_RTL {  right: .7em; left:auto}
.CtxtMenu_MenuInputBox {  padding-left: 1em; right:.5em; color:#666666;  font-family: null;}
.CtxtMenu_MenuInputBox.CtxtMenu_RTL {  left: .1em;}
.CtxtMenu_MenuComboBox {  left:.1em; padding-bottom:.5em;}
.CtxtMenu_MenuSlider {  left: .1em;}
.CtxtMenu_SliderValue {  position:absolute; right:.1em; padding-top:.25em; color:#333333;  font-size: .75em}
.CtxtMenu_SliderBar {  outline: none; background: #d3d3d3}
.CtxtMenu_MenuLabel {  padding: 1px 2em 3px 1.33em;  font-style:italic}
.CtxtMenu_MenuRule {  border-top: 1px solid #DDDDDD;  margin: 4px 3px;}
.CtxtMenu_MenuDisabled {  color:GrayText}
.CtxtMenu_MenuActive {  background-color: #606872;  color: white;}
.CtxtMenu_MenuDisabled:focus {  background-color: #E8E8E8}
.CtxtMenu_MenuLabel:focus {  background-color: #E8E8E8}
.CtxtMenu_ContextMenu:focus {  outline:none}
.CtxtMenu_ContextMenu .CtxtMenu_MenuItem:focus {  outline:none}
.CtxtMenu_SelectionMenu {  position:relative; float:left;  border-bottom: none; -webkit-box-shadow:none; -webkit-border-radius:0px; }
.CtxtMenu_SelectionItem {  padding-right: 1em;}
.CtxtMenu_Selection {  right: 40%; width:50%; }
.CtxtMenu_SelectionBox {  padding: 0em; max-height:20em; max-width: none;  background-color:#FFFFFF;}
.CtxtMenu_SelectionDivider {  clear: both; border-top: 2px solid #000000;}
.CtxtMenu_Menu .CtxtMenu_MenuClose {  top:-10px; left:-10px}
</style><style id="MJX-CHTML-styles">
mjx-container[jax="CHTML"] {
  line-height: 0;
}

mjx-container [space="1"] {
  margin-left: .111em;
}

mjx-container [space="2"] {
  margin-left: .167em;
}

mjx-container [space="3"] {
  margin-left: .222em;
}

mjx-container [space="4"] {
  margin-left: .278em;
}

mjx-container [space="5"] {
  margin-left: .333em;
}

mjx-container [rspace="1"] {
  margin-right: .111em;
}

mjx-container [rspace="2"] {
  margin-right: .167em;
}

mjx-container [rspace="3"] {
  margin-right: .222em;
}

mjx-container [rspace="4"] {
  margin-right: .278em;
}

mjx-container [rspace="5"] {
  margin-right: .333em;
}

mjx-container [size="s"] {
  font-size: 70.7%;
}

mjx-container [size="ss"] {
  font-size: 50%;
}

mjx-container [size="Tn"] {
  font-size: 60%;
}

mjx-container [size="sm"] {
  font-size: 85%;
}

mjx-container [size="lg"] {
  font-size: 120%;
}

mjx-container [size="Lg"] {
  font-size: 144%;
}

mjx-container [size="LG"] {
  font-size: 173%;
}

mjx-container [size="hg"] {
  font-size: 207%;
}

mjx-container [size="HG"] {
  font-size: 249%;
}

mjx-container [width="full"] {
  width: 100%;
}

mjx-box {
  display: inline-block;
}

mjx-block {
  display: block;
}

mjx-itable {
  display: inline-table;
}

mjx-row {
  display: table-row;
}

mjx-row > * {
  display: table-cell;
}

mjx-mtext {
  display: inline-block;
  text-align: left;
}

mjx-mstyle {
  display: inline-block;
}

mjx-merror {
  display: inline-block;
  color: red;
  background-color: yellow;
}

mjx-mphantom {
  visibility: hidden;
}

_::-webkit-full-page-media, _:future, :root mjx-container {
  will-change: opacity;
}

mjx-assistive-mml {
  position: absolute !important;
  top: 0px;
  left: 0px;
  clip: rect(1px, 1px, 1px, 1px);
  padding: 1px 0px 0px 0px !important;
  border: 0px !important;
  display: block !important;
  width: auto !important;
  overflow: hidden !important;
  -webkit-touch-callout: none;
  -webkit-user-select: none;
  -khtml-user-select: none;
  -moz-user-select: none;
  -ms-user-select: none;
  user-select: none;
}

mjx-assistive-mml[display="block"] {
  width: 100% !important;
}

mjx-math {
  display: inline-block;
  text-align: left;
  line-height: 0;
  text-indent: 0;
  font-style: normal;
  font-weight: normal;
  font-size: 100%;
  font-size-adjust: none;
  letter-spacing: normal;
  border-collapse: collapse;
  word-wrap: normal;
  word-spacing: normal;
  white-space: nowrap;
  direction: ltr;
  padding: 1px 0;
}

mjx-container[jax="CHTML"][display="true"] {
  display: block;
  text-align: center;
  margin: 1em 0;
}

mjx-container[jax="CHTML"][display="true"][width="full"] {
  display: flex;
}

mjx-container[jax="CHTML"][display="true"] mjx-math {
  padding: 0;
}

mjx-container[jax="CHTML"][justify="left"] {
  text-align: left;
}

mjx-container[jax="CHTML"][justify="right"] {
  text-align: right;
}

mjx-mi {
  display: inline-block;
  text-align: left;
}

mjx-c {
  display: inline-block;
}

mjx-utext {
  display: inline-block;
  padding: .75em 0 .2em 0;
}

mjx-mo {
  display: inline-block;
  text-align: left;
}

mjx-stretchy-h {
  display: inline-table;
  width: 100%;
}

mjx-stretchy-h > * {
  display: table-cell;
  width: 0;
}

mjx-stretchy-h > * > mjx-c {
  display: inline-block;
  transform: scalex(1.0000001);
}

mjx-stretchy-h > * > mjx-c::before {
  display: inline-block;
  width: initial;
}

mjx-stretchy-h > mjx-ext {
  /* IE */ overflow: hidden;
  /* others */ overflow: clip visible;
  width: 100%;
}

mjx-stretchy-h > mjx-ext > mjx-c::before {
  transform: scalex(500);
}

mjx-stretchy-h > mjx-ext > mjx-c {
  width: 0;
}

mjx-stretchy-h > mjx-beg > mjx-c {
  margin-right: -.1em;
}

mjx-stretchy-h > mjx-end > mjx-c {
  margin-left: -.1em;
}

mjx-stretchy-v {
  display: inline-block;
}

mjx-stretchy-v > * {
  display: block;
}

mjx-stretchy-v > mjx-beg {
  height: 0;
}

mjx-stretchy-v > mjx-end > mjx-c {
  display: block;
}

mjx-stretchy-v > * > mjx-c {
  transform: scaley(1.0000001);
  transform-origin: left center;
  overflow: hidden;
}

mjx-stretchy-v > mjx-ext {
  display: block;
  height: 100%;
  box-sizing: border-box;
  border: 0px solid transparent;
  /* IE */ overflow: hidden;
  /* others */ overflow: visible clip;
}

mjx-stretchy-v > mjx-ext > mjx-c::before {
  width: initial;
  box-sizing: border-box;
}

mjx-stretchy-v > mjx-ext > mjx-c {
  transform: scaleY(500) translateY(.075em);
  overflow: visible;
}

mjx-mark {
  display: inline-block;
  height: 0px;
}

mjx-msub {
  display: inline-block;
  text-align: left;
}

mjx-mfrac {
  display: inline-block;
  text-align: left;
}

mjx-frac {
  display: inline-block;
  vertical-align: 0.17em;
  padding: 0 .22em;
}

mjx-frac[type="d"] {
  vertical-align: .04em;
}

mjx-frac[delims] {
  padding: 0 .1em;
}

mjx-frac[atop] {
  padding: 0 .12em;
}

mjx-frac[atop][delims] {
  padding: 0;
}

mjx-dtable {
  display: inline-table;
  width: 100%;
}

mjx-dtable > * {
  font-size: 2000%;
}

mjx-dbox {
  display: block;
  font-size: 5%;
}

mjx-num {
  display: block;
  text-align: center;
}

mjx-den {
  display: block;
  text-align: center;
}

mjx-mfrac[bevelled] > mjx-num {
  display: inline-block;
}

mjx-mfrac[bevelled] > mjx-den {
  display: inline-block;
}

mjx-den[align="right"], mjx-num[align="right"] {
  text-align: right;
}

mjx-den[align="left"], mjx-num[align="left"] {
  text-align: left;
}

mjx-nstrut {
  display: inline-block;
  height: .054em;
  width: 0;
  vertical-align: -.054em;
}

mjx-nstrut[type="d"] {
  height: .217em;
  vertical-align: -.217em;
}

mjx-dstrut {
  display: inline-block;
  height: .505em;
  width: 0;
}

mjx-dstrut[type="d"] {
  height: .726em;
}

mjx-line {
  display: block;
  box-sizing: border-box;
  min-height: 1px;
  height: .06em;
  border-top: .06em solid;
  margin: .06em -.1em;
  overflow: hidden;
}

mjx-line[type="d"] {
  margin: .18em -.1em;
}

mjx-mrow {
  display: inline-block;
  text-align: left;
}

mjx-mn {
  display: inline-block;
  text-align: left;
}

mjx-msup {
  display: inline-block;
  text-align: left;
}

mjx-munder {
  display: inline-block;
  text-align: left;
}

mjx-over {
  text-align: left;
}

mjx-munder:not([limits="false"]) {
  display: inline-table;
}

mjx-munder > mjx-row {
  text-align: left;
}

mjx-under {
  padding-bottom: .1em;
}

mjx-TeXAtom {
  display: inline-block;
  text-align: left;
}

mjx-c::before {
  display: block;
  width: 0;
}

.MJX-TEX {
  font-family: MJXZERO, MJXTEX;
}

.TEX-B {
  font-family: MJXZERO, MJXTEX-B;
}

.TEX-I {
  font-family: MJXZERO, MJXTEX-I;
}

.TEX-MI {
  font-family: MJXZERO, MJXTEX-MI;
}

.TEX-BI {
  font-family: MJXZERO, MJXTEX-BI;
}

.TEX-S1 {
  font-family: MJXZERO, MJXTEX-S1;
}

.TEX-S2 {
  font-family: MJXZERO, MJXTEX-S2;
}

.TEX-S3 {
  font-family: MJXZERO, MJXTEX-S3;
}

.TEX-S4 {
  font-family: MJXZERO, MJXTEX-S4;
}

.TEX-A {
  font-family: MJXZERO, MJXTEX-A;
}

.TEX-C {
  font-family: MJXZERO, MJXTEX-C;
}

.TEX-CB {
  font-family: MJXZERO, MJXTEX-CB;
}

.TEX-FR {
  font-family: MJXZERO, MJXTEX-FR;
}

.TEX-FRB {
  font-family: MJXZERO, MJXTEX-FRB;
}

.TEX-SS {
  font-family: MJXZERO, MJXTEX-SS;
}

.TEX-SSB {
  font-family: MJXZERO, MJXTEX-SSB;
}

.TEX-SSI {
  font-family: MJXZERO, MJXTEX-SSI;
}

.TEX-SC {
  font-family: MJXZERO, MJXTEX-SC;
}

.TEX-T {
  font-family: MJXZERO, MJXTEX-T;
}

.TEX-V {
  font-family: MJXZERO, MJXTEX-V;
}

.TEX-VB {
  font-family: MJXZERO, MJXTEX-VB;
}

mjx-stretchy-v mjx-c, mjx-stretchy-h mjx-c {
  font-family: MJXZERO, MJXTEX-S1, MJXTEX-S4, MJXTEX, MJXTEX-A ! important;
}

@font-face /* 0 */ {
  font-family: MJXZERO;
  src: url("https://cdn.jsdelivr.net/npm/mathjax@3.2.2/es5/output/chtml/fonts/woff-v2/MathJax_Zero.woff") format("woff");
}

@font-face /* 1 */ {
  font-family: MJXTEX;
  src: url("https://cdn.jsdelivr.net/npm/mathjax@3.2.2/es5/output/chtml/fonts/woff-v2/MathJax_Main-Regular.woff") format("woff");
}

@font-face /* 2 */ {
  font-family: MJXTEX-B;
  src: url("https://cdn.jsdelivr.net/npm/mathjax@3.2.2/es5/output/chtml/fonts/woff-v2/MathJax_Main-Bold.woff") format("woff");
}

@font-face /* 3 */ {
  font-family: MJXTEX-I;
  src: url("https://cdn.jsdelivr.net/npm/mathjax@3.2.2/es5/output/chtml/fonts/woff-v2/MathJax_Math-Italic.woff") format("woff");
}

@font-face /* 4 */ {
  font-family: MJXTEX-MI;
  src: url("https://cdn.jsdelivr.net/npm/mathjax@3.2.2/es5/output/chtml/fonts/woff-v2/MathJax_Main-Italic.woff") format("woff");
}

@font-face /* 5 */ {
  font-family: MJXTEX-BI;
  src: url("https://cdn.jsdelivr.net/npm/mathjax@3.2.2/es5/output/chtml/fonts/woff-v2/MathJax_Math-BoldItalic.woff") format("woff");
}

@font-face /* 6 */ {
  font-family: MJXTEX-S1;
  src: url("https://cdn.jsdelivr.net/npm/mathjax@3.2.2/es5/output/chtml/fonts/woff-v2/MathJax_Size1-Regular.woff") format("woff");
}

@font-face /* 7 */ {
  font-family: MJXTEX-S2;
  src: url("https://cdn.jsdelivr.net/npm/mathjax@3.2.2/es5/output/chtml/fonts/woff-v2/MathJax_Size2-Regular.woff") format("woff");
}

@font-face /* 8 */ {
  font-family: MJXTEX-S3;
  src: url("https://cdn.jsdelivr.net/npm/mathjax@3.2.2/es5/output/chtml/fonts/woff-v2/MathJax_Size3-Regular.woff") format("woff");
}

@font-face /* 9 */ {
  font-family: MJXTEX-S4;
  src: url("https://cdn.jsdelivr.net/npm/mathjax@3.2.2/es5/output/chtml/fonts/woff-v2/MathJax_Size4-Regular.woff") format("woff");
}

@font-face /* 10 */ {
  font-family: MJXTEX-A;
  src: url("https://cdn.jsdelivr.net/npm/mathjax@3.2.2/es5/output/chtml/fonts/woff-v2/MathJax_AMS-Regular.woff") format("woff");
}

@font-face /* 11 */ {
  font-family: MJXTEX-C;
  src: url("https://cdn.jsdelivr.net/npm/mathjax@3.2.2/es5/output/chtml/fonts/woff-v2/MathJax_Calligraphic-Regular.woff") format("woff");
}

@font-face /* 12 */ {
  font-family: MJXTEX-CB;
  src: url("https://cdn.jsdelivr.net/npm/mathjax@3.2.2/es5/output/chtml/fonts/woff-v2/MathJax_Calligraphic-Bold.woff") format("woff");
}

@font-face /* 13 */ {
  font-family: MJXTEX-FR;
  src: url("https://cdn.jsdelivr.net/npm/mathjax@3.2.2/es5/output/chtml/fonts/woff-v2/MathJax_Fraktur-Regular.woff") format("woff");
}

@font-face /* 14 */ {
  font-family: MJXTEX-FRB;
  src: url("https://cdn.jsdelivr.net/npm/mathjax@3.2.2/es5/output/chtml/fonts/woff-v2/MathJax_Fraktur-Bold.woff") format("woff");
}

@font-face /* 15 */ {
  font-family: MJXTEX-SS;
  src: url("https://cdn.jsdelivr.net/npm/mathjax@3.2.2/es5/output/chtml/fonts/woff-v2/MathJax_SansSerif-Regular.woff") format("woff");
}

@font-face /* 16 */ {
  font-family: MJXTEX-SSB;
  src: url("https://cdn.jsdelivr.net/npm/mathjax@3.2.2/es5/output/chtml/fonts/woff-v2/MathJax_SansSerif-Bold.woff") format("woff");
}

@font-face /* 17 */ {
  font-family: MJXTEX-SSI;
  src: url("https://cdn.jsdelivr.net/npm/mathjax@3.2.2/es5/output/chtml/fonts/woff-v2/MathJax_SansSerif-Italic.woff") format("woff");
}

@font-face /* 18 */ {
  font-family: MJXTEX-SC;
  src: url("https://cdn.jsdelivr.net/npm/mathjax@3.2.2/es5/output/chtml/fonts/woff-v2/MathJax_Script-Regular.woff") format("woff");
}

@font-face /* 19 */ {
  font-family: MJXTEX-T;
  src: url("https://cdn.jsdelivr.net/npm/mathjax@3.2.2/es5/output/chtml/fonts/woff-v2/MathJax_Typewriter-Regular.woff") format("woff");
}

@font-face /* 20 */ {
  font-family: MJXTEX-V;
  src: url("https://cdn.jsdelivr.net/npm/mathjax@3.2.2/es5/output/chtml/fonts/woff-v2/MathJax_Vector-Regular.woff") format("woff");
}

@font-face /* 21 */ {
  font-family: MJXTEX-VB;
  src: url("https://cdn.jsdelivr.net/npm/mathjax@3.2.2/es5/output/chtml/fonts/woff-v2/MathJax_Vector-Bold.woff") format("woff");
}

mjx-c.mjx-c1D447.TEX-I::before {
  padding: 0.677em 0.704em 0 0;
  content: "T";
}

mjx-c.mjx-c3D::before {
  padding: 0.583em 0.778em 0.082em 0;
  content: "=";
}

mjx-c.mjx-c6D::before {
  padding: 0.442em 0.833em 0 0;
  content: "m";
}

mjx-c.mjx-c61::before {
  padding: 0.448em 0.5em 0.011em 0;
  content: "a";
}

mjx-c.mjx-c78::before {
  padding: 0.431em 0.528em 0 0;
  content: "x";
}

mjx-c.mjx-c28::before {
  padding: 0.75em 0.389em 0.25em 0;
  content: "(";
}

mjx-c.mjx-c63::before {
  padding: 0.448em 0.444em 0.011em 0;
  content: "c";
}

mjx-c.mjx-c6F::before {
  padding: 0.448em 0.5em 0.01em 0;
  content: "o";
}

mjx-c.mjx-c73::before {
  padding: 0.448em 0.394em 0.011em 0;
  content: "s";
}

mjx-c.mjx-c2C::before {
  padding: 0.121em 0.278em 0.194em 0;
  content: ",";
}

mjx-c.mjx-c74::before {
  padding: 0.615em 0.389em 0.01em 0;
  content: "t";
}

mjx-c.mjx-c68::before {
  padding: 0.694em 0.556em 0 0;
  content: "h";
}

mjx-c.mjx-c29::before {
  padding: 0.75em 0.389em 0.25em 0;
  content: ")";
}

mjx-c.mjx-c31::before {
  padding: 0.666em 0.5em 0 0;
  content: "1";
}

mjx-c.mjx-c32::before {
  padding: 0.666em 0.5em 0 0;
  content: "2";
}

mjx-c.mjx-c22C5::before {
  padding: 0.31em 0.278em 0 0;
  content: "\22C5";
}

mjx-c.mjx-c1D441.TEX-I::before {
  padding: 0.683em 0.888em 0 0;
  content: "N";
}

mjx-c.mjx-c33::before {
  padding: 0.665em 0.5em 0.022em 0;
  content: "3";
}

mjx-c.mjx-c2E::before {
  padding: 0.12em 0.278em 0 0;
  content: ".";
}

mjx-c.mjx-c35::before {
  padding: 0.666em 0.5em 0.022em 0;
  content: "5";
}

mjx-c.mjx-c65::before {
  padding: 0.448em 0.444em 0.011em 0;
  content: "e";
}

mjx-c.mjx-c38::before {
  padding: 0.666em 0.5em 0.022em 0;
  content: "8";
}

mjx-c.mjx-c41::before {
  padding: 0.716em 0.75em 0 0;
  content: "A";
}

mjx-c.mjx-c47::before {
  padding: 0.705em 0.785em 0.022em 0;
  content: "G";
}

mjx-c.mjx-c20::before {
  padding: 0 0.25em 0 0;
  content: " ";
}

mjx-c.mjx-c72::before {
  padding: 0.442em 0.392em 0 0;
  content: "r";
}

mjx-c.mjx-c52::before {
  padding: 0.683em 0.736em 0.022em 0;
  content: "R";
}

mjx-c.mjx-c53::before {
  padding: 0.705em 0.556em 0.022em 0;
  content: "S";
}

mjx-c.mjx-c62::before {
  padding: 0.694em 0.556em 0.011em 0;
  content: "b";
}

mjx-c.mjx-c79::before {
  padding: 0.431em 0.528em 0.204em 0;
  content: "y";
}

mjx-c.mjx-c2212::before {
  padding: 0.583em 0.778em 0.082em 0;
  content: "\2212";
}

mjx-c.mjx-c50::before {
  padding: 0.683em 0.681em 0 0;
  content: "P";
}

mjx-c.mjx-c55::before {
  padding: 0.683em 0.75em 0.022em 0;
  content: "U";
}

mjx-c.mjx-c67::before {
  padding: 0.453em 0.5em 0.206em 0;
  content: "g";
}

mjx-c.mjx-c6E::before {
  padding: 0.442em 0.556em 0 0;
  content: "n";
}

mjx-c.mjx-c64::before {
  padding: 0.694em 0.556em 0.011em 0;
  content: "d";
}

mjx-c.mjx-c77::before {
  padding: 0.431em 0.722em 0.011em 0;
  content: "w";
}

mjx-c.mjx-c69::before {
  padding: 0.669em 0.278em 0 0;
  content: "i";
}

mjx-c.mjx-c2192::before {
  padding: 0.511em 1em 0.011em 0;
  content: "\2192";
}

mjx-c.mjx-c6C::before {
  padding: 0.694em 0.278em 0 0;
  content: "l";
}

mjx-c.mjx-c54::before {
  padding: 0.677em 0.722em 0 0;
  content: "T";
}

mjx-c.mjx-c1D435.TEX-I::before {
  padding: 0.683em 0.759em 0 0;
  content: "B";
}

mjx-c.mjx-c1D44A.TEX-I::before {
  padding: 0.683em 1.048em 0.022em 0;
  content: "W";
}

mjx-c.mjx-c2248::before {
  padding: 0.483em 0.778em 0 0;
  content: "\2248";
}

mjx-c.mjx-c28.TEX-S3::before {
  padding: 1.45em 0.736em 0.949em 0;
  content: "(";
}

mjx-c.mjx-c1D44D.TEX-I::before {
  padding: 0.683em 0.723em 0 0;
  content: "Z";
}

mjx-c.mjx-c29.TEX-S3::before {
  padding: 1.45em 0.736em 0.949em 0;
  content: ")";
}

mjx-c.mjx-c1D43E.TEX-I::before {
  padding: 0.683em 0.889em 0 0;
  content: "K";
}

mjx-c.mjx-c48::before {
  padding: 0.683em 0.75em 0 0;
  content: "H";
}

mjx-c.mjx-c1D43B.TEX-I::before {
  padding: 0.683em 0.888em 0 0;
  content: "H";
}

mjx-c.mjx-c30::before {
  padding: 0.666em 0.5em 0.022em 0;
  content: "0";
}

mjx-c.mjx-c34::before {
  padding: 0.677em 0.5em 0 0;
  content: "4";
}

mjx-c.mjx-c39::before {
  padding: 0.666em 0.5em 0.022em 0;
  content: "9";
}

mjx-c.mjx-c2D::before {
  padding: 0.252em 0.333em 0 0;
  content: "-";
}

mjx-c.mjx-c75::before {
  padding: 0.442em 0.556em 0.011em 0;
  content: "u";
}

mjx-c.mjx-c6B::before {
  padding: 0.694em 0.528em 0 0;
  content: "k";
}

mjx-c.mjx-c5B.TEX-S3::before {
  padding: 1.45em 0.528em 0.949em 0;
  content: "[";
}

mjx-c.mjx-c5D.TEX-S3::before {
  padding: 1.45em 0.528em 0.949em 0;
  content: "]";
}

mjx-c.mjx-c1D45A.TEX-I::before {
  padding: 0.442em 0.878em 0.011em 0;
  content: "m";
}

mjx-c.mjx-c1D44E.TEX-I::before {
  padding: 0.441em 0.529em 0.01em 0;
  content: "a";
}

mjx-c.mjx-c1D465.TEX-I::before {
  padding: 0.442em 0.572em 0.011em 0;
  content: "x";
}

mjx-c.mjx-c70::before {
  padding: 0.442em 0.556em 0.194em 0;
  content: "p";
}

mjx-c.mjx-c1D437.TEX-I::before {
  padding: 0.683em 0.828em 0 0;
  content: "D";
}

mjx-c.mjx-c1D456.TEX-I::before {
  padding: 0.661em 0.345em 0.011em 0;
  content: "i";
}

mjx-c.mjx-c1D440.TEX-I::before {
  padding: 0.683em 1.051em 0 0;
  content: "M";
}

mjx-c.mjx-c224A.TEX-A::before {
  padding: 0.579em 0.778em 0.039em 0;
  content: "\224A";
}

mjx-c.mjx-c1D44B.TEX-I::before {
  padding: 0.683em 0.852em 0 0;
  content: "X";
}

mjx-c.mjx-c1D434.TEX-I::before {
  padding: 0.716em 0.75em 0 0;
  content: "A";
}

mjx-c.mjx-c5B::before {
  padding: 0.75em 0.278em 0.25em 0;
  content: "[";
}

mjx-c.mjx-c1D43C.TEX-I::before {
  padding: 0.683em 0.504em 0 0;
  content: "I";
}

mjx-c.mjx-c1D44C.TEX-I::before {
  padding: 0.683em 0.763em 0 0;
  content: "Y";
}

mjx-c.mjx-c1D43D.TEX-I::before {
  padding: 0.683em 0.633em 0.022em 0;
  content: "J";
}

mjx-c.mjx-c5D::before {
  padding: 0.75em 0.278em 0.25em 0;
  content: "]";
}

mjx-c.mjx-cA0::before {
  padding: 0 0.25em 0 0;
  content: "\A0";
}

mjx-c.mjx-c7B::before {
  padding: 0.75em 0.5em 0.25em 0;
  content: "{";
}

mjx-c.mjx-c1D448.TEX-I::before {
  padding: 0.683em 0.767em 0.022em 0;
  content: "U";
}

mjx-c.mjx-c7D::before {
  padding: 0.75em 0.5em 0.25em 0;
  content: "}";
}

mjx-c.mjx-c1D446.TEX-I::before {
  padding: 0.705em 0.645em 0.022em 0;
  content: "S";
}

mjx-c.mjx-c1D439.TEX-I::before {
  padding: 0.68em 0.749em 0 0;
  content: "F";
}

mjx-c.mjx-c36::before {
  padding: 0.666em 0.5em 0.022em 0;
  content: "6";
}

mjx-c.mjx-c42::before {
  padding: 0.683em 0.708em 0 0;
  content: "B";
}

mjx-c.mjx-c2F::before {
  padding: 0.75em 0.5em 0.25em 0;
  content: "/";
}

mjx-c.mjx-c4D::before {
  padding: 0.683em 0.917em 0 0;
  content: "M";
}

mjx-c.mjx-c4C::before {
  padding: 0.683em 0.625em 0 0;
  content: "L";
}

mjx-c.mjx-c2261::before {
  padding: 0.464em 0.778em 0 0;
  content: "\2261";
}

mjx-c.mjx-c2217::before {
  padding: 0.465em 0.5em 0 0;
  content: "\2217";
}

mjx-c.mjx-c1D436.TEX-I::before {
  padding: 0.705em 0.76em 0.022em 0;
  content: "C";
}

mjx-c.mjx-c76::before {
  padding: 0.431em 0.528em 0.011em 0;
  content: "v";
}

mjx-c.mjx-c3E::before {
  padding: 0.54em 0.778em 0.04em 0;
  content: ">";
}

mjx-c.mjx-c1D458.TEX-I::before {
  padding: 0.694em 0.521em 0.011em 0;
  content: "k";
}

mjx-c.mjx-c1D438.TEX-I::before {
  padding: 0.68em 0.764em 0 0;
  content: "E";
}

mjx-c.mjx-c3C::before {
  padding: 0.54em 0.778em 0.04em 0;
  content: "<";
}

mjx-c.mjx-c2B::before {
  padding: 0.583em 0.778em 0.082em 0;
  content: "+";
}
</style><link crossorigin="anonymous" href="https://distill.pub/third-party/katex/katex.min.css" rel="stylesheet"/><script async="" src="https://distill.pub/third-party/katex/katex.min.js"></script></head>
<body> <d-front-matter> <script async="" type="text/json">
      {
            "title": "如何理解 GPU",
            "description": "我们在 Google 热爱 TPU，但 GPU 也很棒。本章深入探讨 NVIDIA GPU 的世界——每个芯片如何工作，它们如何互联，以及这对 LLM 意味着什么，特别是与 TPU 相比。本节建立在 <a href='https://jax-ml.github.io/scaling-book/tpus/'>第 2 章</a> 和 <a href='https://jax-ml.github.io/scaling-book/training'>第 5 章</a> 的基础上，因此建议您先阅读它们。",
            "published": "2025 年 8 月 18 日",
            "authors": [

              {
                "author": "Jacob Austin<sup>†</sup>",
                "authorURL": "https://www.jacobaustin.org/",
                "affiliations": [
                  {
                    "name": "<sup>†</sup>Google DeepMind",
                    "url": ""
                  }
                ]
              },

              {
                "author": "Swapnil Patil<sup>†</sup>",
                "authorURL": "https://www.linkedin.com/in/swapnil-patil-5b47a068",
                "affiliations": [
                  {
                    "name": "",
                    "url": ""
                  }
                ]
              },

              {
                "author": "Adam Paszke<sup>†</sup>",
                "authorURL": "https://x.com/apaszke",
                "affiliations": [
                  {
                    "name": "",
                    "url": ""
                  }
                ]
              },

              {
                "author": "Reiner Pope<sup>*</sup>",
                "authorURL": "https://x.com/reinerpope",
                "affiliations": [
                  {
                    "name": "<sup>*</sup>MatX",
                    "url": ""
                  }
                ]
              }

            ],
            "katex": {
              "delimiters": [
                {
                  "left": "$",
                  "right": "$",
                  "display": false
                },
                {
                  "left": "$$",
                  "right": "$$",
                  "display": true
                }
              ]
            }
          }
    </script> </d-front-matter> <header> <script>
    function goToTop() {
      document.body.scrollTop = 0; // For Safari
      document.documentElement.scrollTop = 0; // For Chrome, Firefox, IE and Opera
    }

    // When the user scrolls down 20px from the top of the document, show the button
    window.onscroll = function() {scrollFunction()};

    function scrollFunction() {
      // Get the button:
      let mybutton = document.getElementById("top-button");

      if (document.body.scrollTop > 40 || document.documentElement.scrollTop > 40) {
        mybutton.style.display = "block";
      } else {
        mybutton.style.display = "none";
      }
  }
  </script> <nav class="navbar navbar-light navbar-expand-sm fixed-top" id="navbar" role="navigation"> <div class="container"> <a class="navbar-brand title font-weight-lighter" href="scaling-book.html"> 如何扩展你的模型 </a> <button aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation" class="navbar-toggler collapsed ml-auto" data-target="#navbarNav" data-toggle="collapse" type="button"> <span class="sr-only">切换导航</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="left-button section-button"><a href="conclusion.html"><svg viewbox="-78.5 0 512 512"><path d="M257 64L291 98 128 262 291 426 257 460 61 262 257 64Z"></path></svg></a></div> <div class="right-button section-button"><a href=""><svg viewbox="-78.5 0 512 512"><path d="M98 460L64 426 227 262 64 98 98 64 294 262 98 460Z"></path></svg></a></div> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item"> <a class="nav-link" href="scaling-book.html"> </a> </li> <li class="nav-item nav-hidden"><a class="nav-link" id="top-button" onclick="goToTop()" style="display: none;">返回顶部</a></li> <li class="nav-item nav-hidden"><p class="nav-link"></p></li> <li class="nav-item nav-hidden"><a class="nav-link" href="conclusion.html">上一部分</a></li> <li class="nav-item nav-hidden"><a class="nav-link" href="">下一部分</a></li> <li class="nav-item nav-hidden"><p class="nav-link"></p></li> <li class="nav-item dropdown"> <a aria-expanded="false" aria-haspopup="true" class="nav-link dropdown-toggle" data-toggle="dropdown" href="#" id="navbarDropdown" role="button">章节 </a> <div aria-labelledby="navbarDropdown" class="dropdown-menu dropdown-menu-right"> <a class="dropdown-item" href="https://jax-ml.github.io/scaling-book/index">第 0 部分：引言</a> <a class="dropdown-item" href="roofline.html">第 1 部分：屋顶线模型简介</a> <a class="dropdown-item" href="tpus.html">第 2 部分：TPU 全解</a> <a class="dropdown-item" href="sharding.html">第 3 部分：分片矩阵乘法</a> <a class="dropdown-item" href="transformers.html">第 4 部分：Transformer</a> <a class="dropdown-item" href="training.html">第 5 部分：训练</a> <a class="dropdown-item" href="applied-training.html">第 6 部分：LLaMA 训练</a> <a class="dropdown-item" href="inference.html">第 7 部分：推理</a> <a class="dropdown-item" href="applied-inference.html">第 8 部分：LLaMA 服务</a> <a class="dropdown-item" href="profiling.html">第 9 部分：性能分析</a> <a class="dropdown-item" href="jax-stuff.html">第 10 部分：JAX 全解</a> <a class="dropdown-item" href="conclusion.html">第 11 部分：结论</a> <a class="dropdown-item" href="gpus.html">第 12 部分：GPU</a> </div> </li> <li class="toggle-container"> <button id="light-toggle" title="Change theme"> <i class="ti ti-sun-moon" id="light-toggle-system"></i> <i class="ti ti-moon-filled" id="light-toggle-dark"></i> <i class="ti ti-sun-filled" id="light-toggle-light"></i> </button> </li> </ul> </div> </div> </nav> <progress id="progress" value="0"> <div class="progress-container"> <span class="progress-bar"></span> </div> </progress> </header> <div class="post distill"><div class="translation-info base-grid" style="margin-bottom: 20px;">
<div style="grid-column: text;
                       display: flex;
                       align-items: center;
                       justify-content: space-between;
                       padding: 16px 0;
                       border-bottom: 1px solid var(--global-text-color-light, rgba(0,0,0,0.15));
                       font-size: 16px;
                       line-height: 1.5;
                       color: var(--global-text-color, currentColor);">
<div style="display: flex;
                           flex-direction: column;
                           gap: 8px;">
<div>
<span style="font-weight: 600; color: var(--global-text-color, currentColor);">🔗 英文原文：</span>
<a href="https://jax-ml.github.io/scaling-book/gpus/" onmouseout="this.style.textDecoration='none'" onmouseover="this.style.textDecoration='underline'" rel="noopener noreferrer" style="color: var(--global-theme-color, #004276);
                                  text-decoration: none;
                                  margin-left: 4px;" target="_blank">
                           https://jax-ml.github.io/scaling-book/gpus/
                        </a>
</div>
<div>
<span style="font-weight: 600; color: var(--global-text-color, currentColor);">✍️ 翻译：</span>
<a href="https://github.com/skindhu/Build-A-Large-Language-Model-CN" target="_blank" style="margin-left: 4px; color: var(--global-theme-color, #004276); text-decoration: none;">北极的树</a>
</div>
</div>
<div style="flex-shrink: 0;
                           display: flex;
                           flex-direction: column;
                           align-items: center;
                           gap: 6px;
                           margin-left: 20px;">
<img alt="微信二维码" loading="lazy" src="https://wechat-account-1251781786.cos.ap-guangzhou.myqcloud.com/wechat_account.jpeg" style="width: 80px;
                                height: 80px;
                                border-radius: 6px;
                                opacity: 0.9;"/>
<span style="font-size: 12px;
                                 color: var(--global-text-color-light, currentColor);
                                 opacity: 0.8;
                                 text-align: center;">
                        微信公众号
                    </span>
</div>
</div>
</div> <d-title> <h1>如何理解 GPU</h1> <p>《如何扩展你的模型》的<a href="scaling-book.html">第 12 部分</a>（<a href="conclusion.html">第 11 部分：结论</a> | <a href="">结尾</a>）</p> <p>我们在 Google 热爱 TPU，但 GPU 也很棒。本章深入探讨 NVIDIA GPU 的世界——每个芯片如何工作，它们如何互联，以及这对 LLM 意味着什么，特别是与 TPU 相比。本节建立在<a href="tpus.html">第 2 章</a>和<a href="training.html">第 5 章</a>的基础上，因此建议您先阅读它们。</p> </d-title> <d-byline>
<div class="byline grid">
<div class="authors-affiliations grid">
<h3 style="grid-column: 1; grid-row: 1;">作者</h3>
<h3></h3>
<h3>所属机构</h3>
<p class="author" style="grid-column: 1; grid-row: 2;">
<a class="name" href="https://www.jacobaustin.org/">Jacob Austin<sup>†</sup></a>
</p>
<p class="affiliation" style="grid-column: 3; grid-row: 2;">
<span class="affiliation"><sup>†</sup>Google DeepMind</span>
</p>
<p class="author" style="grid-column: 1; grid-row: 3;">
<a class="name" href="https://www.linkedin.com/in/swapnil-patil-5b47a068">Swapnil Patil<sup>†</sup></a>
</p>
<p class="affiliation" style="grid-column: 3; grid-row: 3;">
<span class="affiliation"></span>
</p>
<p class="author" style="grid-column: 2; grid-row: 2;">
<a class="name" href="https://x.com/apaszke">Adam Paszke<sup>†</sup></a>
</p>
<p class="affiliation" style="grid-column: 3; grid-row: 2;">
<span class="affiliation"></span>
</p>
<p class="author" style="grid-column: 2; grid-row: 3;">
<a class="name" href="https://x.com/reinerpope">Reiner Pope<sup>*</sup></a>
</p>
<p class="affiliation" style="grid-column: 3; grid-row: 3;">
<span class="affiliation"><sup>*</sup>MatX</span>
</p>
</div>
<div>
<h3>发布日期</h3>
<p>2025 年 8 月 18 日</p>
</div>
</div>
</d-byline> <d-article> <d-contents> <nav class="l-text figcaption"> <h3>目录</h3> <div> <a href="#what-is-a-gpu">什么是 GPU？</a> </div> <div> <a href="#"></a> </div> <ul> <li> <a href="#memory">内存</a> </li> <li> <a href="#summary-of-gpu-specs">GPU 规格摘要</a> </li> <li> <a href="#gpus-vs-tpus-at-the-chip-level">芯片层面上的 GPU 与 TPU 对比</a> </li> <li> <a href="#quiz-1-gpu-hardware">测验 1：GPU 硬件</a> </li> </ul> <div> <a href="#networking">网络</a> </div> <div> <a href="#"></a> </div> <ul> <li> <a href="#at-the-node-level">节点层面</a> </li> <li> <a href="#quiz-2-gpu-nodes">测验 2：GPU 节点</a> </li> <li> <a href="#beyond-the-node-level">超越节点层面</a> </li> <li> <a href="#quiz-3-beyond-the-node-level">测验 3：超越节点层面</a> </li> </ul> <div> <a href="#how-do-collectives-work-on-gpus">集合通信操作在 GPU 上如何工作？</a> </div> <div> <a href="#"></a> </div> <ul> <li> <a href="#intra-node-collectives">节点内集合通信</a> </li> <li> <a href="#cross-node-collectives">跨节点集合通信</a> </li> <li> <a href="#quiz-4-collectives">测验 4：集合通信</a> </li> </ul> <div> <a href="#rooflines-for-llm-scaling-on-gpus">GPU 上 LLM 扩展的屋顶线模型</a> </div> <div> <a href="#"></a> </div> <ul> <li> <a href="#data-parallelism">数据并行性</a> </li> <li> <a href="#tensor-parallelism">张量并行性</a> </li> <li> <a href="#expert-parallelism">专家并行性</a> </li> <li> <a href="#pipeline-parallelism">流水线并行性</a> </li> <li> <a href="#examples">示例</a> </li> <li> <a href="#tldr-of-llm-scaling-on-gpus">GPU 上 LLM 扩展总结</a> </li> <li> <a href="#quiz-5-llm-rooflines">测验 5：LLM 屋顶线模型</a> </li> </ul> <div> <a href="#acknowledgements-and-further-reading">致谢与延伸阅读</a> </div> <div> <a href="#appendix">附录</a> </div> <div> <a href="#"></a> </div> <ul> <li> <a href="#appendix-a-how-does-this-change-with-gb200">附录 A：GB200 会带来哪些变化？</a> </li> <li> <a href="#appendix-b-more-networking-details">附录 B：更多网络细节</a> </li> </ul> </nav> </d-contents> <h2 id="what-is-a-gpu">什么是 GPU？</h2> <p>现代的机器学习 GPU（例如 H100、B200）基本上是一堆专门用于矩阵乘法的计算核心（称为<strong>流式多处理器</strong>或 <strong>SM</strong>），连接到一块高速内存（称为 <strong>HBM</strong>）。下图是一个示意图：</p> <figure> <picture> <img class="img-fluid" height="auto" loading="lazy" onerror="this.onerror=null; $('.responsive-img-srcset').remove();" src="https://jax-ml.github.io/scaling-book/assets/gpu/gpu-diagram.png" width="100%"/> </picture> <figcaption class="caption"><b>图：</b>展示 H100 或 B200 GPU 抽象布局的示意图。H100 有 132 个 SM，而 B200 有 148 个。我们宽泛地使用术语“Warp 调度器”来描述一组 32 个 CUDA SIMD 核心<i>以及</i>向它们分派工作的调度器。请注意这与 TPU 的相似程度！</figcaption> </figure> <p>每个 SM，就像 TPU 的 TensorCore 一样，都有一个专用的矩阵乘法核心（不幸的是也叫 <strong>Tensor Core</strong><d-footnote id="d-footnote-1">GPU 的 Tensor Core 是 SM 的矩阵乘法子单元，而 TPU 的 TensorCore 是包含 MXU、VPU 和其他组件的总称单元。</d-footnote>）、一个向量算术单元（称为 <strong>Warp 调度器</strong><d-footnote id="d-footnote-2">NVIDIA 对此没有一个好的命名，所以我们只是在几个糟糕的选项中选择了最好的一个。Warp 调度器主要是向一组 CUDA 核心分派工作的单元，但我们在这里用它来描述控制单元和它所控制的核心集合。</d-footnote>）和一个快速的片上缓存（称为 <strong>SMEM</strong>）。与 TPU 最多只有 2 个独立的“Tensor Core”不同，现代 GPU 有超过 100 个 SM（H100 上有 132 个）。每个 SM 的功能远不及一个 TPU TensorCore，但整个系统更加灵活。每个 SM 或多或少是完全独立的，因此一个 GPU 可以同时执行数百个独立的任务。<d-footnote id="d-footnote-3">虽然 SM 是独立的，但为了达到峰值性能，它们通常被迫进行协调，因为它们都共享一个容量有限的 L2 缓存。</d-footnote></p> <p>让我们更详细地看一下 H100 的 SM：</p> <figure> <picture> <img class="img-small" height="auto" loading="lazy" onerror="this.onerror=null; $('.responsive-img-srcset').remove();" src="https://jax-ml.github.io/scaling-book/assets/gpu/blackwell-sm.png" width="100%"/> </picture> <figcaption class="caption"><b>图：</b>H100 SM 的示意图（<a href="https://wccftech.com/nvidia-hopper-gh100-gpu-official-5nm-process-worlds-fastest-hpc-chip-80-billion-transistors-hbm3-memory/" rel="external nofollow noopener" target="_blank">来源</a>），展示了 4 个<i>子分区</i>，每个分区包含一个 Tensor Core、Warp 调度器、寄存器文件和不同精度的 CUDA 核心组。底部的“L1 数据缓存”是 256kB 的 SMEM 单元。B200 看起来类似，但增加了大量的 Tensor Memory (TMEM) 来为庞大的 Tensor Core 提供数据。</figcaption> </figure> <p>每个 SM 分为 4 个相同的象限，NVIDIA 称之为 <strong>SM 子分区</strong>，每个子分区包含一个 Tensor Core、16k 个 32 位寄存器和一个称为 Warp 调度器的 SIMD/SIMT 向量算术单元，其通道（ALU）NVIDIA 称为 <strong>CUDA 核心</strong>。每个分区的核心组件可以说是 Tensor Core，它执行矩阵乘法并贡献了绝大部分的 FLOPs/s，但它并不是唯一值得注意的组件。</p> <ul> <li> <p><strong>CUDA 核心：</strong>每个子分区包含一组称为 CUDA 核心的 ALU，用于执行 SIMD/SIMT 向量算术。每个 ALU 通常每个周期可以执行 1 次算术操作，例如 f32.add。<d-footnote id="d-footnote-4">较新的 GPU 支持 FMA（融合乘加）指令，理论上每个周期执行两个 FLOPs，NVIDIA 无情地利用这一事实将其报告的规格翻倍。</d-footnote>每个子分区包含 32 个 fp32 核心（以及数量较少的 int32 和 fp64 核心），它们在每个周期内都执行相同的指令。与 TPU 的 VPU 类似，CUDA 核心负责执行 ReLU、逐点向量操作和归约（求和）。<d-footnote id="d-footnote-5">历史上，在引入 Tensor Core 之前，CUDA 核心是 GPU 的主要组件，用于渲染，包括光线-三角形相交和着色。在今天的游戏 GPU 上，它们仍然承担大部分渲染工作，而 TensorCore 用于上采样（DLSS），这使得 GPU 可以在较低分辨率下渲染（像素越少 = 工作量越少），然后使用机器学习进行上采样。</d-footnote></p> </li> <li> <p><strong>Tensor Core (TC)：</strong>每个子分区都有自己的 Tensor Core，它是一个专用的矩阵乘法单元，类似于 TPU 的 MXU。Tensor Core 占 GPU FLOPs/s 的绝大部分（例如，在 H100 上，我们有 990 bf16 TC TFLOP/s，而 CUDA 核心只有 66 TFLOPs/s）。</p> <ul> <li> <a href="https://www.nvidia.com/en-us/data-center/h100/" rel="external nofollow noopener" target="_blank">990 bf16 TFLOPs/s</a>，在 132 个 SM 以 1.76GHz 运行时，意味着每个 H100 TC 可以执行 <code class="language-plaintext highlighter-rouge">7.5e12 / 1.76e9 / 4 ~ 1024</code> bf16 FLOPs/周期，大约相当于一个 8x8x8 的矩阵乘法。<d-footnote id="d-footnote-6">NVIDIA 没有分享很多 TC 硬件细节，所以这更多的是猜测而非确切事实——当然，这并不能说明 TC 是如何实现的。我们知道 V100 每个 TC 每周期可以执行 256 FLOPs。A100 可以做到 512，H100 可以做到 1024，而 B200 的细节尚未公布，但似乎可能是 2048 FLOPs/TC/周期，因为 `2250e12 / (148 * 4 * 1.86e9)` 大约是 2048。更多细节在<a href="https://forums.developer.nvidia.com/t/how-to-calculate-the-tensor-core-fp16-performance-of-h100/244727" rel="external nofollow noopener" target="_blank">这里</a>得到确认。</d-footnote> </li> <li>与 TPU 类似，GPU 可以以更高的吞吐量执行较低精度的矩阵乘法（例如，H100 的 fp8 FLOPs/s 是 fp16 的 2 倍）。低精度训练或服务可以显著加快速度。</li> <li>自 Volta 以来的每一代 GPU 都增加了 TC 的尺寸（<a href="https://semianalysis.com/2025/06/23/nvidia-tensor-core-evolution-from-volta-to-blackwell/" rel="external nofollow noopener" target="_blank">关于这一点的好文章</a>）。到了 B200，TC 已经变得非常大，以至于其输入无法再装入 SMEM，因此 B200 引入了一个名为 TMEM 的新内存空间。<d-footnote id="d-footnote-7">在 Ampere 中，Tensor Core 可以由单个 warp 提供数据，而在 Hopper 中则需要一个完整的 SM（warpgroup），在 Blackwell 中则由 2 个 SM 提供数据。在 Blackwell 中，矩阵乘法也变得如此之大，以至于参数（特别是累加器）不再适合寄存器内存/SMEM，因此 Blackwell 增加了 TMEM 来解决这个问题。</d-footnote> </li> </ul> </li> </ul> <p><strong>CUDA 核心比 TPU 的 VPU 更灵活：</strong> GPU 的 CUDA 核心（自 V100 起）使用所谓的 SIMT（<em>单指令多线程</em>）编程模型，而 TPU 使用的是 SIMD（<em>单指令多数据</em>）模型。与 TPU VPU 中的 ALU 类似，一个子分区内的 CUDA 核心必须在每个周期内执行相同的操作（例如，如果一个核心在做两个浮点数相加，那么该子分区中的所有其他 CUDA 核心也必须这样做）。然而，与 VPU 不同的是，每个 CUDA 核心（或在 CUDA 编程模型中称为“线程”）都有自己的指令指针，并且可以被<em>独立</em>编程。当同一 warp 中的两个线程被指令执行不同的操作时，你实际上会执行<em>两种</em>操作，并屏蔽掉那些不需要执行分歧操作的核心。</p> <figure> <picture> <img class="img-fluid" height="auto" loading="lazy" onerror="this.onerror=null; $('.responsive-img-srcset').remove();" src="https://jax-ml.github.io/scaling-book/assets/gpu/warp-divergence.png" width="100%"/> </picture> <figcaption class="caption"><b>图：</b>一组线程内 warp 分歧的示例（<a href="https://images.nvidia.com/content/volta-architecture/pdf/volta-architecture-whitepaper.pdf" rel="external nofollow noopener" target="_blank">来源</a>）。白色区域表示至少一部分物理 CUDA 核心的停顿</figcaption> </figure> <p>这使得线程级别的编程非常灵活，但代价是如果 warp 分歧过于频繁，性能会悄无声息地下降。线程在访问内存方面也更加灵活；VPU 只能操作连续的内存块，而 CUDA 核心可以访问共享寄存器中的单个浮点数并维护每个线程的状态。</p> <p><strong>CUDA 核心调度也更加灵活：</strong> SM 的运行方式有点像多线程 CPU，因为它们可以并发地“调度”许多程序（<strong>warps</strong>）（每个 SM 最多 64 个），但每个 <em>Warp 调度器</em> 在每个时钟周期只执行一个程序。<d-footnote id="d-footnote-8">在给定 SM 上调度的 Warp 称为“驻留”。</d-footnote> Warp 调度器会自动在活动 warp 之间切换，以隐藏内存加载等 I/O 操作。相比之下，TPU 通常是单线程的。</p> <h3 id="memory">内存</h3> <p>除了计算单元，GPU 还有一个内存层次结构，最大的是 HBM（主 GPU 内存），然后是一系列较小的缓存（L2、L1/SMEM、TMEM、寄存器内存）。</p> <ul> <li> <strong>寄存器：</strong> 每个子分区都有自己的寄存器文件，在 H100/B200 上包含 16,384 个 32 位字（每个 SM <code class="language-plaintext highlighter-rouge">4 * 16384 * 4 = 256kiB</code>），可由 CUDA 核心访问。 <ul> <li>每个 CUDA 核心一次最多只能访问 256 个寄存器，所以尽管我们每个 SM 最多可以调度 64 个“驻留 warp”，但如果每个线程使用 256 个寄存器，你一次只能容纳 8 个（<code class="language-plaintext highlighter-rouge">256 * 1024 / (4 * 32 * 256)</code>）。</li> </ul> </li> <li> <p><strong>SMEM (L1 缓存)：</strong> 每个 SM 都有自己的 256kB 片上缓存，称为 SMEM，它可以由程序员控制为“共享内存”，也可以由硬件用作片上缓存。SMEM 用于存储激活值和 TC 矩阵乘法的输入。</p> </li> <li> <strong>L2 缓存：</strong> 所有 SM 共享<d-footnote id="d-footnote-9">技术上，L2 缓存被分成两半，因此在 H100 上，一半的 SM 可以各自访问 25MB。有一个连接这两半的链接，但带宽较低。</d-footnote>一个相对较大的约 50MB 的 L2 缓存，用于减少主内存访问。 <ul> <li>这在大小上与 TPU 的 VMEM 相似，但它<strong>慢得多</strong>，并且不受程序员控制。这导致了一些“超距幽灵作用”，程序员需要修改内存访问模式以确保 L2 缓存得到良好利用。<d-footnote id="d-footnote-10">L2 缓存被所有 SM 共享这一事实，实际上迫使程序员以一种相当协调的方式运行 SM，尽管原则上它们是独立的单元。</d-footnote> </li> <li>NVIDIA 没有公布其芯片的 L2 带宽，但据<a href="https://chipsandcheese.com/p/nvidias-h100-funny-l2-and-tons-of-bandwidth" rel="external nofollow noopener" target="_blank">测量</a>约为 5.5TB/s。这大约是 HBM 带宽的 1.6 倍，但它是全双工的，所以有效的双向带宽接近 3 倍。相比之下，TPU 的 VMEM 大 2 倍<em>并且</em>带宽要大得多（约 40TB/s）。</li> </ul> </li> <li> <strong>HBM：</strong> 主 GPU 内存，用于存储模型权重、梯度、激活值等。 <ul> <li>HBM 的大小从 Volta 的 32GB 大幅增加到 Blackwell (B200) 的 192GB。</li> <li>从 HBM 到 CUDA Tensor Core 的带宽称为 HBM 带宽或内存带宽，在 H100 上约为 3.35TB/s，在 B200 上约为 9TB/s。</li> </ul> </li> </ul> <h3 id="summary-of-gpu-specs">GPU 规格摘要</h3> <p>以下是近期 GPU 型号的规格摘要。不同版本的 GPU 的 SM 数量、时钟速度和 FLOPs 会有所不同。以下是内存容量数据：</p> <table class="table-hover" data-toggle="table"> <thead> <tr> <th style="text-align: center">GPU</th> <th style="text-align: center">代</th> <th style="text-align: center">时钟速度</th> <th style="text-align: center">SM/芯片</th> <th style="text-align: center">SMEM 容量/SM</th> <th style="text-align: center">L2 容量/芯片</th> <th style="text-align: center">HBM 容量/芯片</th> </tr> </thead> <tbody> <tr> <td style="text-align: center">V100</td> <td style="text-align: center">Volta</td> <td style="text-align: center">1.25GHz/1.38HGz</td> <td style="text-align: center">80</td> <td style="text-align: center">96kB</td> <td style="text-align: center">6MB</td> <td style="text-align: center">32GB</td> </tr> <tr> <td style="text-align: center">A100</td> <td style="text-align: center">Ampere</td> <td style="text-align: center">1.10GHz/1.41GHz</td> <td style="text-align: center">108</td> <td style="text-align: center">192kB</td> <td style="text-align: center">40MB</td> <td style="text-align: center">80GB</td> </tr> <tr> <td style="text-align: center">H100</td> <td style="text-align: center">Hopper</td> <td style="text-align: center">1.59GHz/1.98GHz</td> <td style="text-align: center">132</td> <td style="text-align: center">256kB</td> <td style="text-align: center">50MB</td> <td style="text-align: center">80GB</td> </tr> <tr> <td style="text-align: center">H200</td> <td style="text-align: center">Hopper</td> <td style="text-align: center">1.59GHz/1.98GHz</td> <td style="text-align: center">132</td> <td style="text-align: center">256kB</td> <td style="text-align: center">50MB</td> <td style="text-align: center">141GB</td> </tr> <tr> <td style="text-align: center">B200</td> <td style="text-align: center">Blackwell</td> <td style="text-align: center">?</td> <td style="text-align: center">148</td> <td style="text-align: center">256kB</td> <td style="text-align: center">126MB</td> <td style="text-align: center">192GB</td> </tr> </tbody> </table> <p>所有代次每个 SM 都有 256kB 的寄存器内存。Blackwell 每个 SM 还增加了 256kB 的 TMEM。以下是每个芯片的 FLOPs 和带宽数据：</p> <table class="table-hover" data-toggle="table"> <thead> <tr> <th style="text-align: center">GPU</th> <th style="text-align: center">代</th> <th style="text-align: center">HBM 带宽/芯片</th> <th style="text-align: center">FLOPs/s/芯片 (bf16/fp16)</th> <th style="text-align: center">FLOPs/s/芯片 (fp8/int8)</th> <th style="text-align: center">FLOPs/s/芯片 (fp4)</th> </tr> </thead> <tbody> <tr> <td style="text-align: center">V100</td> <td style="text-align: center">Volta</td> <td style="text-align: center">9.0e11</td> <td style="text-align: center">—</td> <td style="text-align: center">—</td> <td style="text-align: center">—</td> </tr> <tr> <td style="text-align: center">A100</td> <td style="text-align: center">Ampere</td> <td style="text-align: center">2.0e12</td> <td style="text-align: center">3.1e14</td> <td style="text-align: center">6.2e14</td> <td style="text-align: center">—</td> </tr> <tr> <td style="text-align: center">H100</td> <td style="text-align: center">Hopper</td> <td style="text-align: center">3.4e12</td> <td style="text-align: center">9.9e14</td> <td style="text-align: center">2.0e15</td> <td style="text-align: center">—</td> </tr> <tr> <td style="text-align: center">H200</td> <td style="text-align: center">Hopper</td> <td style="text-align: center">4.8e12</td> <td style="text-align: center">9.9e14</td> <td style="text-align: center">2.0e15</td> <td style="text-align: center">—</td> </tr> <tr> <td style="text-align: center">B200</td> <td style="text-align: center">Blackwell</td> <td style="text-align: center">8.0e12</td> <td style="text-align: center">2.3e15</td> <td style="text-align: center">4.5e15</td> <td style="text-align: center">9.0e15</td> </tr> </tbody> </table> <p>我们排除了 B100，因为它没有大规模生产。<d-footnote id="d-footnote-11">虽然 NVIDIA 制造了 B100 代，但它们只短暂销售和生产，据称是由于设计缺陷导致它们无法接近其声称的规格运行。它们在不因散热和功耗问题而降频的情况下难以达到峰值 FLOPs。</d-footnote> 一些规格会因 GPU 的具体版本而略有不同，因为 NVIDIA GPU 不像 TPU 那样标准化。</p> <p>这是一个有用的 GPU 和 TPU 组件对比备忘单：</p> <table class="table-hover" data-toggle="table"> <thead> <tr> <th style="text-align: center">GPU</th> <th style="text-align: center">TPU</th> <th style="text-align: center">它是什么？</th> </tr> </thead> <tbody> <tr> <td style="text-align: center">流式多处理器 (SM)</td> <td style="text-align: center">TensorCore</td> <td style="text-align: center">包含其他单元的核心“单元”</td> </tr> <tr> <td style="text-align: center">Warp 调度器</td> <td style="text-align: center">VPU</td> <td style="text-align: center">SIMD 向量算术单元</td> </tr> <tr> <td style="text-align: center">CUDA 核心</td> <td style="text-align: center">VPU ALU</td> <td style="text-align: center">SIMD ALU</td> </tr> <tr> <td style="text-align: center">SMEM (L1 缓存)</td> <td style="text-align: center">VMEM</td> <td style="text-align: center">快速片上缓存内存</td> </tr> <tr> <td style="text-align: center">Tensor Core</td> <td style="text-align: center">MXU</td> <td style="text-align: center">矩阵乘法单元</td> </tr> <tr> <td style="text-align: center">HBM (又名 GMEM)</td> <td style="text-align: center">HBM</td> <td style="text-align: center">高带宽大容量内存</td> </tr> </tbody> </table> <h3 id="gpus-vs-tpus-at-the-chip-level">芯片层面上的 GPU 与 TPU 对比</h3> <p>GPU 最初是用于渲染视频游戏的，但自从深度学习在 2010 年代兴起以来，它们越来越像专用的矩阵乘法机器——换句话说，越来越像 TPU。<d-footnote id="d-footnote-12">在深度学习热潮之前，GPU（“图形处理单元”）做的是，嗯，图形处理——主要是为了视频游戏。视频游戏用数百万个小三角形来表示物体，游戏将这些三角形渲染（或“光栅化”）成一个二维图像，每秒在屏幕上显示 30-60 次（这个频率称为帧率）。光栅化涉及将这些三角形投影到相机的坐标系中，并计算哪些三角形与哪些像素重叠，每秒数十亿次。可以想象，这是非常昂贵的，而这仅仅是开始。然后你必须通过组合可能与光线相交的几个半透明三角形的颜色来为每个像素着色。GPU 被设计用来极快地执行这些操作，并着眼于通用性；你需要同时运行许多不同的 GPU 工作负载（称为“着色器”），而没有任何单一操作占主导地位。因此，面向消费者的图形 GPU 可以进行矩阵乘法，但这并不是它们的主要功能。</d-footnote>在某种程度上，这段历史解释了为什么现代 GPU 是现在这个样子。它们并非纯粹为 LLM 或 ML 模型设计，而是作为通用加速器，硬件追求一定程度的“通用性”，这既是福也是祸。GPU 在应用于新任务时更常“开箱即用”，并且对优秀编译器的依赖远低于 TPU。但这也使得它们更难推理或获得屋顶线性能，因为太多的编译器特性可能导致瓶颈。</p> <p><strong>GPU 更加模块化。</strong> TPU 有 1-2 个大的 TensorCore，而 GPU 有数百个小的 SM。同样，每个 TensorCore 有 4 个大的 VPU，每个 VPU 有 1024 个 ALU，而 GPU 的 H100 有 132 * 4 = 528 个小的独立 SIMD 单元。以下是 GPU 与 TPU 的 1:1 比较，突出了这一点：</p> <table class="table-hover" data-toggle="table"> <thead> <tr> <th style="text-align: center">GPU</th> <th style="text-align: center">TPU</th> <th style="text-align: center">H100 #</th> <th style="text-align: center">TPU v5p #</th> </tr> </thead> <tbody> <tr> <td style="text-align: center">SM (流式多处理器)</td> <td style="text-align: center">TensorCore</td> <td style="text-align: center">132</td> <td style="text-align: center">2</td> </tr> <tr> <td style="text-align: center">Warp 调度器</td> <td style="text-align: center">VPU</td> <td style="text-align: center">528</td> <td style="text-align: center">8</td> </tr> <tr> <td style="text-align: center">SMEM (L1 缓存)</td> <td style="text-align: center">VMEM</td> <td style="text-align: center">32MB</td> <td style="text-align: center">128MB</td> </tr> <tr> <td style="text-align: center">寄存器</td> <td style="text-align: center">向量寄存器 (VRegs)</td> <td style="text-align: center">32MB</td> <td style="text-align: center">256kB</td> </tr> <tr> <td style="text-align: center">Tensor Core</td> <td style="text-align: center">MXU</td> <td style="text-align: center">528</td> <td style="text-align: center">8</td> </tr> </tbody> </table> <p>这种模块化上的差异一方面使得 TPU 的制造成本更低，理解起来更简单，但另一方面也给编译器带来了更大的负担，要求它做出正确的选择。因为 TPU 只有一个控制线程，并且只支持向量化的 VPU 级指令，编译器需要手动将所有内存加载和 MXU/VPU 工作流水线化以避免停顿。而 GPU 程序员可以轻松启动几十个不同的内核，每个内核都在完全独立的 SM 上运行。但另一方面，这些内核可能会因为 L2 缓存颠簸或未能合并内存加载而性能极差；因为硬件控制了大部分运行时，所以很难推理幕后发生了什么。因此，TPU 通常可以用更少的工作量更接近峰值屋顶线性能。</p> <p><strong>历史上，单个 GPU 比同类 TPU 更强大（也更昂贵）：</strong> 单个 H200 的 FLOPs/s 接近 TPU v5p 的 2 倍，HBM 是其 1.5 倍。同时，Google Cloud 上的标价约为 H200 每小时 <span>$</span>10，而 TPU v5p 每小时 <span>$</span>4。TPU 通常比 GPU 更依赖于将多个芯片联网在一起。</p> <p><strong>TPU 有更多的快速缓存内存。</strong> TPU 的 VMEM 也比 GPU 的 SMEM (+TMEM) 多得多，这些内存可以用来存储权重和激活值，使得它们可以被极快地加载和使用。如果能够持续地将模型权重存储或预取到 VMEM 中，这可以使它们在 LLM 推理方面更快。</p> <h3 id="quiz-1-gpu-hardware">测验 1：GPU 硬件</h3> <p>这里有一些练习题，用于测试上述内容。提供了答案，但在查看答案之前，最好手持纸笔尝试回答问题。</p> <p><strong>问题 1 [CUDA 核心]：</strong> 一个 H100 有多少个 fp32 CUDA 核心（ALU）？B200 呢？这与一个 TPU v5p 中的独立 ALU 数量相比如何？</p> <details><summary>点击此处查看答案。</summary> <p><strong>答案：</strong> 一个 H100 有 132 个 SM，每个 SM 有 4 个子分区，每个子分区包含 32 个 fp32 CUDA 核心，所以我们有 <code class="language-plaintext highlighter-rouge">132 * 4 * 32 = 16896</code> 个 CUDA 核心。一个 B200 有 <code class="language-plaintext highlighter-rouge">148</code> 个 SM，所以总共有 <code class="language-plaintext highlighter-rouge">18944</code> 个。一个 TPU v5p 有 2 个 TensorCore（通常通过 Megacore 连接），每个都有一个 VPU，具有 (8, 128) 个通道和每个通道 4 个独立的 ALU，所以有 <code class="language-plaintext highlighter-rouge">2 * 4 * 8 * 128 = 8192</code> 个 ALU。这大约是 H100 向量通道数量的一半，运行频率大致相同。</p> </details> <p><strong>问题 2 [向量 FLOPs 计算]</strong>：单个 H100 有 132 个 SM，时钟速度为 1.59GHz（最高可达 1.98GHz boost）。假设它每个 ALU 每个周期可以执行一次向量操作。每秒可以执行多少向量 fp32 FLOPs？使用 boost 呢？这与矩阵乘法 FLOPs 相比如何？</p> <details><summary>点击此处查看答案。</summary> <p><strong>答案：</strong> <code class="language-plaintext highlighter-rouge">132 * 4 * 32 * 1.59e9 = 26.9TFLOPs/s</code>。使用 boost 时为 33.5 TFLOPs/s。这是<a href="https://www.nvidia.com/en-us/data-center/h100/" rel="external nofollow noopener" target="_blank">规格表</a>中报告的一半，因为技术上我们可以在一个周期内执行一次 FMA（融合乘加），这算作两个 FLOPs，但这在大多数情况下并不实用。我们可以执行 990 bfloat16 矩阵乘法 TFLOPs/s，所以忽略 FMA，Tensor Core 的 FLOPs/s 大约是其 30 倍。</p> </details> <p><strong>问题 3 [GPU 矩阵乘法强度]：</strong> H100 上的峰值 fp16 矩阵乘法强度是多少？B200 呢？fp8 呢？<em>强度我们指的是矩阵乘法 FLOPs/s 与内存带宽的比率。</em></p> <details><summary>点击此处查看答案。</summary> <p><strong>答案：</strong> 对于 H100，我们有峰值 990e12 fp16 FLOPs 和 3.35e12 字节/秒的带宽。所以临界强度是 <code class="language-plaintext highlighter-rouge">990e12 / 3.35e12 = 295</code>，与 TPU 的 240 相当接近。对于 B200，它是 <code class="language-plaintext highlighter-rouge">2250e12 / 8e12 = 281</code>，非常相似。这意味着，与 TPU 类似，我们需要大约 280 的批处理大小才能在矩阵乘法中达到计算密集型。</p> <p>对于 H100 和 B200，我们的 fp8 FLOPs 都是 2 倍，所以峰值强度也翻倍到 590 和 562，尽管在某种意义上它保持不变，如果我们考虑到我们的权重也可能以 fp8 加载的话。</p> </details> <p><strong>问题 4 [矩阵乘法运行时]：</strong> 使用问题 3 的答案，你预计一个 <code class="language-plaintext highlighter-rouge">fp16[64, 4096] * fp16[4096, 8192]</code> 的矩阵乘法在单个 B200 上需要多长时间？<code class="language-plaintext highlighter-rouge">fp16[512, 4096] * fp16[4096, 8192]</code> 呢？</p> <details><summary>点击此处查看答案。</summary> <p>从上面我们知道，当批处理大小低于 281 个 token 时，我们会受通信限制。因此第一个完全受带宽限制。我们读取或写入 <d-math>2BD + 2DF + 2BF</d-math> 字节 (<code class="language-plaintext highlighter-rouge">2*64*4096 + 2*4096*8192 + 2*64*8192=69e6</code>)，带宽为 <code class="language-plaintext highlighter-rouge">8e12</code> 字节/秒，所以大约需要 <code class="language-plaintext highlighter-rouge">69e6 / 8e12 = 8.6us</code>。实际上我们可能只能获得总带宽的一部分，所以可能需要接近 10-12us。当我们增加批处理大小时，我们完全受计算限制，所以我们预计 <code class="language-plaintext highlighter-rouge">T=2*512*4096*8192/2.3e15=15us</code>。我们同样只期望获得总 FLOPs 的一部分，所以我们可能会看到接近 20us。</p> </details> <p><strong>问题 5 [L1 缓存容量]：</strong> H100 的总 L1/SMEM 容量是多少？寄存器内存呢？这与 TPU VMEM 容量相比如何？</p> <details><summary>点击此处查看答案。</summary> <p><strong>答案：</strong> 每个 SM 有 256kB 的 SMEM 和 256kB 的寄存器内存，所以每种大约 33MB (<code class="language-plaintext highlighter-rouge">132 * 256kB</code>)。加在一起，总共大约 66MB。这大约是现代 TPU 120MB VMEM 的一半，尽管一个 TPU 总共只有 256kB 的寄存器内存！TPU VMEM 的延迟低于 SMEM 的延迟，这也是为什么 TPU 上的寄存器内存不那么关键的原因之一（向 VMEM 的溢出和填充成本很低）。</p> </details> <p><strong>问题 6 [计算 B200 时钟频率]：</strong> NVIDIA 在<a href="https://resources.nvidia.com/en-us-blackwell-architecture" rel="external nofollow noopener" target="_blank">这里</a>报告说，一个 B200 可以执行 80TFLOPs/s 的向量 fp32 计算。鉴于每个 CUDA 核心可以在一个 FMA（融合乘加）操作中执行 2 FLOPs/周期，估算峰值时钟周期。</p> <details><summary>点击此处查看答案。</summary> <p><strong>答案：</strong> 我们知道我们有 148 * 4 * 32 = 18944 个 CUDA 核心，所以我们可以执行 <code class="language-plaintext highlighter-rouge">18944 * 2 = 37888 FLOPs / 周期</code>。因此 <code class="language-plaintext highlighter-rouge">80e12 / 37888 = 2.1GHz</code>，这是一个很高但合理的峰值时钟速度。B200 通常是液冷的，所以更高的时钟周期更合理。</p> </details> <p><strong>问题 7 [估算 H100 加法运行时]：</strong> 使用上面的数据，计算在单个 H100 上将两个 <code class="language-plaintext highlighter-rouge">fp32[N]</code> 向量相加需要多长时间。计算 <d-math>T_\text{math}</d-math> 和 <d-math>T_\text{comms}</d-math>。这个操作的算术强度是多少？如果你能访问到，也尝试在 PyTorch 或 JAX 中对 <code class="language-plaintext highlighter-rouge">N = 1024</code> 和 <code class="language-plaintext highlighter-rouge">N=1024 * 1024 * 1024</code> 运行这个操作。结果如何？</p> <details><summary>点击此处查看答案。</summary> <p><strong>答案：</strong> 首先，将两个 <code class="language-plaintext highlighter-rouge">fp32[N]</code> 向量相加执行 N FLOPs，需要加载 <code class="language-plaintext highlighter-rouge">4 * N * 2</code> 字节并写回 4 * N 字节，总共 <code class="language-plaintext highlighter-rouge">3 * 4 * N = 12N</code> 字节。计算它们的比率，我们得到 <code class="language-plaintext highlighter-rouge">总 FLOPs / 总字节数 = N / 12N = 1 / 12</code>，这相当糟糕。</p> <p>正如我们上面计算的，忽略 FMA，我们可以达到大约 33.5 TFLOPs/s 的 boost。这只有在所有 CUDA 核心都被使用的情况下才能实现。对于 <code class="language-plaintext highlighter-rouge">N = 1024</code>，我们最多只能使用 1024 个 CUDA 核心或 8 个 SM，这将花费更长的时间（假设我们受计算限制，大约长 16 倍）。我们还有 3.35e12 字节/秒的内存带宽。因此，我们的峰值硬件强度是 <code class="language-plaintext highlighter-rouge">33.5e12 / 3.35e12 = 10</code>。<d-footnote id="d-footnote-13">值得注意的是，这个强度在最近几代 GPU 中保持不变。对于 H100s 是 33.5 / 3.5，对于 B200 是 80 / 8。为什么会这样尚不清楚，但这是一个有趣的观察。</d-footnote> 所以我们将严重受通信限制。因此我们的运行时就是</p> <mjx-container class="MathJax CtxtMenu_Attached_0" ctxtmenu_counter="0" display="true" jax="CHTML" style="font-size: 116.9%; position: relative;" tabindex="0"><mjx-math aria-hidden="true" class="MJX-TEX" display="true" style="margin-left: 0px; margin-right: 0px;"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D447 TEX-I"></mjx-c></mjx-mi><mjx-mo class="mjx-n" space="4"><mjx-c class="mjx-c3D"></mjx-c></mjx-mo><mjx-mo class="mjx-n" space="4"><mjx-c class="mjx-c6D"></mjx-c><mjx-c class="mjx-c61"></mjx-c><mjx-c class="mjx-c78"></mjx-c></mjx-mo><mjx-mo class="mjx-n"><mjx-c class="mjx-c28"></mjx-c></mjx-mo><mjx-msub><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D447 TEX-I"></mjx-c></mjx-mi><mjx-script style="vertical-align: -0.15em; margin-left: -0.12em;"><mjx-mtext class="mjx-n" size="s"><mjx-c class="mjx-c63"></mjx-c><mjx-c class="mjx-c6F"></mjx-c><mjx-c class="mjx-c6D"></mjx-c><mjx-c class="mjx-c6D"></mjx-c><mjx-c class="mjx-c73"></mjx-c></mjx-mtext></mjx-script></mjx-msub><mjx-mo class="mjx-n"><mjx-c class="mjx-c2C"></mjx-c></mjx-mo><mjx-msub space="2"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D447 TEX-I"></mjx-c></mjx-mi><mjx-script style="vertical-align: -0.15em; margin-left: -0.12em;"><mjx-mtext class="mjx-n" size="s"><mjx-c class="mjx-c6D"></mjx-c><mjx-c class="mjx-c61"></mjx-c><mjx-c class="mjx-c74"></mjx-c><mjx-c class="mjx-c68"></mjx-c></mjx-mtext></mjx-script></mjx-msub><mjx-mo class="mjx-n"><mjx-c class="mjx-c29"></mjx-c></mjx-mo><mjx-mo class="mjx-n" space="4"><mjx-c class="mjx-c3D"></mjx-c></mjx-mo><mjx-mfrac space="4"><mjx-frac type="d"><mjx-num><mjx-nstrut type="d"></mjx-nstrut><mjx-mrow><mjx-mn class="mjx-n"><mjx-c class="mjx-c31"></mjx-c><mjx-c class="mjx-c32"></mjx-c></mjx-mn><mjx-mo class="mjx-n" space="3"><mjx-c class="mjx-c22C5"></mjx-c></mjx-mo><mjx-mi class="mjx-i" space="3"><mjx-c class="mjx-c1D441 TEX-I"></mjx-c></mjx-mi></mjx-mrow></mjx-num><mjx-dbox><mjx-dtable><mjx-line type="d"></mjx-line><mjx-row><mjx-den><mjx-dstrut type="d"></mjx-dstrut><mjx-mtext class="mjx-n"><mjx-c class="mjx-c33"></mjx-c><mjx-c class="mjx-c2E"></mjx-c><mjx-c class="mjx-c33"></mjx-c><mjx-c class="mjx-c35"></mjx-c><mjx-c class="mjx-c65"></mjx-c><mjx-c class="mjx-c31"></mjx-c><mjx-c class="mjx-c32"></mjx-c></mjx-mtext></mjx-den></mjx-row></mjx-dtable></mjx-dbox></mjx-frac></mjx-mfrac><mjx-mo class="mjx-n" space="4"><mjx-c class="mjx-c3D"></mjx-c></mjx-mo><mjx-mfrac space="4"><mjx-frac type="d"><mjx-num><mjx-nstrut type="d"></mjx-nstrut><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D441 TEX-I"></mjx-c></mjx-mi></mjx-num><mjx-dbox><mjx-dtable><mjx-line type="d"></mjx-line><mjx-row><mjx-den><mjx-dstrut type="d"></mjx-dstrut><mjx-mtext class="mjx-n"><mjx-c class="mjx-c32"></mjx-c><mjx-c class="mjx-c2E"></mjx-c><mjx-c class="mjx-c38"></mjx-c><mjx-c class="mjx-c65"></mjx-c><mjx-c class="mjx-c31"></mjx-c><mjx-c class="mjx-c31"></mjx-c></mjx-mtext></mjx-den></mjx-row></mjx-dtable></mjx-dbox></mjx-frac></mjx-mfrac></mjx-math><mjx-assistive-mml display="block" unselectable="on"><math display="block" xmlns="http://www.w3.org/1998/Math/MathML"><mi>T</mi><mo>=</mo><mo data-mjx-texclass="OP" movablelimits="true">max</mo><mo stretchy="false">(</mo><msub><mi>T</mi><mtext>comms</mtext></msub><mo>,</mo><msub><mi>T</mi><mtext>math</mtext></msub><mo stretchy="false">)</mo><mo>=</mo><mfrac><mrow><mn>12</mn><mo>⋅</mo><mi>N</mi></mrow><mtext>3.35e12</mtext></mfrac><mo>=</mo><mfrac><mi>N</mi><mtext>2.8e11</mtext></mfrac></math></mjx-assistive-mml></mjx-container> <p>对于 <code class="language-plaintext highlighter-rouge">N = 65,536</code>，这大约是 0.23us。实际上我们在 JAX 中看到的运行时大约是 1.5us，这没问题，因为我们预计在这里会受到严重的延迟限制。对于 <code class="language-plaintext highlighter-rouge">N = 1024 * 1024 * 1024</code>，我们的屋顶线大约是 3.84ms，我们看到的是 4.1ms，这很好！</p> </details> <h2 id="networking">网络</h2> <p>网络是 GPU 和 TPU 差异最大的领域之一。正如我们所见，TPU 以 2D 或 3D 环面连接，每个 TPU 只连接到其邻居。这意味着在两个 TPU 之间发送消息必须经过所有中间的 TPU，并迫使我们只能在网格上使用统一的通信模式。虽然在某些方面不方便，但这也意味着每个 TPU 的链接数量是恒定的，我们可以扩展到任意大的 TPU “pod” 而不损失带宽。</p> <p>另一方面，GPU 使用更传统的基于交换机的分层树状网络。一组 8 个 GPU 称为<strong>节点</strong>（对于 GB200 最多 72 个<d-footnote id="d-footnote-14">术语“节点”是重载的，可以指两件事：NVLink 域，即通过 NVLink 互连完全连接的 GPU 集合，或者连接到单个 CPU 主机的 GPU 集合。在 B200 之前，这两者通常是相同的，但在 GB200 NVL72 中，我们有一个包含 72 个 GPU 的 NVLink 域，但每个主机仍然只连接 8 个 GPU。我们在这里使用术语“节点”来指代 NVLink 域，但这有争议。</d-footnote>），它们通过称为 NVLink 的高带宽互连在 1 跳内连接，这些节点通过连接到每个 GPU 的 NIC 使用较低带宽的 InfiniBand (IB) 或以太网网络连接成更大的单元（称为 <strong>SU</strong> 或可扩展单元）。这些单元又可以通过更高级别的交换机连接成任意大的单元。</p> <figure> <picture> <img class="img-fluid" height="auto" loading="lazy" onerror="this.onerror=null; $('.responsive-img-srcset').remove();" src="https://jax-ml.github.io/scaling-book/assets/gpu/superpod-diagram.png" width="100%"/> </picture> <figcaption class="caption"><b>图：</b>一个典型 H100 网络的示意图。一组 8 个 GPU 通过 NVSwitches（也称为 NVLink 交换机）连接成一个节点或 NVLink 域，这些节点通过交换式 InfiniBand 结构相互连接。在 NVLink 域中，每个 H100 约有 450GB/s 的出口带宽，每个节点有 400GB/s 的出口带宽进入 IB 网络。</figcaption> </figure> <h3 id="at-the-node-level">节点层面</h3> <p>一个 GPU 节点是一个小单元，通常由 8 个 GPU（对于 GB200 最多 72 个）组成，通过全对全、全带宽、低延迟的 NVLink 互连连接。<d-footnote id="d-footnote-15">有人向我描述 NVLink 就像一个增强版的 PCIe 连接，具有低延迟和协议开销，但不是为可扩展性/容错性设计的，而 InfiniBand 更像以太网，专为更大的有损网络设计。</d-footnote>每个节点包含几个高带宽的 NVSwitches，用于在所有本地 GPU 之间交换数据包。实际的节点级拓扑随时间变化很大，包括每个节点的交换机数量，但对于 H100，我们每个节点有 4 个 NVSwitches，GPU 以 <code class="language-plaintext highlighter-rouge">5 + 4 + 4 + 5</code> 的链接模式连接到它们，如图所示：</p> <figure> <picture> <img class="img-fluid" height="auto" loading="lazy" onerror="this.onerror=null; $('.responsive-img-srcset').remove();" src="https://jax-ml.github.io/scaling-book/assets/gpu/nvlink-nodes.png" width="100%"/> </picture> <figcaption class="caption"><b>图：</b>从 Pascall (P100) 开始的节点（即 NVLink 域）示意图。自 Volta (V100) 以来，我们通过一组交换机在节点内实现了全对全连接。H100 节点有 4 个 NVSwitches，通过 25GB/s 的链接连接到所有 8 个 GPU。</figcaption> </figure> <p>对于 Hopper 代（NVLink 4.0），每个 NVLink 链接具有 25GB/s 的全双工<d-footnote id="d-footnote-16">这里的全双工意味着每个方向 25GB/s，两个方向相互独立。你可以在链路上总共发送 50GB/s，但每个方向最多 25GB/s。</d-footnote>带宽（B200 为 50GB/s），这使得每个 GPU 进入网络的带宽为 <code class="language-plaintext highlighter-rouge">18 * 25=450GB/s</code> 全双工。巨大的 NVSwitches 最多有 64 个 NVLink 端口，这意味着一个带有 4 个交换机的 8xH100 节点最多可以处理 <code class="language-plaintext highlighter-rouge">64 * 25e9 * 4=6.4TB/s</code> 的带宽。以下是这些数字随 GPU 代次变化的概述：</p> <table class="table-hover" data-toggle="table"> <thead> <tr> <th style="text-align: center">NVLink 代</th> <th style="text-align: center">NVSwitch 代</th> <th style="text-align: center">GPU 代</th> <th style="text-align: center">NVLink 带宽 (GB/s, 全双工)</th> <th style="text-align: center">NVLink 端口 / GPU</th> <th style="text-align: center">节点 GPU 间带宽 (GB/s 全双工)</th> <th style="text-align: center">节点大小 (NVLink 域)</th> <th style="text-align: center">NVSwitches / 节点</th> </tr> </thead> <tbody> <tr> <td style="text-align: center"><strong>3.0</strong></td> <td style="text-align: center"><strong>2.0</strong></td> <td style="text-align: center">Ampere</td> <td style="text-align: center">25</td> <td style="text-align: center">12</td> <td style="text-align: center">300</td> <td style="text-align: center">8</td> <td style="text-align: center">6</td> </tr> <tr> <td style="text-align: center"><strong>4.0</strong></td> <td style="text-align: center"><strong>3.0</strong></td> <td style="text-align: center">Hopper</td> <td style="text-align: center">25</td> <td style="text-align: center">18</td> <td style="text-align: center">450</td> <td style="text-align: center">8</td> <td style="text-align: center">4</td> </tr> <tr> <td style="text-align: center"><strong>5.0</strong></td> <td style="text-align: center"><strong>4.0</strong></td> <td style="text-align: center">Blackwell</td> <td style="text-align: center">50</td> <td style="text-align: center">18</td> <td style="text-align: center">900</td> <td style="text-align: center">8/72</td> <td style="text-align: center">2/18</td> </tr> </tbody> </table> <p>Blackwell (B200) 有 8 个 GPU 的节点。GB200NVL72 支持更大的 72 个 GPU 的 NVLink 域。我们展示了 8 GPU 和 72 GPU 系统的详细信息。</p> <h3 id="quiz-2-gpu-nodes">测验 2：GPU 节点</h3> <p>这里有更多关于网络的问题/解答。我发现亲自做这些特别有用，因为它们让你真正理解通信模式。</p> <p><strong>问题 1 [H100 节点的总带宽]：</strong> 在一个有 4 个交换机的 8xH100 节点中，我们每个节点有多少总带宽？<em>提示：</em>同时考虑 NVLink 和 NVSwitch 的带宽。</p> <details><summary>点击此处查看答案。</summary> <p><strong>答案：</strong> 我们有 Gen4 4xNVSwitches，每个具有 <code class="language-plaintext highlighter-rouge">64 * 25e9=1.6TB/s</code> 的单向带宽。这将在交换机层面给我们 <code class="language-plaintext highlighter-rouge">4 * 1.6e12=6.4e12</code> 的带宽。然而，请注意每个 GPU 只能处理 450GB/s 的单向带宽，这意味着我们最多有 <code class="language-plaintext highlighter-rouge">450e9 * 8 = 3.6TB/s</code> 的带宽。由于这个数字更小，峰值带宽是 3.6TB/s。</p> </details> <p><strong>问题 2 [对分带宽]</strong>：对分带宽定义为网络任意均分后可用的最小带宽。换句话说，如果将网络分成相等的两半，两半之间有多少带宽？你能计算出 8x H100 节点的对分带宽吗？<em>提示：</em>对分带宽通常包括双向流量。</p> <details><summary>点击此处查看答案。</summary> <p><strong>答案：</strong> 任何均分都会在每半边有 4 个 GPU，每个 GPU 可以向另一半输出 <code class="language-plaintext highlighter-rouge">4 * 450GB/s</code> 的流量。考虑到双向流量，这使得跨越分区的字节数为 <code class="language-plaintext highlighter-rouge">8 * 450GB/s</code>，即 3.6TB/s 的对分带宽。这与 NVIDIA 报告的相符，例如<a href="https://hc34.hotchips.org/assets/program/conference/day2/Network%20and%20Switches/NVSwitch%20HotChips%202022%20r5.pdf" rel="external nofollow noopener" target="_blank">这里</a>。</p> </details> <p><strong>问题 3 [AllGather 成本]</strong>：给定一个 B 字节的数组，一个（吞吐量受限的）AllGather 在 8xH100 节点上需要多长时间？对 bf16[D<sub>X</sub>, F] 进行计算，其中 <code class="language-plaintext highlighter-rouge">D=4096</code>，<code class="language-plaintext highlighter-rouge">F=65,536</code>。<em>在回答这个问题之前，值得阅读 TPU 集合通信<a href="sharding.html">部分</a>。在这里思考一下，但我们接下来会更详细地讨论集合通信。</em></p> <details><summary>点击此处查看答案。</summary> <p><strong>答案：</strong> 每个 GPU 可以输出 450GB/s，每个 GPU 有 <d-math>B / N</d-math> 字节（其中 <code class="language-plaintext highlighter-rouge">N=8</code>，节点大小）。我们可以想象每个节点将其字节一个接一个地发送给其他 <d-math>N - 1</d-math> 个节点，总共导致 (N - 1) 轮，每轮 <d-math>T_\text{comms} = (B / (N * W_\text{unidirectional}))</d-math>，或者 <d-math>T_\text{comms} = (N - 1) * B / (N * W_\text{unidirectional})</d-math>。这大约是 <d-math>B / (N * W_\text{uni})</d-math> 或 <d-math>B / \text{3.6e12}</d-math>，即对分带宽。</p> <p>对于给定的数组，我们有 <code class="language-plaintext highlighter-rouge">B=4096 * 65536 * 2=512MB</code>，所以总时间是 <code class="language-plaintext highlighter-rouge">536e6 * (8 - 1) / 3.6e12 = 1.04ms</code>。这可能是延迟受限的，所以实际上可能需要更长的时间（实际上大约需要 1.5ms）。</p> </details> <h2 id="beyond-the-node-level">超越节点层面</h2> <p>在节点层面之上，GPU 网络的拓扑结构不那么标准化。NVIDIA 发布了一个<a href="https://docs.nvidia.com/dgx-superpod/reference-architecture-scalable-infrastructure-h100/latest/network-fabrics.html" rel="external nofollow noopener" target="_blank">参考 DGX SuperPod 架构</a>，该架构使用 InfiniBand 连接比单个节点更多的 GPU，但客户和数据中心提供商可以根据自己的需求进行定制。<d-footnote id="d-footnote-17">例如，Meta 在一个与此描述显著不同的数据中心网络上训练了 LLaMA-3，该网络使用以太网、一个三层交换结构，并且在顶层有一个超额订阅的交换机。</d-footnote></p> <p>这是一个参考的 1024 GPU H100 系统的图表，其中底行的每个方框都是一个包含 8 个 GPU、8 个 400Gbps CX7 NIC（每个 GPU 一个）和 4 个 NVSwitches 的 8xH100 节点。</p> <figure> <picture> <img class="img-fluid" height="auto" loading="lazy" onerror="this.onerror=null; $('.responsive-img-srcset').remove();" src="https://jax-ml.github.io/scaling-book/assets/gpu/h100-superpod.png" width="100%"/> </picture> <figcaption class="caption"><b>图：</b>参考的 1024 H100 DGX SuperPod 图，包含 128 个节点（有时是 127 个），每个节点有 8 个 H100 GPU，连接到一个 InfiniBand 扩展网络。每 32 个节点（256 个 GPU）的集合称为“可扩展单元”或 SU。叶交换机和脊交换机 IB 交换机为节点间提供了足够的对分带宽。</figcaption> </figure> <p><strong>可扩展单元：</strong> 每组 32 个节点称为一个“可扩展单元”（或 SU），隶属于一组 8 个叶 InfiniBand 交换机。这个 SU 有 256 个 GPU，每个节点有 4 个 NVSwitches，还有 8 个 Infiniband 叶交换机。图中所示的所有布线都是 InfiniBand NDR（50GB/s 全双工），配备 64 端口 NDR IB 交换机（每个端口也是 50GB/s）。<em>请注意，IB 交换机的带宽是 NVSwitches 的 2 倍（64 个端口，每个端口 400 Gbps 链接）。</em></p> <p><strong>SuperPod：</strong> 整个 SuperPod 随后连接 4 个这样的 SU，配备 16 个顶层“脊”IB 交换机，总共给我们 1024 个 GPU，512 个节点级 NVSwitches，32 个叶 IB 交换机和 16 个脊 IB 交换机，总共有 512 + 32 + 16 = 560 个交换机。叶交换机以 32 个节点为一组连接到节点，所以每组 256 个 GPU 有 8 个叶交换机。所有叶交换机都连接到所有脊交换机。</p> <p><strong>我们有多少带宽？</strong> InfiniBand 网络（称为“扩展网络”）的整体拓扑结构是一个<strong>胖树</strong>，其电缆和交换机保证了节点级以上的完全对分带宽（这里是 400GB/s）。这意味着如果我们将节点分成两半，每个节点可以同时向另一分区中的节点输出 400GB/s。更重要的是，这意味着我们在扩展网络中应该有大致恒定的 AllReduce 带宽！虽然可能不是这样实现的，但你可以想象在任意数量的扩展网络节点上进行环形规约，因为你可以构建一个包含所有节点的环。</p> <table class="table-hover" data-toggle="table"> <thead> <tr> <th style="text-align: center">级别</th> <th style="text-align: center">GPU 数量</th> <th style="text-align: center">每单元交换机数</th> <th style="text-align: center">交换机类型</th> <th style="text-align: center">每单元带宽 (TB/s, 全双工)</th> <th style="text-align: center">GPU 间带宽 (GB/s, 全双工)</th> <th style="text-align: center">胖树带宽 (GB/s, 全双工)</th> </tr> </thead> <tbody> <tr> <td style="text-align: center">节点</td> <td style="text-align: center">8</td> <td style="text-align: center">4</td> <td style="text-align: center">NVL</td> <td style="text-align: center">3.6</td> <td style="text-align: center">450</td> <td style="text-align: center">450</td> </tr> <tr> <td style="text-align: center">叶</td> <td style="text-align: center">256</td> <td style="text-align: center">8</td> <td style="text-align: center">IB</td> <td style="text-align: center">12.8</td> <td style="text-align: center">50</td> <td style="text-align: center">400</td> </tr> <tr> <td style="text-align: center">脊</td> <td style="text-align: center">1024</td> <td style="text-align: center">16</td> <td style="text-align: center">IB</td> <td style="text-align: center">51.2</td> <td style="text-align: center">50</td> <td style="text-align: center">400</td> </tr> </tbody> </table> <p>相比之下，一个 TPU v5p 每个链接约有 90GB/s 的出口带宽，或者在 3D 环面的所有轴向上有 540GB/s 的出口带宽。这不是点对点的，所以只能用于受限的、统一的通信模式，但这仍然给我们提供了更高的 TPU 间带宽，可以扩展到任意大的拓扑结构（至少高达 8960 个 TPU）。</p> <p>理论上，GPU 交换结构可以通过增加额外的交换机或间接层来扩展到任意大小，但代价是增加延迟和昂贵的网络交换机。</p> <p class="takeaway"><strong>要点</strong>：在一个 H100 节点内，我们每个 GPU 有 450GB/s 的全胖树带宽，而在节点之外，这个带宽下降到 400GB/s 的节点间带宽。这对于通信原语来说至关重要。</p> <p><strong>GB200 NVL72s：</strong> NVIDIA 最近开始生产新的 GB200 NVL72 GPU 集群，将 72 个 GPU 组合在一个 NVLink 域中，具有完整的 900GB/s GPU 间带宽。这些域随后可以连接成更大的 SuperPod，具有成比例增加的（9 倍）IB 胖树带宽。以下是该拓扑的图表：</p> <figure> <picture> <img class="img-fluid" height="auto" loading="lazy" onerror="this.onerror=null; $('.responsive-img-srcset').remove();" src="https://jax-ml.github.io/scaling-book/assets/gpu/gb200-superpod.png" width="100%"/> </picture> <figcaption class="caption"><b>图：</b>一个包含 576 个 GPU 的 GB200 DGX SuperPod 的示意图。底层每个机架包含 72 个 GB200 GPU。</figcaption> </figure> <p>计算单个节点（上图中的橙色线）的出口带宽，我们有 <code class="language-plaintext highlighter-rouge">4 * 18 * 400 / 8 = 3.6TB/s</code> 到叶级别的带宽，这比 H100 多 9 倍（正如节点包含 9 倍多的 GPU）。这意味着关键的节点出口带宽要高得多，我们的跨节点集合通信带宽实际上可能比节点内的要<em>低</em>。更多讨论请参见<a href="#appendix-a-how-does-this-change-with-gb200">附录 A</a>。</p> <table class="table-hover" data-toggle="table"> <thead> <tr> <th style="text-align: center">节点类型</th> <th style="text-align: center">每节点 GPU 数</th> <th style="text-align: center">GPU 出口带宽</th> <th style="text-align: center">节点出口带宽</th> </tr> </thead> <tbody> <tr> <td style="text-align: center">H100</td> <td style="text-align: center">8</td> <td style="text-align: center">450e9</td> <td style="text-align: center">400e9</td> </tr> <tr> <td style="text-align: center">B200</td> <td style="text-align: center">8</td> <td style="text-align: center">900e9</td> <td style="text-align: center">400e9</td> </tr> <tr> <td style="text-align: center">GB200 NVL72</td> <td style="text-align: center">72</td> <td style="text-align: center">900e9</td> <td style="text-align: center">3600e9</td> </tr> </tbody> </table> <p class="takeaway"><strong>要点</strong>：GB200 NVL72 SuperPods 极大地增加了节点大小和给定节点的出口带宽，这显著改变了我们的屋顶线模型。</p> <h3 id="quiz-3-beyond-the-node-level">测验 3：超越节点层面</h3> <p><strong>问题 1 [胖树拓扑]：</strong> 使用上面的 DGX H100 图，计算整个 1024 GPU pod 在节点级别的对分带宽。证明每个链接的带宽选择是为了确保完全的对分带宽。<em>提示：确保计算链接带宽和交换机带宽。</em></p> <details><summary>点击此处查看答案。</summary> <p><strong>答案：</strong> 让我们逐个组件来分析：</p> <ul> <li>首先，每个节点有 8x400Gbps NDR IB 电缆连接到叶交换机，给每个节点 <code class="language-plaintext highlighter-rouge">8 * 400 / 8 = 400 GB/s</code> 的到叶的带宽。我们有 8 个叶交换机，每个 3.2TB/s（64 个 400 GBps 链接），但我们只能使用 64 个端口中的 32 个从 SU 输入，所以那是 <code class="language-plaintext highlighter-rouge">32 * 400 / 8 = 12.8TB/s</code> 用于 32 个节点，同样是每个节点 400GB/s。</li> <li>然后在脊级别，我们有 <code class="language-plaintext highlighter-rouge">8 * 16 * 2</code> 400Gbps NDR IB 电缆连接每个 SU 到脊，给每个 SU <code class="language-plaintext highlighter-rouge">8 * 16 * 2 * 400 / 8 = 12.8 TB/s</code> 的到叶的带宽。同样，这是每个节点 400GB/s。我们有 16 个脊交换机，每个 3.2TB/s，给我们 <code class="language-plaintext highlighter-rouge">16 * 3.2 = 51.2 TB/s</code>，对于 128 个节点，这又是 400GB/s。</li> </ul> <p>因此，如果我们以任何方式对分我们的节点，它们之间将有每个 GPU 400GB/s 的带宽。每个组件都恰好有确保胖树所需的带宽。</p> </details> <p><strong>问题 2 [扩展到更大的 DGX pod]：</strong> 假设我们想在 2048 个 GPU 而不是 1024 个上进行训练。修改上述 DGX 拓扑以处理这个问题的最简单/最好的方法是什么？4096 个呢？<em>提示：没有唯一的正确答案，但尽量降低成本。记住链接容量。<a href="https://docs.nvidia.com/dgx-superpod-reference-architecture-dgx-h100.pdf" rel="external nofollow noopener" target="_blank">这篇</a>文档可能会有帮助。</em></p> <details><summary>点击此处查看答案。</summary> <p><strong>答案：</strong> 一个选项是保持 SU 结构不变（32 个节点在 8 个交换机下），然后用更多的顶层交换机增加更多的 SU。我们需要 2 倍多的脊交换机，所以我们将有 8 个 SU 和 32 个脊交换机，给我们足够的带宽。</p> <p>这样做的一个问题是，每个叶交换机只有 64 个端口，我们在上面的图表中已经全部使用了。但实际上，每个脊使用 1x 400 Gbps NDR 电缆而不是 2x 是很容易的，这提供了相同的总带宽但为我们节省了一些端口。</p> <p>对于 4096 个 GPU，我们实际上用完了端口，所以我们需要增加另一个间接层，也就是说，在层次结构中增加一个级别。NVIDIA 称这些为“核心交换机”，并用 128 个脊交换机和 64 个核心交换机构建一个 4096 GPU 集群。你可以计算一下，这提供了足够的带宽。</p> </details> <h2 id="how-do-collectives-work-on-gpus">集合通信操作在 GPU 上如何工作？</h2> <p>GPU 可以执行与 TPU 相同的所有集合通信操作：ReduceScatters、AllGathers、AllReduces 和 AllToAlls。与 TPU 不同，这些操作的工作方式取决于它们是在节点级别（通过 NVLink）还是在更高级别（通过 InfiniBand）执行。这些集合通信由 NVIDIA 在 <a href="https://developer.nvidia.com/nvshmem" rel="external nofollow noopener" target="_blank">NVSHMEM</a> 和 <a href="https://developer.nvidia.com/nccl" rel="external nofollow noopener" target="_blank">NCCL</a>（发音为“nickel”）库中实现。NCCL 是开源的，<a href="https://github.com/NVIDIA/nccl" rel="external nofollow noopener" target="_blank">在这里</a>。虽然 NCCL 根据延迟要求/拓扑使用多种实现（<a href="https://github.com/NVIDIA/nccl/issues/1415#issuecomment-2310650081" rel="external nofollow noopener" target="_blank">详情</a>），但从现在开始，我们将讨论一个在交换树结构上的理论最优模型。</p> <h3 id="intra-node-collectives">节点内集合通信</h3> <p><strong>AllGather 或 ReduceScatter：</strong> 对于节点级别的 AllGather 或 ReduceScatter，你可以像 TPU 一样围绕一个环执行它们，在每一跳都使用完整的 GPU 间带宽。任意排序 GPU，并使用完整的 GPU 间带宽将数组的一部分沿环发送。<d-footnote id="d-footnote-18">你也可以认为每个 GPU 将其大小为 <d-math>\text{bytes} / N</d-math> 的块发送给其他 <d-math>N - 1</d-math> 个 GPU，总共通信了 <d-math>(N - 1) * N * bytes / N</d-math> 字节，这给了我们</d-footnote> 每一跳的成本是 <d-math>T_\text{hop} = \text{bytes} / (N * \text{GPU 出口带宽})</d-math>，所以总成本是</p><span> <mjx-container class="MathJax CtxtMenu_Attached_0" ctxtmenu_counter="1" display="true" jax="CHTML" style="font-size: 116.9%; position: relative;" tabindex="0"><mjx-math aria-hidden="true" class="MJX-TEX" display="true" style="margin-left: 0px; margin-right: 0px;"><mjx-msub><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D447 TEX-I"></mjx-c></mjx-mi><mjx-script style="vertical-align: -0.153em; margin-left: -0.12em;"><mjx-mtext class="mjx-n" size="s"><mjx-c class="mjx-c41"></mjx-c><mjx-c class="mjx-c47"></mjx-c><mjx-c class="mjx-c20"></mjx-c><mjx-c class="mjx-c6F"></mjx-c><mjx-c class="mjx-c72"></mjx-c><mjx-c class="mjx-c20"></mjx-c><mjx-c class="mjx-c52"></mjx-c><mjx-c class="mjx-c53"></mjx-c><mjx-c class="mjx-c20"></mjx-c><mjx-c class="mjx-c63"></mjx-c><mjx-c class="mjx-c6F"></mjx-c><mjx-c class="mjx-c6D"></mjx-c><mjx-c class="mjx-c6D"></mjx-c><mjx-c class="mjx-c73"></mjx-c></mjx-mtext></mjx-script></mjx-msub><mjx-mo class="mjx-n" space="4"><mjx-c class="mjx-c3D"></mjx-c></mjx-mo><mjx-mfrac space="4"><mjx-frac type="d"><mjx-num><mjx-nstrut type="d"></mjx-nstrut><mjx-mrow><mjx-mtext class="mjx-n"><mjx-c class="mjx-c62"></mjx-c><mjx-c class="mjx-c79"></mjx-c><mjx-c class="mjx-c74"></mjx-c><mjx-c class="mjx-c65"></mjx-c><mjx-c class="mjx-c73"></mjx-c></mjx-mtext><mjx-mo class="mjx-n" space="3"><mjx-c class="mjx-c22C5"></mjx-c></mjx-mo><mjx-mo class="mjx-n" space="3"><mjx-c class="mjx-c28"></mjx-c></mjx-mo><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D441 TEX-I"></mjx-c></mjx-mi><mjx-mo class="mjx-n" space="3"><mjx-c class="mjx-c2212"></mjx-c></mjx-mo><mjx-mn class="mjx-n" space="3"><mjx-c class="mjx-c31"></mjx-c></mjx-mn><mjx-mo class="mjx-n"><mjx-c class="mjx-c29"></mjx-c></mjx-mo></mjx-mrow></mjx-num><mjx-dbox><mjx-dtable><mjx-line type="d"></mjx-line><mjx-row><mjx-den><mjx-dstrut type="d"></mjx-dstrut><mjx-mrow><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D441 TEX-I"></mjx-c></mjx-mi><mjx-mo class="mjx-n" space="3"><mjx-c class="mjx-c22C5"></mjx-c></mjx-mo><mjx-mtext class="mjx-n" space="3"><mjx-c class="mjx-c47"></mjx-c><mjx-c class="mjx-c50"></mjx-c><mjx-c class="mjx-c55"></mjx-c><mjx-c class="mjx-c20"></mjx-c><mjx-c class="mjx-c65"></mjx-c><mjx-c class="mjx-c67"></mjx-c><mjx-c class="mjx-c72"></mjx-c><mjx-c class="mjx-c65"></mjx-c><mjx-c class="mjx-c73"></mjx-c><mjx-c class="mjx-c73"></mjx-c><mjx-c class="mjx-c20"></mjx-c><mjx-c class="mjx-c62"></mjx-c><mjx-c class="mjx-c61"></mjx-c><mjx-c class="mjx-c6E"></mjx-c><mjx-c class="mjx-c64"></mjx-c><mjx-c class="mjx-c77"></mjx-c><mjx-c class="mjx-c69"></mjx-c><mjx-c class="mjx-c64"></mjx-c><mjx-c class="mjx-c74"></mjx-c><mjx-c class="mjx-c68"></mjx-c></mjx-mtext></mjx-mrow></mjx-den></mjx-row></mjx-dtable></mjx-dbox></mjx-frac></mjx-mfrac><mjx-mo class="mjx-n" space="4"><mjx-c class="mjx-c2192"></mjx-c></mjx-mo><mjx-mfrac space="4"><mjx-frac type="d"><mjx-num><mjx-nstrut type="d"></mjx-nstrut><mjx-mtext class="mjx-n"><mjx-c class="mjx-c62"></mjx-c><mjx-c class="mjx-c79"></mjx-c><mjx-c class="mjx-c74"></mjx-c><mjx-c class="mjx-c65"></mjx-c><mjx-c class="mjx-c73"></mjx-c></mjx-mtext></mjx-num><mjx-dbox><mjx-dtable><mjx-line type="d"></mjx-line><mjx-row><mjx-den><mjx-dstrut type="d"></mjx-dstrut><mjx-mtext class="mjx-n"><mjx-c class="mjx-c47"></mjx-c><mjx-c class="mjx-c50"></mjx-c><mjx-c class="mjx-c55"></mjx-c><mjx-c class="mjx-c20"></mjx-c><mjx-c class="mjx-c65"></mjx-c><mjx-c class="mjx-c67"></mjx-c><mjx-c class="mjx-c72"></mjx-c><mjx-c class="mjx-c65"></mjx-c><mjx-c class="mjx-c73"></mjx-c><mjx-c class="mjx-c73"></mjx-c><mjx-c class="mjx-c20"></mjx-c><mjx-c class="mjx-c62"></mjx-c><mjx-c class="mjx-c61"></mjx-c><mjx-c class="mjx-c6E"></mjx-c><mjx-c class="mjx-c64"></mjx-c><mjx-c class="mjx-c77"></mjx-c><mjx-c class="mjx-c69"></mjx-c><mjx-c class="mjx-c64"></mjx-c><mjx-c class="mjx-c74"></mjx-c><mjx-c class="mjx-c68"></mjx-c></mjx-mtext></mjx-den></mjx-row></mjx-dtable></mjx-dbox></mjx-frac></mjx-mfrac></mjx-math><mjx-assistive-mml display="block" unselectable="on"><math display="block" xmlns="http://www.w3.org/1998/Math/MathML"><msub><mi>T</mi><mtext>AG or RS comms</mtext></msub><mo>=</mo><mfrac><mrow><mtext>bytes</mtext><mo>⋅</mo><mo stretchy="false">(</mo><mi>N</mi><mo>−</mo><mn>1</mn><mo stretchy="false">)</mo></mrow><mrow><mi>N</mi><mo>⋅</mo><mtext>GPU egress bandwidth</mtext></mrow></mfrac><mo stretchy="false">→</mo><mfrac><mtext>bytes</mtext><mtext>GPU egress bandwidth</mtext></mfrac></math></mjx-assistive-mml></mjx-container> </span><p>你会注意到这和 TPU 上完全一样。对于 AllReduce，你可以像往常一样组合一个 RS + AG，成本是两倍。</p> <figure> <picture> <img class="img-fluid" height="auto" loading="lazy" onerror="this.onerror=null; $('.responsive-img-srcset').remove();" src="https://jax-ml.github.io/scaling-book/assets/gpu/all-gather.gif" width="100%"/> </picture> <figcaption class="caption"><b>图：</b>带宽最优的 1D 环形 AllGather 算法。对于 B 字节，这将在顶层交换机上传输 V / X 字节 X - 1 次。</figcaption> </figure> <p>如果你担心延迟（例如，如果你的数组很小），你可以做一个树形规约，即在 2、4、8 对内进行 AllReduce，总共有 <d-math>\log(N)</d-math> 跳而不是 <d-math>N - 1</d-math> 跳，尽管总成本仍然相同。</p> <p class="takeaway"><strong>要点：</strong>在一个节点内对 B 字节的数组进行 AllGather 或 ReduceScatter 的成本大约是 <d-math>T_\text{comms} = B * (8 - 1) / (8 * W_\text{GPU egress}) \approxeq B / W_\text{GPU egress}</d-math>。理论上，在 H100 上这大约是 <d-math>B / \text{450e9}</d-math>，在 B200 上是 <d-math>B / \text{900e9}</d-math>。除非启用了网络内规约，否则 AllReduce 的成本是这个的两倍。</p> <p><b style="color: #57cf57;">即时测验 1 [AllGather 时间]：</b>使用一个具有 450 GB/s 全双工带宽的 8xH100 节点，AllGather(bf16[B<sub>X</sub>, F]) 需要多长时间？设 <d-math>B=1024</d-math>，<d-math>F=16,384</d-math>。</p> <details><summary>点击此处查看答案。</summary> <p><strong>答案：</strong> 我们总共有 <d-math>2 \cdot B \cdot F</d-math> 字节，单向带宽为 450e9。这大约需要 <d-math>T_\text{comms} = (2 \cdot B \cdot F) / \text{450e9}</d-math>，或者更精确地说是 <d-math>(2 \cdot B \cdot F \cdot (8 - 1)) / (8 \cdot \text{450e9})</d-math>。使用给定的值，这大约是 <d-math>(2 \cdot 1024 \cdot 16384) / \text{450e9} = \text{75us}</d-math>，或者更精确地说是 <d-math>\text{65us}</d-math>。</p> </details> <p><strong>AllToAlls：</strong> 节点内的 GPU 具有全对全连接性，这使得 AllToAlls 非常容易。每个 GPU 只需直接发送到目标节点。在一个节点内，对于 B 字节，每个 GPU 有 <d-math>B / N</d-math> 字节，并向 <d-math>N - 1</d-math> 个目标节点发送 <d-math>(B / N^2)</d-math> 字节，总共是</p><span> <mjx-container class="MathJax CtxtMenu_Attached_0" ctxtmenu_counter="2" display="true" jax="CHTML" style="font-size: 116.9%; position: relative;" tabindex="0"><mjx-math aria-hidden="true" class="MJX-TEX" display="true" style="margin-left: 0px; margin-right: 0px;"><mjx-msub><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D447 TEX-I"></mjx-c></mjx-mi><mjx-script style="vertical-align: -0.153em; margin-left: -0.12em;"><mjx-mtext class="mjx-n" size="s"><mjx-c class="mjx-c41"></mjx-c><mjx-c class="mjx-c6C"></mjx-c><mjx-c class="mjx-c6C"></mjx-c><mjx-c class="mjx-c54"></mjx-c><mjx-c class="mjx-c6F"></mjx-c><mjx-c class="mjx-c41"></mjx-c><mjx-c class="mjx-c6C"></mjx-c><mjx-c class="mjx-c6C"></mjx-c><mjx-c class="mjx-c20"></mjx-c><mjx-c class="mjx-c63"></mjx-c><mjx-c class="mjx-c6F"></mjx-c><mjx-c class="mjx-c6D"></mjx-c><mjx-c class="mjx-c6D"></mjx-c><mjx-c class="mjx-c73"></mjx-c></mjx-mtext></mjx-script></mjx-msub><mjx-mo class="mjx-n" space="4"><mjx-c class="mjx-c3D"></mjx-c></mjx-mo><mjx-mfrac space="4"><mjx-frac type="d"><mjx-num><mjx-nstrut type="d"></mjx-nstrut><mjx-mrow><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D435 TEX-I"></mjx-c></mjx-mi><mjx-mo class="mjx-n" space="3"><mjx-c class="mjx-c22C5"></mjx-c></mjx-mo><mjx-mo class="mjx-n" space="3"><mjx-c class="mjx-c28"></mjx-c></mjx-mo><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D441 TEX-I"></mjx-c></mjx-mi><mjx-mo class="mjx-n" space="3"><mjx-c class="mjx-c2212"></mjx-c></mjx-mo><mjx-mn class="mjx-n" space="3"><mjx-c class="mjx-c31"></mjx-c></mjx-mn><mjx-mo class="mjx-n"><mjx-c class="mjx-c29"></mjx-c></mjx-mo></mjx-mrow></mjx-num><mjx-dbox><mjx-dtable><mjx-line type="d"></mjx-line><mjx-row><mjx-den><mjx-dstrut type="d"></mjx-dstrut><mjx-mrow><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D44A TEX-I"></mjx-c></mjx-mi><mjx-mo class="mjx-n" space="3"><mjx-c class="mjx-c22C5"></mjx-c></mjx-mo><mjx-msup space="3"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D441 TEX-I"></mjx-c></mjx-mi><mjx-script style="vertical-align: 0.289em; margin-left: 0.054em;"><mjx-mn class="mjx-n" size="s"><mjx-c class="mjx-c32"></mjx-c></mjx-mn></mjx-script></mjx-msup></mjx-mrow></mjx-den></mjx-row></mjx-dtable></mjx-dbox></mjx-frac></mjx-mfrac><mjx-mo class="mjx-n" space="4"><mjx-c class="mjx-c2248"></mjx-c></mjx-mo><mjx-mfrac space="4"><mjx-frac type="d"><mjx-num><mjx-nstrut type="d"></mjx-nstrut><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D435 TEX-I"></mjx-c></mjx-mi></mjx-num><mjx-dbox><mjx-dtable><mjx-line type="d"></mjx-line><mjx-row><mjx-den><mjx-dstrut type="d"></mjx-dstrut><mjx-mrow><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D44A TEX-I"></mjx-c></mjx-mi><mjx-mo class="mjx-n" space="3"><mjx-c class="mjx-c22C5"></mjx-c></mjx-mo><mjx-mi class="mjx-i" space="3"><mjx-c class="mjx-c1D441 TEX-I"></mjx-c></mjx-mi></mjx-mrow></mjx-den></mjx-row></mjx-dtable></mjx-dbox></mjx-frac></mjx-mfrac></mjx-math><mjx-assistive-mml display="block" unselectable="on"><math display="block" xmlns="http://www.w3.org/1998/Math/MathML"><msub><mi>T</mi><mtext>AllToAll comms</mtext></msub><mo>=</mo><mfrac><mrow><mi>B</mi><mo>⋅</mo><mo stretchy="false">(</mo><mi>N</mi><mo>−</mo><mn>1</mn><mo stretchy="false">)</mo></mrow><mrow><mi>W</mi><mo>⋅</mo><msup><mi>N</mi><mn>2</mn></msup></mrow></mfrac><mo>≈</mo><mfrac><mi>B</mi><mrow><mi>W</mi><mo>⋅</mo><mi>N</mi></mrow></mfrac></math></mjx-assistive-mml></mjx-container> </span><p>与 TPU 相比，TPU 的成本是 <d-math>B / (4W)</d-math>。因此，在单个节点内，我们在运行时间上获得了 2 倍的理论加速（<d-math>B / 4W</d-math> vs. <d-math>B / 8W</d-math>）。</p> <p>对于专家混合 (MoE) 模型，我们经常需要进行<em>稀疏或不规则的 AllToAll，</em>我们保证输出维度上的 <d-math>N</d-math> 个分片中最多有 <d-math>k</d-math> 个是非零的，也就是说 <d-math>T_\text{AllToAll}_X \rightarrow K[B, N]</d-math>，其中每个轴上最多有 <d-math>k</d-math> 个 <d-math>N</d-math> 个条目是非零的。这个成本降低了 <d-math>k/N</d-math>，总共大约是 <d-math>\min(k/N, 1) \cdot B / (W \cdot N)</d-math>。对于一个 MoE，我们通常独立随机地选择非零值，所以有一定几率有少于 <d-math>k</d-math> 个非零值，给我们大约 <d-math>(N-1)/N \cdot \min(k/N, 1) \cdot B / (W \cdot N)</d-math>。<d-footnote id="d-footnote-19">真实成本实际上是 <mjx-container class="MathJax CtxtMenu_Attached_0" ctxtmenu_counter="3" display="true" jax="CHTML" style="font-size: 113.1%; position: relative;" tabindex="0"><mjx-math aria-hidden="true" class="MJX-TEX" display="true" style="margin-left: 0px; margin-right: 0px;"><mjx-mo class="mjx-n"><mjx-c class="mjx-c28"></mjx-c></mjx-mo><mjx-mn class="mjx-n"><mjx-c class="mjx-c31"></mjx-c></mjx-mn><mjx-mo class="mjx-n" space="3"><mjx-c class="mjx-c2212"></mjx-c></mjx-mo><mjx-msup space="3"><mjx-mrow><mjx-mo class="mjx-s3"><mjx-c class="mjx-c28 TEX-S3"></mjx-c></mjx-mo><mjx-mfrac><mjx-frac type="d"><mjx-num><mjx-nstrut type="d"></mjx-nstrut><mjx-mrow><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D44D TEX-I"></mjx-c></mjx-mi><mjx-mo class="mjx-n" space="3"><mjx-c class="mjx-c2212"></mjx-c></mjx-mo><mjx-mn class="mjx-n" space="3"><mjx-c class="mjx-c31"></mjx-c></mjx-mn></mjx-mrow></mjx-num><mjx-dbox><mjx-dtable><mjx-line type="d"></mjx-line><mjx-row><mjx-den><mjx-dstrut type="d"></mjx-dstrut><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D44D TEX-I"></mjx-c></mjx-mi></mjx-den></mjx-row></mjx-dtable></mjx-dbox></mjx-frac></mjx-mfrac><mjx-mo class="mjx-s3"><mjx-c class="mjx-c29 TEX-S3"></mjx-c></mjx-mo></mjx-mrow><mjx-script style="vertical-align: 1.177em;"><mjx-mi class="mjx-i" size="s"><mjx-c class="mjx-c1D43E TEX-I"></mjx-c></mjx-mi></mjx-script></mjx-msup><mjx-mo class="mjx-n"><mjx-c class="mjx-c29"></mjx-c></mjx-mo><mjx-mo class="mjx-n" space="3"><mjx-c class="mjx-c22C5"></mjx-c></mjx-mo><mjx-mfrac space="3"><mjx-frac type="d"><mjx-num><mjx-nstrut type="d"></mjx-nstrut><mjx-mrow><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D44D TEX-I"></mjx-c></mjx-mi><mjx-mo class="mjx-n" space="3"><mjx-c class="mjx-c2212"></mjx-c></mjx-mo><mjx-mn class="mjx-n" space="3"><mjx-c class="mjx-c31"></mjx-c></mjx-mn></mjx-mrow></mjx-num><mjx-dbox><mjx-dtable><mjx-line type="d"></mjx-line><mjx-row><mjx-den><mjx-dstrut type="d"></mjx-dstrut><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D44D TEX-I"></mjx-c></mjx-mi></mjx-den></mjx-row></mjx-dtable></mjx-dbox></mjx-frac></mjx-mfrac></mjx-math><mjx-assistive-mml display="block" unselectable="on"><math display="block" xmlns="http://www.w3.org/1998/Math/MathML"><mo stretchy="false">(</mo><mn>1</mn><mo>−</mo><msup><mrow data-mjx-texclass="INNER"><mo data-mjx-texclass="OPEN">(</mo><mfrac><mrow><mi>Z</mi><mo>−</mo><mn>1</mn></mrow><mi>Z</mi></mfrac><mo data-mjx-texclass="CLOSE">)</mo></mrow><mi>K</mi></msup><mo stretchy="false">)</mo><mo>⋅</mo><mfrac><mrow><mi>Z</mi><mo>−</mo><mn>1</mn></mrow><mi>Z</mi></mfrac></math></mjx-assistive-mml></mjx-container> 在 <d-math>K</d-math> 次掷骰子中不同结果的期望数量，但它非常接近给出的近似值。更多细节请参见附录。</d-footnote></p> <p><b style="color: #c55404ff;">即时测验 2 [AllToAll 时间]：</b>使用一个具有 450 GB/s 单向带宽的 8xH100 节点，AllToAll<sub>X-&gt;N</sub>(bf16[B<sub>X</sub>, N]) 需要多长时间？如果我们知道 8 个条目中只有 4 个是非零的呢？</p> <details><summary>点击此处查看答案。</summary> <p><strong>答案：</strong> 从上面我们知道，在密集情况下，成本是 <d-math>B \cdot N / (W \cdot N)</d-math>，或者 <d-math>B / W</d-math>。如果我们知道只有 <d-math>\frac{1}{2}</d-math> 的条目是非填充的，我们可以发送 <d-math>B \cdot N \cdot k / (W \cdot N^2) = B \cdot k/N / W = B / (2 \cdot W)</d-math>，大约是总成本的一半。</p> </details> <p class="takeaway"><strong>要点：</strong>在单个节点内的 GPU 上对一个 <d-math>B</d-math> 字节的数组进行 AllToAll 的成本大约是 <d-math>T_\text{comms} = (B \cdot (8 - 1)) / (8^2 \cdot W_\text{GPU egress}) \approx B / (8 \cdot W_\text{GPU egress})</d-math>。对于一个不规则的（top-<d-math>k</d-math>）AllToAll，这个成本进一步降低到 <d-math>(B \cdot k) / (864 \cdot W_\text{GPU egress})</d-math>。</p> <p><strong>实证测量：</strong> 这是一个在 8xH100 节点上 AllReduce 带宽的实证测量。Algo BW 是测量的带宽（字节/运行时），而 Bus BW 计算为 <d-math>2 \cdot W \cdot (8 - 1) / 8</d-math>，理论上是实际链接带宽的度量。你会注意到我们确实接近 370GB/s，低于 450GB/s 但相当接近，尽管每个设备只有大约 10GB。这意味着尽管这些估计在理论上是正确的，但需要一个大的消息才能实现它。</p> <figure> <picture> <img class="img-fluid" height="auto" loading="lazy" onerror="this.onerror=null; $('.responsive-img-srcset').remove();" src="https://jax-ml.github.io/scaling-book/assets/gpu/gpu-all-reduce-bw.png" width="100%"/> </picture> <figcaption class="caption"><b>图：</b>一个 8xH100 节点（禁用 SHARP）的 AllReduce 吞吐量。蓝色曲线是经验链接带宽，根据经验测量计算为 <d-math>2 * \text{bytes} * (N - 1) / (N * \text{runtime})</d-math>。请注意，即使使用巨大的 10GB 数组，我们也没有特别接近声称的 450GB/s 带宽。</figcaption> </figure> <p>这是一个真正的问题，因为它有意义地复杂化了我们可以提出的任何理论主张，因为例如，即使是在一个合理大小的数组上进行 AllReduce，比如 LLaMA-3 70B 的 MLP（大小为 <code class="language-plaintext highlighter-rouge">bf16[8192, 28672]</code>，或者 8 路模型分片后为 <code class="language-plaintext highlighter-rouge">bf16[8192, 3584] = 58MB</code>），也只能达到大约 150GB/s，而峰值是 450GB/s。相比之下，TPU 在更小的消息大小下就能达到峰值带宽（见附录 B）。</p> <p class="takeaway"><strong>要点：</strong>尽管 NVIDIA 声称 H100 NVLink 的带宽约为 450GB/s，但在实践中很难超过 370 GB/s，因此请相应调整上述估计。</p> <p><strong>网络内规约：</strong> 自 Hopper 代以来，NVIDIA 交换机支持<a href="https://developer.nvidia.com/blog/advancing-performance-with-nvidia-sharp-in-network-computing/" rel="external nofollow noopener" target="_blank">“SHARP”（可扩展分层聚合和规约协议）</a>，它允许“网络内规约”。这意味着<em>网络交换机本身</em>可以执行规约操作，并将结果多路复用或“多播”到多个目标 GPU：</p> <figure> <picture> <img class="img-fluid" height="auto" loading="lazy" onerror="this.onerror=null; $('.responsive-img-srcset').remove();" src="https://jax-ml.github.io/scaling-book/assets/gpu/sharp-algorithm.png" width="100%"/> </picture> <figcaption class="caption"><b>图：</b>没有 SHARP 的 AllReduce 理论成本是原来的 2 倍，因为它必须两次通过每个 GPU。实际上，速度提升只有大约 30%（来自 NCCL 2.27.5）。</figcaption> </figure> <p>理论上，这几乎将 AllReduce 的成本减半，因为它意味着每个 GPU 可以将其数据发送到一个顶层交换机，该交换机本身执行规约并将结果广播到每个 GPU，而无需两次从每个 GPU 出口，同时也减少了网络延迟。</p><span> <mjx-container class="MathJax CtxtMenu_Attached_0" ctxtmenu_counter="4" display="true" jax="CHTML" style="font-size: 116.9%; position: relative;" tabindex="0"><mjx-math aria-hidden="true" class="MJX-TEX" display="true" style="margin-left: 0px; margin-right: 0px;"><mjx-msub><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D447 TEX-I"></mjx-c></mjx-mi><mjx-script style="vertical-align: -0.153em; margin-left: -0.12em;"><mjx-mtext class="mjx-n" size="s"><mjx-c class="mjx-c53"></mjx-c><mjx-c class="mjx-c48"></mjx-c><mjx-c class="mjx-c41"></mjx-c><mjx-c class="mjx-c52"></mjx-c><mjx-c class="mjx-c50"></mjx-c><mjx-c class="mjx-c20"></mjx-c><mjx-c class="mjx-c41"></mjx-c><mjx-c class="mjx-c52"></mjx-c><mjx-c class="mjx-c20"></mjx-c><mjx-c class="mjx-c63"></mjx-c><mjx-c class="mjx-c6F"></mjx-c><mjx-c class="mjx-c6D"></mjx-c><mjx-c class="mjx-c6D"></mjx-c><mjx-c class="mjx-c73"></mjx-c></mjx-mtext></mjx-script></mjx-msub><mjx-mo class="mjx-n" space="4"><mjx-c class="mjx-c3D"></mjx-c></mjx-mo><mjx-mfrac space="4"><mjx-frac type="d"><mjx-num><mjx-nstrut type="d"></mjx-nstrut><mjx-mtext class="mjx-n"><mjx-c class="mjx-c62"></mjx-c><mjx-c class="mjx-c79"></mjx-c><mjx-c class="mjx-c74"></mjx-c><mjx-c class="mjx-c65"></mjx-c><mjx-c class="mjx-c73"></mjx-c></mjx-mtext></mjx-num><mjx-dbox><mjx-dtable><mjx-line type="d"></mjx-line><mjx-row><mjx-den><mjx-dstrut type="d"></mjx-dstrut><mjx-mtext class="mjx-n"><mjx-c class="mjx-c47"></mjx-c><mjx-c class="mjx-c50"></mjx-c><mjx-c class="mjx-c55"></mjx-c><mjx-c class="mjx-c20"></mjx-c><mjx-c class="mjx-c65"></mjx-c><mjx-c class="mjx-c67"></mjx-c><mjx-c class="mjx-c72"></mjx-c><mjx-c class="mjx-c65"></mjx-c><mjx-c class="mjx-c73"></mjx-c><mjx-c class="mjx-c73"></mjx-c><mjx-c class="mjx-c20"></mjx-c><mjx-c class="mjx-c62"></mjx-c><mjx-c class="mjx-c61"></mjx-c><mjx-c class="mjx-c6E"></mjx-c><mjx-c class="mjx-c64"></mjx-c><mjx-c class="mjx-c77"></mjx-c><mjx-c class="mjx-c69"></mjx-c><mjx-c class="mjx-c64"></mjx-c><mjx-c class="mjx-c74"></mjx-c><mjx-c class="mjx-c68"></mjx-c></mjx-mtext></mjx-den></mjx-row></mjx-dtable></mjx-dbox></mjx-frac></mjx-mfrac></mjx-math><mjx-assistive-mml display="block" unselectable="on"><math display="block" xmlns="http://www.w3.org/1998/Math/MathML"><msub><mi>T</mi><mtext>SHARP AR comms</mtext></msub><mo>=</mo><mfrac><mtext>bytes</mtext><mtext>GPU egress bandwidth</mtext></mfrac></math></mjx-assistive-mml></mjx-container> </span><p>请注意，这是精确的，而不是差一个 <d-math>1/N</d-math> 的因子，因为每个 GPU 首先出口 <d-math>B \cdot (N - 1) / N</d-math>，然后接收其本地分片的局部规约版本（入口 <d-math>B/N</d-math>），完成规约，然后再次出口 <d-math>B/N</d-math>，然后入口完全规约的结果（入口 <d-math>B \cdot (N - 1) / N</d-math>），结果恰好是 <d-math>B</d-math> 字节的入口。</p> <p>然而，在实践中，我们看到启用 SHARP 后带宽增加了约 30%，而预测是 75%。这仅仅使我们的有效集合通信带宽达到约 480GB/s，远未达到 2 倍。</p> <figure> <picture> <img class="img-fluid" height="auto" loading="lazy" onerror="this.onerror=null; $('.responsive-img-srcset').remove();" src="https://jax-ml.github.io/scaling-book/assets/gpu/sharp-all-reduce-cost.png" width="100%"/> </picture> <figcaption class="caption"><b>图：</b>在节点内启用和未启用 NVIDIA SHARP 的 AllReduce 算法带宽的实证测量。在峰值时，增益约为 30% 的吞吐量提升，尽管从算法上讲，它应该能够实现接近 75% 的增益。</figcaption> </figure> <p class="takeaway"><strong>要点：</strong>理论上，NVIDIA SHARP（在大多数 NVIDIA 交换机上可用）应将对 <d-math>B</d-math> 字节的 AllReduce 成本从大约 <d-math>2 * B / W</d-math> 降低到 <d-math>B / W</d-math>。然而，在实践中，我们只看到大约 30% 的带宽提升。由于纯 AllReduce 在 LLM 中相当罕见，这并不是特别有用。</p> <h3 id="cross-node-collectives">跨节点集合通信</h3> <p>当我们超越节点级别时，成本变得更加微妙。当在树上进行规约时，你可以想象从下往上规约，首先在节点内，然后在叶级别，然后在脊级别，在每个级别都使用常规算法。特别是对于 AllReduce，你可以看到这使我们能够总体上传输更少的数据，因为在节点级别进行 AllReduce 后，我们只需要向叶级别出口 <d-math>B</d-math> 字节，而不是 <d-math>B * N</d-math>。</p> <p><strong>这有多昂贵？</strong> 作为一阶近似，因为我们有完全的对分带宽，AllGather 或 ReduceScatter 的成本大约是缓冲区大小（字节）除以节点出口带宽（H100 上为 400GB/s），<em>无论树形规约的任何细节如何。</em></p><span> <mjx-container class="MathJax CtxtMenu_Attached_0" ctxtmenu_counter="5" display="true" jax="CHTML" style="font-size: 116.9%; position: relative;" tabindex="0"><mjx-math aria-hidden="true" class="MJX-TEX" display="true" style="margin-left: 0px; margin-right: 0px;"><mjx-msub><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D447 TEX-I"></mjx-c></mjx-mi><mjx-script style="vertical-align: -0.153em; margin-left: -0.12em;"><mjx-mtext class="mjx-n" size="s"><mjx-c class="mjx-c41"></mjx-c><mjx-c class="mjx-c47"></mjx-c><mjx-c class="mjx-c20"></mjx-c><mjx-c class="mjx-c6F"></mjx-c><mjx-c class="mjx-c72"></mjx-c><mjx-c class="mjx-c20"></mjx-c><mjx-c class="mjx-c52"></mjx-c><mjx-c class="mjx-c53"></mjx-c><mjx-c class="mjx-c20"></mjx-c><mjx-c class="mjx-c63"></mjx-c><mjx-c class="mjx-c6F"></mjx-c><mjx-c class="mjx-c6D"></mjx-c><mjx-c class="mjx-c6D"></mjx-c><mjx-c class="mjx-c73"></mjx-c></mjx-mtext></mjx-script></mjx-msub><mjx-mo class="mjx-n" space="4"><mjx-c class="mjx-c3D"></mjx-c></mjx-mo><mjx-mfrac space="4"><mjx-frac type="d"><mjx-num><mjx-nstrut type="d"></mjx-nstrut><mjx-mtext class="mjx-n"><mjx-c class="mjx-c62"></mjx-c><mjx-c class="mjx-c79"></mjx-c><mjx-c class="mjx-c74"></mjx-c><mjx-c class="mjx-c65"></mjx-c><mjx-c class="mjx-c73"></mjx-c></mjx-mtext></mjx-num><mjx-dbox><mjx-dtable><mjx-line type="d"></mjx-line><mjx-row><mjx-den><mjx-dstrut type="d"></mjx-dstrut><mjx-msub><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D44A TEX-I"></mjx-c></mjx-mi><mjx-script style="vertical-align: -0.15em; margin-left: -0.104em;"><mjx-mtext class="mjx-n" size="s"><mjx-c class="mjx-c6E"></mjx-c><mjx-c class="mjx-c6F"></mjx-c><mjx-c class="mjx-c64"></mjx-c><mjx-c class="mjx-c65"></mjx-c><mjx-c class="mjx-c20"></mjx-c><mjx-c class="mjx-c65"></mjx-c><mjx-c class="mjx-c67"></mjx-c><mjx-c class="mjx-c72"></mjx-c><mjx-c class="mjx-c65"></mjx-c><mjx-c class="mjx-c73"></mjx-c><mjx-c class="mjx-c73"></mjx-c></mjx-mtext></mjx-script></mjx-msub></mjx-den></mjx-row></mjx-dtable></mjx-dbox></mjx-frac></mjx-mfrac><mjx-munder space="4"><mjx-row><mjx-base style="padding-left: 0.455em;"><mjx-mo class="mjx-n"><mjx-c class="mjx-c3D"></mjx-c></mjx-mo></mjx-base></mjx-row><mjx-row><mjx-under style="padding-top: 0.167em;"><mjx-mrow size="s"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D43B TEX-I"></mjx-c></mjx-mi><mjx-mn class="mjx-n"><mjx-c class="mjx-c31"></mjx-c><mjx-c class="mjx-c30"></mjx-c><mjx-c class="mjx-c30"></mjx-c></mjx-mn></mjx-mrow></mjx-under></mjx-row></mjx-munder><mjx-mfrac space="4"><mjx-frac type="d"><mjx-num><mjx-nstrut type="d"></mjx-nstrut><mjx-mtext class="mjx-n"><mjx-c class="mjx-c62"></mjx-c><mjx-c class="mjx-c79"></mjx-c><mjx-c class="mjx-c74"></mjx-c><mjx-c class="mjx-c65"></mjx-c><mjx-c class="mjx-c73"></mjx-c></mjx-mtext></mjx-num><mjx-dbox><mjx-dtable><mjx-line type="d"></mjx-line><mjx-row><mjx-den><mjx-dstrut type="d"></mjx-dstrut><mjx-mtext class="mjx-n"><mjx-c class="mjx-c34"></mjx-c><mjx-c class="mjx-c30"></mjx-c><mjx-c class="mjx-c30"></mjx-c><mjx-c class="mjx-c65"></mjx-c><mjx-c class="mjx-c39"></mjx-c></mjx-mtext></mjx-den></mjx-row></mjx-dtable></mjx-dbox></mjx-frac></mjx-mfrac></mjx-math><mjx-assistive-mml display="block" unselectable="on"><math display="block" xmlns="http://www.w3.org/1998/Math/MathML"><msub><mi>T</mi><mtext>AG or RS comms</mtext></msub><mo>=</mo><mfrac><mtext>bytes</mtext><msub><mi>W</mi><mtext>node egress</mtext></msub></mfrac><munder><mo>=</mo><mrow><mi>H</mi><mn>100</mn></mrow></munder><mfrac><mtext>bytes</mtext><mtext>400e9</mtext></mfrac></math></mjx-assistive-mml></mjx-container> </span><p>其中 <d-math>W_\text{node}</d-math> 出口带宽对于上述 H100 网络通常是 400GB/s（每个节点出口 8x400Gbps IB 链接）。想象这一点的最清晰方式是想象在<em>集群中的每个节点</em>上进行环形规约。由于胖树拓扑结构，我们总能构建一个在任意两个节点之间具有 <d-math>W_\text{node}</d-math> 出口带宽的环，并进行正常的规约。节点级规约（几乎）永远不会是瓶颈，因为它具有更高的总带宽和更好的延迟，尽管一般而言成本是</p><span> <mjx-container class="MathJax CtxtMenu_Attached_0" ctxtmenu_counter="6" display="true" jax="CHTML" style="font-size: 116.9%; position: relative;" tabindex="0"><mjx-math aria-hidden="true" class="MJX-TEX" display="true" style="margin-left: 0px; margin-right: 0px;"><mjx-msub><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D447 TEX-I"></mjx-c></mjx-mi><mjx-script style="vertical-align: -0.15em; margin-left: -0.12em;"><mjx-mtext class="mjx-n" size="s"><mjx-c class="mjx-c74"></mjx-c><mjx-c class="mjx-c6F"></mjx-c><mjx-c class="mjx-c74"></mjx-c><mjx-c class="mjx-c61"></mjx-c><mjx-c class="mjx-c6C"></mjx-c></mjx-mtext></mjx-script></mjx-msub><mjx-mo class="mjx-n" space="4"><mjx-c class="mjx-c3D"></mjx-c></mjx-mo><mjx-mo class="mjx-n" space="4"><mjx-c class="mjx-c6D"></mjx-c><mjx-c class="mjx-c61"></mjx-c><mjx-c class="mjx-c78"></mjx-c></mjx-mo><mjx-mo class="mjx-n"><mjx-c class="mjx-c28"></mjx-c></mjx-mo><mjx-msub><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D447 TEX-I"></mjx-c></mjx-mi><mjx-script style="vertical-align: -0.15em; margin-left: -0.12em;"><mjx-mtext class="mjx-n" size="s"><mjx-c class="mjx-c63"></mjx-c><mjx-c class="mjx-c6F"></mjx-c><mjx-c class="mjx-c6D"></mjx-c><mjx-c class="mjx-c6D"></mjx-c><mjx-c class="mjx-c73"></mjx-c><mjx-c class="mjx-c20"></mjx-c><mjx-c class="mjx-c61"></mjx-c><mjx-c class="mjx-c74"></mjx-c><mjx-c class="mjx-c20"></mjx-c><mjx-c class="mjx-c6E"></mjx-c><mjx-c class="mjx-c6F"></mjx-c><mjx-c class="mjx-c64"></mjx-c><mjx-c class="mjx-c65"></mjx-c></mjx-mtext></mjx-script></mjx-msub><mjx-mo class="mjx-n"><mjx-c class="mjx-c2C"></mjx-c></mjx-mo><mjx-msub space="2"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D447 TEX-I"></mjx-c></mjx-mi><mjx-script style="vertical-align: -0.15em; margin-left: -0.12em;"><mjx-mtext class="mjx-n" size="s"><mjx-c class="mjx-c63"></mjx-c><mjx-c class="mjx-c6F"></mjx-c><mjx-c class="mjx-c6D"></mjx-c><mjx-c class="mjx-c6D"></mjx-c><mjx-c class="mjx-c73"></mjx-c><mjx-c class="mjx-c20"></mjx-c><mjx-c class="mjx-c69"></mjx-c><mjx-c class="mjx-c6E"></mjx-c><mjx-c class="mjx-c20"></mjx-c><mjx-c class="mjx-c73"></mjx-c><mjx-c class="mjx-c63"></mjx-c><mjx-c class="mjx-c61"></mjx-c><mjx-c class="mjx-c6C"></mjx-c><mjx-c class="mjx-c65"></mjx-c><mjx-c class="mjx-c2D"></mjx-c><mjx-c class="mjx-c6F"></mjx-c><mjx-c class="mjx-c75"></mjx-c><mjx-c class="mjx-c74"></mjx-c><mjx-c class="mjx-c20"></mjx-c><mjx-c class="mjx-c6E"></mjx-c><mjx-c class="mjx-c65"></mjx-c><mjx-c class="mjx-c74"></mjx-c><mjx-c class="mjx-c77"></mjx-c><mjx-c class="mjx-c6F"></mjx-c><mjx-c class="mjx-c72"></mjx-c><mjx-c class="mjx-c6B"></mjx-c></mjx-mtext></mjx-script></mjx-msub><mjx-mo class="mjx-n"><mjx-c class="mjx-c29"></mjx-c></mjx-mo><mjx-mo class="mjx-n" space="4"><mjx-c class="mjx-c3D"></mjx-c></mjx-mo><mjx-mo class="mjx-n" space="4"><mjx-c class="mjx-c6D"></mjx-c><mjx-c class="mjx-c61"></mjx-c><mjx-c class="mjx-c78"></mjx-c></mjx-mo><mjx-mrow space="2"><mjx-mo class="mjx-s3"><mjx-c class="mjx-c5B TEX-S3"></mjx-c></mjx-mo><mjx-mfrac><mjx-frac type="d"><mjx-num><mjx-nstrut type="d"></mjx-nstrut><mjx-mtext class="mjx-n"><mjx-c class="mjx-c62"></mjx-c><mjx-c class="mjx-c79"></mjx-c><mjx-c class="mjx-c74"></mjx-c><mjx-c class="mjx-c65"></mjx-c><mjx-c class="mjx-c73"></mjx-c></mjx-mtext></mjx-num><mjx-dbox><mjx-dtable><mjx-line type="d"></mjx-line><mjx-row><mjx-den><mjx-dstrut type="d"></mjx-dstrut><mjx-msub><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D44A TEX-I"></mjx-c></mjx-mi><mjx-script style="vertical-align: -0.15em; margin-left: -0.104em;"><mjx-mtext class="mjx-n" size="s"><mjx-c class="mjx-c47"></mjx-c><mjx-c class="mjx-c50"></mjx-c><mjx-c class="mjx-c55"></mjx-c><mjx-c class="mjx-c20"></mjx-c><mjx-c class="mjx-c65"></mjx-c><mjx-c class="mjx-c67"></mjx-c><mjx-c class="mjx-c72"></mjx-c><mjx-c class="mjx-c65"></mjx-c><mjx-c class="mjx-c73"></mjx-c><mjx-c class="mjx-c73"></mjx-c></mjx-mtext></mjx-script></mjx-msub></mjx-den></mjx-row></mjx-dtable></mjx-dbox></mjx-frac></mjx-mfrac><mjx-mo class="mjx-n"><mjx-c class="mjx-c2C"></mjx-c></mjx-mo><mjx-mfrac space="2"><mjx-frac type="d"><mjx-num><mjx-nstrut type="d"></mjx-nstrut><mjx-mtext class="mjx-n"><mjx-c class="mjx-c62"></mjx-c><mjx-c class="mjx-c79"></mjx-c><mjx-c class="mjx-c74"></mjx-c><mjx-c class="mjx-c65"></mjx-c><mjx-c class="mjx-c73"></mjx-c></mjx-mtext></mjx-num><mjx-dbox><mjx-dtable><mjx-line type="d"></mjx-line><mjx-row><mjx-den><mjx-dstrut type="d"></mjx-dstrut><mjx-msub><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D44A TEX-I"></mjx-c></mjx-mi><mjx-script style="vertical-align: -0.15em; margin-left: -0.104em;"><mjx-mtext class="mjx-n" size="s"><mjx-c class="mjx-c6E"></mjx-c><mjx-c class="mjx-c6F"></mjx-c><mjx-c class="mjx-c64"></mjx-c><mjx-c class="mjx-c65"></mjx-c><mjx-c class="mjx-c20"></mjx-c><mjx-c class="mjx-c65"></mjx-c><mjx-c class="mjx-c67"></mjx-c><mjx-c class="mjx-c72"></mjx-c><mjx-c class="mjx-c65"></mjx-c><mjx-c class="mjx-c73"></mjx-c><mjx-c class="mjx-c73"></mjx-c></mjx-mtext></mjx-script></mjx-msub></mjx-den></mjx-row></mjx-dtable></mjx-dbox></mjx-frac></mjx-mfrac><mjx-mo class="mjx-s3"><mjx-c class="mjx-c5D TEX-S3"></mjx-c></mjx-mo></mjx-mrow></mjx-math><mjx-assistive-mml display="block" unselectable="on"><math display="block" xmlns="http://www.w3.org/1998/Math/MathML"><msub><mi>T</mi><mtext>total</mtext></msub><mo>=</mo><mo data-mjx-texclass="OP" movablelimits="true">max</mo><mo stretchy="false">(</mo><msub><mi>T</mi><mtext>comms at node</mtext></msub><mo>,</mo><msub><mi>T</mi><mtext>comms in scale-out network</mtext></msub><mo stretchy="false">)</mo><mo>=</mo><mo data-mjx-texclass="OP" movablelimits="true">max</mo><mrow data-mjx-texclass="INNER"><mo data-mjx-texclass="OPEN">[</mo><mfrac><mtext>bytes</mtext><msub><mi>W</mi><mtext>GPU egress</mtext></msub></mfrac><mo>,</mo><mfrac><mtext>bytes</mtext><msub><mi>W</mi><mtext>node egress</mtext></msub></mfrac><mo data-mjx-texclass="CLOSE">]</mo></mrow></math></mjx-assistive-mml></mjx-container> </span><details><summary>你可以在这里看到更精确的推导。</summary> <p>我们可以更精确地指出，我们实际上是在网络的每一层进行环形规约，这些规约大部分可以重叠，所以我们有：</p> <mjx-container class="MathJax CtxtMenu_Attached_0" ctxtmenu_counter="7" display="true" jax="CHTML" style="font-size: 116.9%; position: relative;" tabindex="0"><mjx-math aria-hidden="true" class="MJX-TEX" display="true" style="margin-left: 0px; margin-right: 0px;"><mjx-msub><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D447 TEX-I"></mjx-c></mjx-mi><mjx-script style="vertical-align: -0.153em; margin-left: -0.12em;"><mjx-mtext class="mjx-n" size="s"><mjx-c class="mjx-c41"></mjx-c><mjx-c class="mjx-c47"></mjx-c><mjx-c class="mjx-c20"></mjx-c><mjx-c class="mjx-c6F"></mjx-c><mjx-c class="mjx-c72"></mjx-c><mjx-c class="mjx-c20"></mjx-c><mjx-c class="mjx-c52"></mjx-c><mjx-c class="mjx-c53"></mjx-c><mjx-c class="mjx-c20"></mjx-c><mjx-c class="mjx-c63"></mjx-c><mjx-c class="mjx-c6F"></mjx-c><mjx-c class="mjx-c6D"></mjx-c><mjx-c class="mjx-c6D"></mjx-c><mjx-c class="mjx-c73"></mjx-c></mjx-mtext></mjx-script></mjx-msub><mjx-mo class="mjx-n" space="4"><mjx-c class="mjx-c3D"></mjx-c></mjx-mo><mjx-mtext class="mjx-n" space="4"><mjx-c class="mjx-c62"></mjx-c><mjx-c class="mjx-c79"></mjx-c><mjx-c class="mjx-c74"></mjx-c><mjx-c class="mjx-c65"></mjx-c><mjx-c class="mjx-c73"></mjx-c></mjx-mtext><mjx-mo class="mjx-n" space="3"><mjx-c class="mjx-c22C5"></mjx-c></mjx-mo><mjx-mi class="mjx-i" space="3"><mjx-c class="mjx-c1D45A TEX-I"></mjx-c></mjx-mi><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D44E TEX-I"></mjx-c></mjx-mi><mjx-msub><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D465 TEX-I"></mjx-c></mjx-mi><mjx-script style="vertical-align: -0.15em;"><mjx-mtext class="mjx-n" size="s"><mjx-c class="mjx-c64"></mjx-c><mjx-c class="mjx-c65"></mjx-c><mjx-c class="mjx-c70"></mjx-c><mjx-c class="mjx-c74"></mjx-c><mjx-c class="mjx-c68"></mjx-c><mjx-c class="mjx-c20"></mjx-c><mjx-c class="mjx-c69"></mjx-c></mjx-mtext></mjx-script></mjx-msub><mjx-mrow space="2"><mjx-mo class="mjx-s3"><mjx-c class="mjx-c5B TEX-S3"></mjx-c></mjx-mo><mjx-mfrac><mjx-frac type="d"><mjx-num><mjx-nstrut type="d"></mjx-nstrut><mjx-mrow><mjx-msub><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D437 TEX-I"></mjx-c></mjx-mi><mjx-script style="vertical-align: -0.15em;"><mjx-mi class="mjx-i" size="s"><mjx-c class="mjx-c1D456 TEX-I"></mjx-c></mjx-mi></mjx-script></mjx-msub><mjx-mo class="mjx-n" space="3"><mjx-c class="mjx-c2212"></mjx-c></mjx-mo><mjx-mn class="mjx-n" space="3"><mjx-c class="mjx-c31"></mjx-c></mjx-mn></mjx-mrow></mjx-num><mjx-dbox><mjx-dtable><mjx-line type="d"></mjx-line><mjx-row><mjx-den><mjx-dstrut type="d"></mjx-dstrut><mjx-mrow><mjx-msub><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D437 TEX-I"></mjx-c></mjx-mi><mjx-script style="vertical-align: -0.15em;"><mjx-mi class="mjx-i" size="s"><mjx-c class="mjx-c1D456 TEX-I"></mjx-c></mjx-mi></mjx-script></mjx-msub><mjx-mo class="mjx-n" space="3"><mjx-c class="mjx-c22C5"></mjx-c></mjx-mo><mjx-msub space="3"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D44A TEX-I"></mjx-c></mjx-mi><mjx-script style="vertical-align: -0.15em; margin-left: -0.104em;"><mjx-mtext class="mjx-n" size="s"><mjx-c class="mjx-c6C"></mjx-c><mjx-c class="mjx-c69"></mjx-c><mjx-c class="mjx-c6E"></mjx-c><mjx-c class="mjx-c6B"></mjx-c><mjx-c class="mjx-c20"></mjx-c><mjx-c class="mjx-c69"></mjx-c></mjx-mtext></mjx-script></mjx-msub></mjx-mrow></mjx-den></mjx-row></mjx-dtable></mjx-dbox></mjx-frac></mjx-mfrac><mjx-mo class="mjx-s3"><mjx-c class="mjx-c5D TEX-S3"></mjx-c></mjx-mo></mjx-mrow></mjx-math><mjx-assistive-mml display="block" unselectable="on"><math display="block" xmlns="http://www.w3.org/1998/Math/MathML"><msub><mi>T</mi><mtext>AG or RS comms</mtext></msub><mo>=</mo><mtext>bytes</mtext><mo>⋅</mo><mi>m</mi><mi>a</mi><msub><mi>x</mi><mtext>depth i</mtext></msub><mrow data-mjx-texclass="INNER"><mo data-mjx-texclass="OPEN">[</mo><mfrac><mrow><msub><mi>D</mi><mi>i</mi></msub><mo>−</mo><mn>1</mn></mrow><mrow><msub><mi>D</mi><mi>i</mi></msub><mo>⋅</mo><msub><mi>W</mi><mtext>link i</mtext></msub></mrow></mfrac><mo data-mjx-texclass="CLOSE">]</mo></mrow></math></mjx-assistive-mml></mjx-container> <p>其中 <d-math>D_i</d-math> 是深度 <d-math>i</d-math> 的度（深度 <d-math>i</d-math> 的子节点数量），<d-math>W_\text{link i}</d-math> 是连接每个子节点到节点 <d-math>i</d-math> 的链接带宽。</p> <p>使用这个，我们可以计算可用的 AllGather/AllReduce 带宽为 <d-math>min_\text{depth i}(D_i * W_\text{link i} / (D_i - 1))</d-math> 对于给定的拓扑。在上面的情况下，我们有：</p> <ul> <li> <strong>节点：</strong> <d-math>D_\text{node}</d-math> = 8，因为我们节点中有 8 个 GPU，Wlink i = 450GB/s。因此我们的 AG 带宽是 <code class="language-plaintext highlighter-rouge">450e9 * 8 / (8 - 1) = 514GB/s</code>。</li> <li> <strong>叶：</strong> <d-math>D_\text{leaf}</d-math> = 32，因为我们 SU 中有 32 个节点，Wlink i = 400GB/s（8x400Gbps IB 链接）。因此我们的带宽是 <code class="language-plaintext highlighter-rouge">400e9 * 32 / (32 - 1) = 413GB/s</code>。</li> <li> <strong>脊：</strong> <d-math>D_\text{spine}</d-math> = 4，因为我们有 4 个 SU，<d-math>W_\text{link i}</d-math> = 12.8TB/s（来自上面的 <code class="language-plaintext highlighter-rouge">8 * 16 * 2 * 400Gbps</code> 链接）。我们的带宽是 <code class="language-plaintext highlighter-rouge">12.8e12 * 4 / (4 - 1) = 17.1TB/s</code>。</li> </ul> <p>因此我们的整体 AG 或 RS 带宽是 <code class="language-plaintext highlighter-rouge">min(514GB/s, 413GB/s, 17.1TB/s) = 413GB/s</code> 在叶级别，所以实际上 <d-math>T_\text{AG or RS comms} = B / \text{413GB/s}</d-math>，即即使在最高级别，我们也有大约 413GB/s 的 AllReduce 带宽。对于带 SHARP 的 AllReduce，它会略低于这个值（大约 400GB/s），因为我们没有 <d-math>(N - 1) / N</d-math> 因子。尽管如此，450GB/s 和 400GB/s 作为近似值足够接近。</p> </details> <p><strong>其他集合通信：</strong> 除非启用 SHARP，否则 AllReduces 的成本仍然是上述的两倍。NVIDIA 也销售支持 SHARP 的 IB 交换机，尽管并非所有提供商都有。AllToAlls 在跨节点时变化很大，因为它们不像 AllReduces 那样是“分层”的。如果我们想将数据从每个 GPU 发送到每个其他 GPU，我们无法利用节点级别的完全对分带宽。这意味着如果我们有一个跨越 <d-math>M = N / 8</d-math> 个节点的 N 路 AllToAll，成本是</p><span> <mjx-container class="MathJax CtxtMenu_Attached_0" ctxtmenu_counter="8" display="true" jax="CHTML" style="font-size: 116.9%; position: relative;" tabindex="0"><mjx-math aria-hidden="true" class="MJX-TEX" display="true" style="margin-left: 0px; margin-right: 0px;"><mjx-msub><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D447 TEX-I"></mjx-c></mjx-mi><mjx-script style="vertical-align: -0.153em; margin-left: -0.12em;"><mjx-mtext class="mjx-n" size="s"><mjx-c class="mjx-c41"></mjx-c><mjx-c class="mjx-c6C"></mjx-c><mjx-c class="mjx-c6C"></mjx-c><mjx-c class="mjx-c54"></mjx-c><mjx-c class="mjx-c6F"></mjx-c><mjx-c class="mjx-c41"></mjx-c><mjx-c class="mjx-c6C"></mjx-c><mjx-c class="mjx-c6C"></mjx-c><mjx-c class="mjx-c20"></mjx-c><mjx-c class="mjx-c63"></mjx-c><mjx-c class="mjx-c6F"></mjx-c><mjx-c class="mjx-c6D"></mjx-c><mjx-c class="mjx-c6D"></mjx-c><mjx-c class="mjx-c73"></mjx-c></mjx-mtext></mjx-script></mjx-msub><mjx-mo class="mjx-n" space="4"><mjx-c class="mjx-c3D"></mjx-c></mjx-mo><mjx-mfrac space="4"><mjx-frac type="d"><mjx-num><mjx-nstrut type="d"></mjx-nstrut><mjx-mrow><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D435 TEX-I"></mjx-c></mjx-mi><mjx-mo class="mjx-n" space="3"><mjx-c class="mjx-c22C5"></mjx-c></mjx-mo><mjx-mo class="mjx-n" space="3"><mjx-c class="mjx-c28"></mjx-c></mjx-mo><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D440 TEX-I"></mjx-c></mjx-mi><mjx-mo class="mjx-n" space="3"><mjx-c class="mjx-c2212"></mjx-c></mjx-mo><mjx-mn class="mjx-n" space="3"><mjx-c class="mjx-c31"></mjx-c></mjx-mn><mjx-mo class="mjx-n"><mjx-c class="mjx-c29"></mjx-c></mjx-mo></mjx-mrow></mjx-num><mjx-dbox><mjx-dtable><mjx-line type="d"></mjx-line><mjx-row><mjx-den><mjx-dstrut type="d"></mjx-dstrut><mjx-mrow><mjx-msup><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D440 TEX-I"></mjx-c></mjx-mi><mjx-script style="vertical-align: 0.289em; margin-left: 0.054em;"><mjx-mn class="mjx-n" size="s"><mjx-c class="mjx-c32"></mjx-c></mjx-mn></mjx-script></mjx-msup><mjx-mo class="mjx-n" space="3"><mjx-c class="mjx-c22C5"></mjx-c></mjx-mo><mjx-msub space="3"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D44A TEX-I"></mjx-c></mjx-mi><mjx-script style="vertical-align: -0.15em; margin-left: -0.104em;"><mjx-mtext class="mjx-n" size="s"><mjx-c class="mjx-c6E"></mjx-c><mjx-c class="mjx-c6F"></mjx-c><mjx-c class="mjx-c64"></mjx-c><mjx-c class="mjx-c65"></mjx-c><mjx-c class="mjx-c20"></mjx-c><mjx-c class="mjx-c65"></mjx-c><mjx-c class="mjx-c67"></mjx-c><mjx-c class="mjx-c72"></mjx-c><mjx-c class="mjx-c65"></mjx-c><mjx-c class="mjx-c73"></mjx-c><mjx-c class="mjx-c73"></mjx-c></mjx-mtext></mjx-script></mjx-msub></mjx-mrow></mjx-den></mjx-row></mjx-dtable></mjx-dbox></mjx-frac></mjx-mfrac><mjx-mo class="mjx-n" space="4"><mjx-c class="mjx-c224A TEX-A"></mjx-c></mjx-mo><mjx-mfrac space="4"><mjx-frac type="d"><mjx-num><mjx-nstrut type="d"></mjx-nstrut><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D435 TEX-I"></mjx-c></mjx-mi></mjx-num><mjx-dbox><mjx-dtable><mjx-line type="d"></mjx-line><mjx-row><mjx-den><mjx-dstrut type="d"></mjx-dstrut><mjx-mrow><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D440 TEX-I"></mjx-c></mjx-mi><mjx-mo class="mjx-n" space="3"><mjx-c class="mjx-c22C5"></mjx-c></mjx-mo><mjx-msub space="3"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D44A TEX-I"></mjx-c></mjx-mi><mjx-script style="vertical-align: -0.15em; margin-left: -0.104em;"><mjx-mtext class="mjx-n" size="s"><mjx-c class="mjx-c6E"></mjx-c><mjx-c class="mjx-c6F"></mjx-c><mjx-c class="mjx-c64"></mjx-c><mjx-c class="mjx-c65"></mjx-c><mjx-c class="mjx-c20"></mjx-c><mjx-c class="mjx-c65"></mjx-c><mjx-c class="mjx-c67"></mjx-c><mjx-c class="mjx-c72"></mjx-c><mjx-c class="mjx-c65"></mjx-c><mjx-c class="mjx-c73"></mjx-c><mjx-c class="mjx-c73"></mjx-c></mjx-mtext></mjx-script></mjx-msub></mjx-mrow></mjx-den></mjx-row></mjx-dtable></mjx-dbox></mjx-frac></mjx-mfrac></mjx-math><mjx-assistive-mml display="block" unselectable="on"><math display="block" xmlns="http://www.w3.org/1998/Math/MathML"><msub><mi>T</mi><mtext>AllToAll comms</mtext></msub><mo>=</mo><mfrac><mrow><mi>B</mi><mo>⋅</mo><mo stretchy="false">(</mo><mi>M</mi><mo>−</mo><mn>1</mn><mo stretchy="false">)</mo></mrow><mrow><msup><mi>M</mi><mn>2</mn></msup><mo>⋅</mo><msub><mi>W</mi><mtext>node egress</mtext></msub></mrow></mfrac><mo>≊</mo><mfrac><mi>B</mi><mrow><mi>M</mi><mo>⋅</mo><msub><mi>W</mi><mtext>node egress</mtext></msub></mrow></mfrac></math></mjx-assistive-mml></mjx-container> </span><p>这实际上只有 50GB/s 而不是 400GB/s 的带宽。我们从单个 H100 节点内的 <d-math>B / (8 * \text{450e9})</d-math> 变成了跨越 2 个节点时的 <d-math>B / (2 \cdot \text{400e9})</d-math>，性能下降超过 4 倍。</p> <p>以下是 1024-GPU DGX H100 SuperPod 架构的摘要：</p> <table class="table-hover" data-toggle="table"> <thead> <tr> <th style="text-align: center">级别</th> <th style="text-align: center">GPU 数量</th> <th style="text-align: center">度 (# 子节点)</th> <th style="text-align: center">交换机带宽 (全双工, TB/s)</th> <th style="text-align: center">电缆带宽 (全双工, TB/s)</th> <th style="text-align: center">集合通信带宽 (GB/s)</th> </tr> </thead> <tbody> <tr> <td style="text-align: center">节点</td> <td style="text-align: center">8</td> <td style="text-align: center">8</td> <td style="text-align: center">6.4</td> <td style="text-align: center">3.6</td> <td style="text-align: center">450</td> </tr> <tr> <td style="text-align: center">叶 (SU)</td> <td style="text-align: center">256</td> <td style="text-align: center">32</td> <td style="text-align: center">25.6</td> <td style="text-align: center">12.8</td> <td style="text-align: center">400</td> </tr> <tr> <td style="text-align: center">脊</td> <td style="text-align: center">1024</td> <td style="text-align: center">4</td> <td style="text-align: center">51.2</td> <td style="text-align: center">51.2</td> <td style="text-align: center">400</td> </tr> </tbody> </table> <p>我们使用术语“集合通信带宽”来描述我们可以从 GPU 或节点出口的有效带宽。它也是 <d-math>\text{对分带宽} * 2 / N</d-math>。</p> <p class="takeaway"><strong>要点：</strong>在节点级别之上，对 B 字节进行 AllGather 或 AllReduce 的成本大约是 <d-math>B / W_\text{node egress}</d-math>，在 H100 DGX SuperPod 上是 <d-math>B / \text{400e9}</d-math>。整体拓扑是一个胖树，旨在为任意两对节点之间提供恒定的带宽。</p> <p><strong>当数组在单独的轴上分片时的规约：</strong> 考虑像这样的规约成本</p><span> <mjx-container class="MathJax CtxtMenu_Attached_0" ctxtmenu_counter="9" display="true" jax="CHTML" style="font-size: 116.9%; position: relative;" tabindex="0"><mjx-math aria-hidden="true" class="MJX-TEX" display="true" style="margin-left: 0px; margin-right: 0px;"><mjx-msub><mjx-mtext class="mjx-n"><mjx-c class="mjx-c41"></mjx-c><mjx-c class="mjx-c6C"></mjx-c><mjx-c class="mjx-c6C"></mjx-c><mjx-c class="mjx-c52"></mjx-c><mjx-c class="mjx-c65"></mjx-c><mjx-c class="mjx-c64"></mjx-c><mjx-c class="mjx-c75"></mjx-c><mjx-c class="mjx-c63"></mjx-c><mjx-c class="mjx-c65"></mjx-c></mjx-mtext><mjx-script style="vertical-align: -0.15em;"><mjx-mi class="mjx-i" size="s"><mjx-c class="mjx-c1D44B TEX-I"></mjx-c></mjx-mi></mjx-script></mjx-msub><mjx-mo class="mjx-n"><mjx-c class="mjx-c28"></mjx-c></mjx-mo><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D434 TEX-I"></mjx-c></mjx-mi><mjx-mo class="mjx-n"><mjx-c class="mjx-c5B"></mjx-c></mjx-mo><mjx-msub><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D43C TEX-I"></mjx-c></mjx-mi><mjx-script style="vertical-align: -0.15em; margin-left: -0.064em;"><mjx-mi class="mjx-i" size="s"><mjx-c class="mjx-c1D44C TEX-I"></mjx-c></mjx-mi></mjx-script></mjx-msub><mjx-mo class="mjx-n"><mjx-c class="mjx-c2C"></mjx-c></mjx-mo><mjx-mi class="mjx-i" space="2"><mjx-c class="mjx-c1D43D TEX-I"></mjx-c></mjx-mi><mjx-mo class="mjx-n"><mjx-c class="mjx-c5D"></mjx-c></mjx-mo><mjx-mtext class="mjx-n"><mjx-c class="mjx-cA0"></mjx-c></mjx-mtext><mjx-mo class="mjx-n"><mjx-c class="mjx-c7B"></mjx-c></mjx-mo><mjx-msub><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D448 TEX-I"></mjx-c></mjx-mi><mjx-script style="vertical-align: -0.15em; margin-left: -0.084em;"><mjx-mi class="mjx-i" size="s"><mjx-c class="mjx-c1D44B TEX-I"></mjx-c></mjx-mi></mjx-script></mjx-msub><mjx-mo class="mjx-n"><mjx-c class="mjx-c7D"></mjx-c></mjx-mo><mjx-mo class="mjx-n"><mjx-c class="mjx-c29"></mjx-c></mjx-mo></mjx-math><mjx-assistive-mml display="block" unselectable="on"><math display="block" xmlns="http://www.w3.org/1998/Math/MathML"><msub><mtext>AllReduce</mtext><mi>X</mi></msub><mo stretchy="false">(</mo><mi>A</mi><mo stretchy="false">[</mo><msub><mi>I</mi><mi>Y</mi></msub><mo>,</mo><mi>J</mi><mo stretchy="false">]</mo><mtext> </mtext><mo fence="false" stretchy="false">{</mo><msub><mi>U</mi><mi>X</mi></msub><mo fence="false" stretchy="false">}</mo><mo stretchy="false">)</mo></math></mjx-assistive-mml></mjx-container> </span><p>其中我们在一个本身沿另一个轴 <d-math>Y</d-math> 分片的数组上进行 AllReduce。在 TPU 上，此操作的总成本比未分片版本降低了 <d-math>1 / Y</d-math> 的因子，因为我们每个轴发送的数据量是 <d-math>1 / Y</d-math>。在 GPU 上，成本取决于哪个轴是“内部”轴（节点内 vs. 节点间）以及每个分片是否跨越多个节点。假设 <d-math>Y</d-math> 是这里的内部轴，总成本有效地降低了 <d-math>Y</d-math>，但前提是 <d-math>Y</d-math> 跨越多个节点：</p><span> <mjx-container class="MathJax CtxtMenu_Attached_0" ctxtmenu_counter="10" display="true" jax="CHTML" style="font-size: 116.9%; position: relative;" tabindex="0"><mjx-math aria-hidden="true" class="MJX-TEX" display="true" style="margin-left: 0px; margin-right: 0px;"><mjx-msub><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D447 TEX-I"></mjx-c></mjx-mi><mjx-script style="vertical-align: -0.15em; margin-left: -0.12em;"><mjx-mtext class="mjx-n" size="s"><mjx-c class="mjx-c63"></mjx-c><mjx-c class="mjx-c6F"></mjx-c><mjx-c class="mjx-c6D"></mjx-c><mjx-c class="mjx-c6D"></mjx-c><mjx-c class="mjx-c73"></mjx-c><mjx-c class="mjx-c20"></mjx-c><mjx-c class="mjx-c61"></mjx-c><mjx-c class="mjx-c74"></mjx-c><mjx-c class="mjx-c20"></mjx-c><mjx-c class="mjx-c6E"></mjx-c><mjx-c class="mjx-c6F"></mjx-c><mjx-c class="mjx-c64"></mjx-c><mjx-c class="mjx-c65"></mjx-c></mjx-mtext></mjx-script></mjx-msub><mjx-mo class="mjx-n" space="4"><mjx-c class="mjx-c3D"></mjx-c></mjx-mo><mjx-mfrac space="4"><mjx-frac type="d"><mjx-num><mjx-nstrut type="d"></mjx-nstrut><mjx-mrow><mjx-mtext class="mjx-n"><mjx-c class="mjx-c62"></mjx-c><mjx-c class="mjx-c79"></mjx-c><mjx-c class="mjx-c74"></mjx-c><mjx-c class="mjx-c65"></mjx-c><mjx-c class="mjx-c73"></mjx-c></mjx-mtext><mjx-mo class="mjx-n" space="3"><mjx-c class="mjx-c22C5"></mjx-c></mjx-mo><mjx-msub space="3"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D437 TEX-I"></mjx-c></mjx-mi><mjx-script style="vertical-align: -0.15em;"><mjx-mtext class="mjx-n" size="s"><mjx-c class="mjx-c6E"></mjx-c><mjx-c class="mjx-c6F"></mjx-c><mjx-c class="mjx-c64"></mjx-c><mjx-c class="mjx-c65"></mjx-c></mjx-mtext></mjx-script></mjx-msub></mjx-mrow></mjx-num><mjx-dbox><mjx-dtable><mjx-line type="d"></mjx-line><mjx-row><mjx-den><mjx-dstrut type="d"></mjx-dstrut><mjx-mrow><mjx-mo class="mjx-n"><mjx-c class="mjx-c6D"></mjx-c><mjx-c class="mjx-c69"></mjx-c><mjx-c class="mjx-c6E"></mjx-c></mjx-mo><mjx-mo class="mjx-n"><mjx-c class="mjx-c28"></mjx-c></mjx-mo><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D44C TEX-I"></mjx-c></mjx-mi><mjx-mo class="mjx-n"><mjx-c class="mjx-c2C"></mjx-c></mjx-mo><mjx-msub space="2"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D437 TEX-I"></mjx-c></mjx-mi><mjx-script style="vertical-align: -0.15em;"><mjx-mtext class="mjx-n" size="s"><mjx-c class="mjx-c6E"></mjx-c><mjx-c class="mjx-c6F"></mjx-c><mjx-c class="mjx-c64"></mjx-c><mjx-c class="mjx-c65"></mjx-c></mjx-mtext></mjx-script></mjx-msub><mjx-mo class="mjx-n"><mjx-c class="mjx-c29"></mjx-c></mjx-mo><mjx-mo class="mjx-n" space="3"><mjx-c class="mjx-c22C5"></mjx-c></mjx-mo><mjx-msub space="3"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D44A TEX-I"></mjx-c></mjx-mi><mjx-script style="vertical-align: -0.15em; margin-left: -0.104em;"><mjx-mtext class="mjx-n" size="s"><mjx-c class="mjx-c47"></mjx-c><mjx-c class="mjx-c50"></mjx-c><mjx-c class="mjx-c55"></mjx-c><mjx-c class="mjx-c20"></mjx-c><mjx-c class="mjx-c65"></mjx-c><mjx-c class="mjx-c67"></mjx-c><mjx-c class="mjx-c72"></mjx-c><mjx-c class="mjx-c65"></mjx-c><mjx-c class="mjx-c73"></mjx-c><mjx-c class="mjx-c73"></mjx-c></mjx-mtext></mjx-script></mjx-msub></mjx-mrow></mjx-den></mjx-row></mjx-dtable></mjx-dbox></mjx-frac></mjx-mfrac></mjx-math><mjx-assistive-mml display="block" unselectable="on"><math display="block" xmlns="http://www.w3.org/1998/Math/MathML"><msub><mi>T</mi><mtext>comms at node</mtext></msub><mo>=</mo><mfrac><mrow><mtext>bytes</mtext><mo>⋅</mo><msub><mi>D</mi><mtext>node</mtext></msub></mrow><mrow><mo data-mjx-texclass="OP" movablelimits="true">min</mo><mo stretchy="false">(</mo><mi>Y</mi><mo>,</mo><msub><mi>D</mi><mtext>node</mtext></msub><mo stretchy="false">)</mo><mo>⋅</mo><msub><mi>W</mi><mtext>GPU egress</mtext></msub></mrow></mfrac></math></mjx-assistive-mml></mjx-container> <mjx-container class="MathJax CtxtMenu_Attached_0" ctxtmenu_counter="11" display="true" jax="CHTML" style="font-size: 116.9%; position: relative;" tabindex="0"><mjx-math aria-hidden="true" class="MJX-TEX" display="true" style="margin-left: 0px; margin-right: 0px;"><mjx-msub><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D447 TEX-I"></mjx-c></mjx-mi><mjx-script style="vertical-align: -0.15em; margin-left: -0.12em;"><mjx-mtext class="mjx-n" size="s"><mjx-c class="mjx-c63"></mjx-c><mjx-c class="mjx-c6F"></mjx-c><mjx-c class="mjx-c6D"></mjx-c><mjx-c class="mjx-c6D"></mjx-c><mjx-c class="mjx-c73"></mjx-c><mjx-c class="mjx-c20"></mjx-c><mjx-c class="mjx-c69"></mjx-c><mjx-c class="mjx-c6E"></mjx-c><mjx-c class="mjx-c20"></mjx-c><mjx-c class="mjx-c73"></mjx-c><mjx-c class="mjx-c63"></mjx-c><mjx-c class="mjx-c61"></mjx-c><mjx-c class="mjx-c6C"></mjx-c><mjx-c class="mjx-c65"></mjx-c><mjx-c class="mjx-c2D"></mjx-c><mjx-c class="mjx-c6F"></mjx-c><mjx-c class="mjx-c75"></mjx-c><mjx-c class="mjx-c74"></mjx-c><mjx-c class="mjx-c20"></mjx-c><mjx-c class="mjx-c6E"></mjx-c><mjx-c class="mjx-c65"></mjx-c><mjx-c class="mjx-c74"></mjx-c><mjx-c class="mjx-c77"></mjx-c><mjx-c class="mjx-c6F"></mjx-c><mjx-c class="mjx-c72"></mjx-c><mjx-c class="mjx-c6B"></mjx-c></mjx-mtext></mjx-script></mjx-msub><mjx-mo class="mjx-n" space="4"><mjx-c class="mjx-c3D"></mjx-c></mjx-mo><mjx-mfrac space="4"><mjx-frac type="d"><mjx-num><mjx-nstrut type="d"></mjx-nstrut><mjx-mrow><mjx-mtext class="mjx-n"><mjx-c class="mjx-c62"></mjx-c><mjx-c class="mjx-c79"></mjx-c><mjx-c class="mjx-c74"></mjx-c><mjx-c class="mjx-c65"></mjx-c><mjx-c class="mjx-c73"></mjx-c></mjx-mtext><mjx-mo class="mjx-n" space="3"><mjx-c class="mjx-c22C5"></mjx-c></mjx-mo><mjx-mi class="mjx-i" space="3"><mjx-c class="mjx-c1D441 TEX-I"></mjx-c></mjx-mi></mjx-mrow></mjx-num><mjx-dbox><mjx-dtable><mjx-line type="d"></mjx-line><mjx-row><mjx-den><mjx-dstrut type="d"></mjx-dstrut><mjx-mrow><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D44C TEX-I"></mjx-c></mjx-mi><mjx-mo class="mjx-n" space="3"><mjx-c class="mjx-c22C5"></mjx-c></mjx-mo><mjx-msub space="3"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D44A TEX-I"></mjx-c></mjx-mi><mjx-script style="vertical-align: -0.15em; margin-left: -0.104em;"><mjx-mtext class="mjx-n" size="s"><mjx-c class="mjx-c6E"></mjx-c><mjx-c class="mjx-c6F"></mjx-c><mjx-c class="mjx-c64"></mjx-c><mjx-c class="mjx-c65"></mjx-c><mjx-c class="mjx-c20"></mjx-c><mjx-c class="mjx-c65"></mjx-c><mjx-c class="mjx-c67"></mjx-c><mjx-c class="mjx-c72"></mjx-c><mjx-c class="mjx-c65"></mjx-c><mjx-c class="mjx-c73"></mjx-c><mjx-c class="mjx-c73"></mjx-c></mjx-mtext></mjx-script></mjx-msub></mjx-mrow></mjx-den></mjx-row></mjx-dtable></mjx-dbox></mjx-frac></mjx-mfrac></mjx-math><mjx-assistive-mml display="block" unselectable="on"><math display="block" xmlns="http://www.w3.org/1998/Math/MathML"><msub><mi>T</mi><mtext>comms in scale-out network</mtext></msub><mo>=</mo><mfrac><mrow><mtext>bytes</mtext><mo>⋅</mo><mi>N</mi></mrow><mrow><mi>Y</mi><mo>⋅</mo><msub><mi>W</mi><mtext>node egress</mtext></msub></mrow></mfrac></math></mjx-assistive-mml></mjx-container> <mjx-container class="MathJax CtxtMenu_Attached_0" ctxtmenu_counter="12" display="true" jax="CHTML" style="font-size: 116.9%; position: relative;" tabindex="0"><mjx-math aria-hidden="true" class="MJX-TEX" display="true" style="margin-left: 0px; margin-right: 0px;"><mjx-msub><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D447 TEX-I"></mjx-c></mjx-mi><mjx-script style="vertical-align: -0.15em; margin-left: -0.12em;"><mjx-mtext class="mjx-n" size="s"><mjx-c class="mjx-c74"></mjx-c><mjx-c class="mjx-c6F"></mjx-c><mjx-c class="mjx-c74"></mjx-c><mjx-c class="mjx-c61"></mjx-c><mjx-c class="mjx-c6C"></mjx-c></mjx-mtext></mjx-script></mjx-msub><mjx-mo class="mjx-n" space="4"><mjx-c class="mjx-c3D"></mjx-c></mjx-mo><mjx-mo class="mjx-n" space="4"><mjx-c class="mjx-c6D"></mjx-c><mjx-c class="mjx-c61"></mjx-c><mjx-c class="mjx-c78"></mjx-c></mjx-mo><mjx-mo class="mjx-n"><mjx-c class="mjx-c28"></mjx-c></mjx-mo><mjx-msub><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D447 TEX-I"></mjx-c></mjx-mi><mjx-script style="vertical-align: -0.15em; margin-left: -0.12em;"><mjx-mtext class="mjx-n" size="s"><mjx-c class="mjx-c63"></mjx-c><mjx-c class="mjx-c6F"></mjx-c><mjx-c class="mjx-c6D"></mjx-c><mjx-c class="mjx-c6D"></mjx-c><mjx-c class="mjx-c73"></mjx-c><mjx-c class="mjx-c20"></mjx-c><mjx-c class="mjx-c61"></mjx-c><mjx-c class="mjx-c74"></mjx-c><mjx-c class="mjx-c20"></mjx-c><mjx-c class="mjx-c6E"></mjx-c><mjx-c class="mjx-c6F"></mjx-c><mjx-c class="mjx-c64"></mjx-c><mjx-c class="mjx-c65"></mjx-c></mjx-mtext></mjx-script></mjx-msub><mjx-mo class="mjx-n"><mjx-c class="mjx-c2C"></mjx-c></mjx-mo><mjx-msub space="2"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D447 TEX-I"></mjx-c></mjx-mi><mjx-script style="vertical-align: -0.15em; margin-left: -0.12em;"><mjx-mtext class="mjx-n" size="s"><mjx-c class="mjx-c63"></mjx-c><mjx-c class="mjx-c6F"></mjx-c><mjx-c class="mjx-c6D"></mjx-c><mjx-c class="mjx-c6D"></mjx-c><mjx-c class="mjx-c73"></mjx-c><mjx-c class="mjx-c20"></mjx-c><mjx-c class="mjx-c69"></mjx-c><mjx-c class="mjx-c6E"></mjx-c><mjx-c class="mjx-c20"></mjx-c><mjx-c class="mjx-c73"></mjx-c><mjx-c class="mjx-c63"></mjx-c><mjx-c class="mjx-c61"></mjx-c><mjx-c class="mjx-c6C"></mjx-c><mjx-c class="mjx-c65"></mjx-c><mjx-c class="mjx-c2D"></mjx-c><mjx-c class="mjx-c6F"></mjx-c><mjx-c class="mjx-c75"></mjx-c><mjx-c class="mjx-c74"></mjx-c><mjx-c class="mjx-c20"></mjx-c><mjx-c class="mjx-c6E"></mjx-c><mjx-c class="mjx-c65"></mjx-c><mjx-c class="mjx-c74"></mjx-c><mjx-c class="mjx-c77"></mjx-c><mjx-c class="mjx-c6F"></mjx-c><mjx-c class="mjx-c72"></mjx-c><mjx-c class="mjx-c6B"></mjx-c></mjx-mtext></mjx-script></mjx-msub><mjx-mo class="mjx-n"><mjx-c class="mjx-c29"></mjx-c></mjx-mo></mjx-math><mjx-assistive-mml display="block" unselectable="on"><math display="block" xmlns="http://www.w3.org/1998/Math/MathML"><msub><mi>T</mi><mtext>total</mtext></msub><mo>=</mo><mo data-mjx-texclass="OP" movablelimits="true">max</mo><mo stretchy="false">(</mo><msub><mi>T</mi><mtext>comms at node</mtext></msub><mo>,</mo><msub><mi>T</mi><mtext>comms in scale-out network</mtext></msub><mo stretchy="false">)</mo></math></mjx-assistive-mml></mjx-container> </span><p>其中 N 是 GPU 的数量，D 再次是节点中的 GPU 数量（节点的度）。如你所见，如果 <d-math>Y &lt; D_\text{node}</d-math>，我们在节点级别获得了胜利，但通常不会看到总运行时间的减少，而如果 <d-math>Y &gt; D_\text{node}</d-math>，我们会得到一个与跨越的节点数量成比例的加速。</p> <p>如果我们想精确地进行环形规约，对于树形 AllGather<sub>X</sub>(A<sub>Y</sub> { U<sub>X</sub> })（假设 Y 是内部轴）的一般规则是</p><span> <mjx-container class="MathJax CtxtMenu_Attached_0" ctxtmenu_counter="13" display="true" jax="CHTML" style="font-size: 116.9%; position: relative;" tabindex="0"><mjx-math aria-hidden="true" class="MJX-TEX" display="true" style="margin-left: 0px; margin-right: 0px;"><mjx-msub><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D447 TEX-I"></mjx-c></mjx-mi><mjx-script style="vertical-align: -0.153em; margin-left: -0.12em;"><mjx-mtext class="mjx-n" size="s"><mjx-c class="mjx-c41"></mjx-c><mjx-c class="mjx-c52"></mjx-c><mjx-c class="mjx-c20"></mjx-c><mjx-c class="mjx-c6F"></mjx-c><mjx-c class="mjx-c72"></mjx-c><mjx-c class="mjx-c20"></mjx-c><mjx-c class="mjx-c52"></mjx-c><mjx-c class="mjx-c53"></mjx-c><mjx-c class="mjx-c20"></mjx-c><mjx-c class="mjx-c63"></mjx-c><mjx-c class="mjx-c6F"></mjx-c><mjx-c class="mjx-c6D"></mjx-c><mjx-c class="mjx-c6D"></mjx-c><mjx-c class="mjx-c73"></mjx-c></mjx-mtext></mjx-script></mjx-msub><mjx-mo class="mjx-n" space="4"><mjx-c class="mjx-c3D"></mjx-c></mjx-mo><mjx-mtext class="mjx-n" space="4"><mjx-c class="mjx-c62"></mjx-c><mjx-c class="mjx-c79"></mjx-c><mjx-c class="mjx-c74"></mjx-c><mjx-c class="mjx-c65"></mjx-c><mjx-c class="mjx-c73"></mjx-c></mjx-mtext><mjx-mo class="mjx-n" space="3"><mjx-c class="mjx-c22C5"></mjx-c></mjx-mo><mjx-munder space="3"><mjx-row><mjx-base style="padding-left: 0.164em;"><mjx-mo class="mjx-n"><mjx-c class="mjx-c6D"></mjx-c><mjx-c class="mjx-c61"></mjx-c><mjx-c class="mjx-c78"></mjx-c></mjx-mo></mjx-base></mjx-row><mjx-row><mjx-under style="padding-top: 0.167em;"><mjx-texatom size="s" texclass="ORD"><mjx-mtext class="mjx-n"><mjx-c class="mjx-c64"></mjx-c><mjx-c class="mjx-c65"></mjx-c><mjx-c class="mjx-c70"></mjx-c><mjx-c class="mjx-c74"></mjx-c><mjx-c class="mjx-c68"></mjx-c><mjx-c class="mjx-cA0"></mjx-c></mjx-mtext><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D456 TEX-I"></mjx-c></mjx-mi></mjx-texatom></mjx-under></mjx-row></mjx-munder><mjx-mrow space="2"><mjx-mo class="mjx-s3"><mjx-c class="mjx-c5B TEX-S3"></mjx-c></mjx-mo><mjx-mfrac><mjx-frac type="d"><mjx-num><mjx-nstrut type="d"></mjx-nstrut><mjx-mrow><mjx-msub><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D437 TEX-I"></mjx-c></mjx-mi><mjx-script style="vertical-align: -0.15em;"><mjx-mi class="mjx-i" size="s"><mjx-c class="mjx-c1D456 TEX-I"></mjx-c></mjx-mi></mjx-script></mjx-msub><mjx-mo class="mjx-n" space="3"><mjx-c class="mjx-c2212"></mjx-c></mjx-mo><mjx-mn class="mjx-n" space="3"><mjx-c class="mjx-c31"></mjx-c></mjx-mn></mjx-mrow></mjx-num><mjx-dbox><mjx-dtable><mjx-line type="d"></mjx-line><mjx-row><mjx-den><mjx-dstrut type="d"></mjx-dstrut><mjx-mrow><mjx-msub><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D437 TEX-I"></mjx-c></mjx-mi><mjx-script style="vertical-align: -0.15em;"><mjx-mi class="mjx-i" size="s"><mjx-c class="mjx-c1D456 TEX-I"></mjx-c></mjx-mi></mjx-script></mjx-msub><mjx-mo class="mjx-n" space="3"><mjx-c class="mjx-c22C5"></mjx-c></mjx-mo><mjx-mo class="mjx-n" space="3"><mjx-c class="mjx-c6D"></mjx-c><mjx-c class="mjx-c61"></mjx-c><mjx-c class="mjx-c78"></mjx-c></mjx-mo><mjx-mo class="mjx-n"><mjx-c class="mjx-c28"></mjx-c></mjx-mo><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D44C TEX-I"></mjx-c></mjx-mi><mjx-mo class="mjx-n"><mjx-c class="mjx-c2C"></mjx-c></mjx-mo><mjx-msub space="2"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D446 TEX-I"></mjx-c></mjx-mi><mjx-script style="vertical-align: -0.15em; margin-left: -0.032em;"><mjx-texatom size="s" texclass="ORD"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D456 TEX-I"></mjx-c></mjx-mi><mjx-mo class="mjx-n"><mjx-c class="mjx-c2212"></mjx-c></mjx-mo><mjx-mn class="mjx-n"><mjx-c class="mjx-c31"></mjx-c></mjx-mn></mjx-texatom></mjx-script></mjx-msub><mjx-mo class="mjx-n"><mjx-c class="mjx-c29"></mjx-c></mjx-mo><mjx-mo class="mjx-n" space="3"><mjx-c class="mjx-c22C5"></mjx-c></mjx-mo><mjx-msub space="3"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D44A TEX-I"></mjx-c></mjx-mi><mjx-script style="vertical-align: -0.15em; margin-left: -0.104em;"><mjx-texatom size="s" texclass="ORD"><mjx-mtext class="mjx-n"><mjx-c class="mjx-c6C"></mjx-c><mjx-c class="mjx-c69"></mjx-c><mjx-c class="mjx-c6E"></mjx-c><mjx-c class="mjx-c6B"></mjx-c><mjx-c class="mjx-cA0"></mjx-c></mjx-mtext><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D456 TEX-I"></mjx-c></mjx-mi></mjx-texatom></mjx-script></mjx-msub></mjx-mrow></mjx-den></mjx-row></mjx-dtable></mjx-dbox></mjx-frac></mjx-mfrac><mjx-mo class="mjx-s3"><mjx-c class="mjx-c5D TEX-S3"></mjx-c></mjx-mo></mjx-mrow></mjx-math><mjx-assistive-mml display="block" unselectable="on"><math display="block" xmlns="http://www.w3.org/1998/Math/MathML"><msub><mi>T</mi><mtext>AR or RS comms</mtext></msub><mo>=</mo><mtext>bytes</mtext><mo>⋅</mo><munder><mo data-mjx-texclass="OP" movablelimits="true">max</mo><mrow data-mjx-texclass="ORD"><mtext>depth </mtext><mi>i</mi></mrow></munder><mrow data-mjx-texclass="INNER"><mo data-mjx-texclass="OPEN">[</mo><mfrac><mrow><msub><mi>D</mi><mi>i</mi></msub><mo>−</mo><mn>1</mn></mrow><mrow><msub><mi>D</mi><mi>i</mi></msub><mo>⋅</mo><mo data-mjx-texclass="OP" movablelimits="true">max</mo><mo stretchy="false">(</mo><mi>Y</mi><mo>,</mo><msub><mi>S</mi><mrow data-mjx-texclass="ORD"><mi>i</mi><mo>−</mo><mn>1</mn></mrow></msub><mo stretchy="false">)</mo><mo>⋅</mo><msub><mi>W</mi><mrow data-mjx-texclass="ORD"><mtext>link </mtext><mi>i</mi></mrow></msub></mrow></mfrac><mo data-mjx-texclass="CLOSE">]</mo></mrow></math></mjx-assistive-mml></mjx-container> </span><p>其中 <d-math>S_i</d-math> 是 M * N * …，即树中 i 级以下子节点的大小。这大致是说，我们跨越的 GPU 或节点越多，我们可用的带宽就越大，但仅限于该节点内。</p> <p><strong>即时测验 3 [沿 2 个轴分片]：</strong> 假设我们想在单个 SU（256 个芯片）上执行 <d-math>\text{AllGather}_X(\text{bf16}[D_X, F_Y])</d-math>，其中 <d-math>Y</d-math> 是内部轴。这将花费多长时间，作为 <d-math>D</d-math>、<d-math>F</d-math> 和 <d-math>Y</d-math> 的函数？</p> <details><summary>点击此处查看答案。</summary> <p><strong>答案：</strong> 我们可以将其分为两种情况，Y &lt;= 8 和 Y &gt; 8。当 <d-math>Y &lt;= 8</d-math> 时，我们仍然受叶交换机的限制，所以答案像往常一样是 <d-math>T_\text{comms} = 2 * D * F * (32 - 1) / (32 * 400e9)</d-math>。当 Y &gt; 8 时，我们从上面得到，大约是</p> <mjx-container class="MathJax CtxtMenu_Attached_0" ctxtmenu_counter="14" display="true" jax="CHTML" style="font-size: 116.9%; position: relative;" tabindex="0"><mjx-math aria-hidden="true" class="MJX-TEX" display="true" style="margin-left: 0px; margin-right: 0px;"><mjx-msub><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D447 TEX-I"></mjx-c></mjx-mi><mjx-script style="vertical-align: -0.15em; margin-left: -0.12em;"><mjx-mtext class="mjx-n" size="s"><mjx-c class="mjx-c63"></mjx-c><mjx-c class="mjx-c6F"></mjx-c><mjx-c class="mjx-c6D"></mjx-c><mjx-c class="mjx-c6D"></mjx-c><mjx-c class="mjx-c73"></mjx-c></mjx-mtext></mjx-script></mjx-msub><mjx-mo class="mjx-n" space="4"><mjx-c class="mjx-c3D"></mjx-c></mjx-mo><mjx-mfrac space="4"><mjx-frac type="d"><mjx-num><mjx-nstrut type="d"></mjx-nstrut><mjx-mrow><mjx-mn class="mjx-n"><mjx-c class="mjx-c32"></mjx-c></mjx-mn><mjx-mo class="mjx-n" space="3"><mjx-c class="mjx-c22C5"></mjx-c></mjx-mo><mjx-mi class="mjx-i" space="3"><mjx-c class="mjx-c1D437 TEX-I"></mjx-c></mjx-mi><mjx-mo class="mjx-n" space="3"><mjx-c class="mjx-c22C5"></mjx-c></mjx-mo><mjx-mi class="mjx-i" space="3"><mjx-c class="mjx-c1D439 TEX-I"></mjx-c></mjx-mi><mjx-mo class="mjx-n" space="3"><mjx-c class="mjx-c22C5"></mjx-c></mjx-mo><mjx-mn class="mjx-n" space="3"><mjx-c class="mjx-c32"></mjx-c><mjx-c class="mjx-c35"></mjx-c><mjx-c class="mjx-c36"></mjx-c></mjx-mn></mjx-mrow></mjx-num><mjx-dbox><mjx-dtable><mjx-line type="d"></mjx-line><mjx-row><mjx-den><mjx-dstrut type="d"></mjx-dstrut><mjx-mrow><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D44C TEX-I"></mjx-c></mjx-mi><mjx-mo class="mjx-n" space="3"><mjx-c class="mjx-c22C5"></mjx-c></mjx-mo><mjx-mtext class="mjx-n" space="3"><mjx-c class="mjx-c31"></mjx-c><mjx-c class="mjx-c32"></mjx-c><mjx-c class="mjx-c2E"></mjx-c><mjx-c class="mjx-c38"></mjx-c><mjx-c class="mjx-c65"></mjx-c><mjx-c class="mjx-c31"></mjx-c><mjx-c class="mjx-c32"></mjx-c></mjx-mtext></mjx-mrow></mjx-den></mjx-row></mjx-dtable></mjx-dbox></mjx-frac></mjx-mfrac><mjx-mo class="mjx-n" space="4"><mjx-c class="mjx-c3D"></mjx-c></mjx-mo><mjx-mfrac space="4"><mjx-frac type="d"><mjx-num><mjx-nstrut type="d"></mjx-nstrut><mjx-mrow><mjx-mn class="mjx-n"><mjx-c class="mjx-c32"></mjx-c></mjx-mn><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D437 TEX-I"></mjx-c></mjx-mi><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D439 TEX-I"></mjx-c></mjx-mi></mjx-mrow></mjx-num><mjx-dbox><mjx-dtable><mjx-line type="d"></mjx-line><mjx-row><mjx-den><mjx-dstrut type="d"></mjx-dstrut><mjx-mrow><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D44C TEX-I"></mjx-c></mjx-mi><mjx-mo class="mjx-n" space="3"><mjx-c class="mjx-c22C5"></mjx-c></mjx-mo><mjx-mtext class="mjx-n" space="3"><mjx-c class="mjx-c35"></mjx-c><mjx-c class="mjx-c30"></mjx-c><mjx-c class="mjx-c47"></mjx-c><mjx-c class="mjx-c42"></mjx-c><mjx-c class="mjx-c2F"></mjx-c><mjx-c class="mjx-c73"></mjx-c></mjx-mtext></mjx-mrow></mjx-den></mjx-row></mjx-dtable></mjx-dbox></mjx-frac></mjx-mfrac></mjx-math><mjx-assistive-mml display="block" unselectable="on"><math display="block" xmlns="http://www.w3.org/1998/Math/MathML"><msub><mi>T</mi><mtext>comms</mtext></msub><mo>=</mo><mfrac><mrow><mn>2</mn><mo>⋅</mo><mi>D</mi><mo>⋅</mo><mi>F</mi><mo>⋅</mo><mn>256</mn></mrow><mrow><mi>Y</mi><mo>⋅</mo><mtext>12.8e12</mtext></mrow></mfrac><mo>=</mo><mfrac><mrow><mn>2</mn><mi>D</mi><mi>F</mi></mrow><mrow><mi>Y</mi><mo>⋅</mo><mtext>50GB/s</mtext></mrow></mfrac></math></mjx-assistive-mml></mjx-container> <p>对于 <code class="language-plaintext highlighter-rouge">D = 8192</code>，<code class="language-plaintext highlighter-rouge">F = 32,768</code>，我们有：</p> <figure> <picture> <img class="img-fluid" height="auto" loading="lazy" onerror="this.onerror=null; $('.responsive-img-srcset').remove();" src="https://jax-ml.github.io/scaling-book/assets/gpu/sharded-all-gather-cost.png" width="100%"/> </picture> <figcaption class="caption"><b>图：</b>当内部轴跨越更多节点时，分片 AllGather 的理论成本。</figcaption> </figure> <p>请注意，如果我们恰好进行 8 路模型并行，我们确实将节点级规约的成本降低了 8 倍，但总成本保持不变，所以这是免费的，但对提高总带宽没有帮助。</p> </details> <p class="takeaway"><strong>要点：</strong>当我们有多个分片轴时，外部规约的成本会因内部轴跨越的节点数量而降低。</p> <h3 id="quiz-4-collectives">测验 4：集合通信</h3> <p><strong>问题 1 [SU AllGather]：</strong> 仅考虑一个具有 M 个节点和每个节点 N 个 GPU 的 SU。在 AllGather 期间，节点级交换机精确地入口和出口多少字节？顶层交换机呢？</p> <details><summary>点击此处查看答案。</summary> <p><strong>答案：</strong> 让我们一步一步来，分析规约的组成部分：</p> <ol> <li>每个 GPU 向交换机发送 <d-math>B / MN</d-math> 字节，总入口量为 <d-math>NB / MN = B / M</d-math> 字节。</li> <li>我们将全部 <d-math>B / M</d-math> 字节出口到脊交换机。</li> <li>我们从脊交换机入口 <d-math>B * (M - 1) / M</d-math> 字节。</li> <li>我们出口 <d-math>B - B / MN</d-math> 字节 <d-math>N</d-math> 次，总共是 <d-math>N * (B - B / MN) = NB - B / M</d-math>。</li> </ol> <p>总共是 <d-math>B</d-math> 入口和 <d-math>BN</d-math> 出口，所以我们应该受出口的瓶颈限制，总时间将是 <d-math>T_\text{AllGather} = BN / W_\text{node} = B / \text{450e9}</d-math>。</p> <p>对于脊交换机，数学实际上更简单。我们必须有 <d-math>B / M</d-math> 字节入口 M 次（总共 <d-math>B</d-math> 字节），然后 <d-math>B (M - 1) / M</d-math> 出口 <d-math>M</d-math> 次，总共是 <d-math>B * (M - 1)</d-math> 出口。由于这个数字明显更大，成本是 <d-math>T_\text{AllGather} = B \cdot (M - 1) / (M \cdot W_\text{node}) = B \cdot (M - 1) / (M \cdot \text{400e9})</d-math>。</p> </details> <p><strong>问题 2 [单节点 SHARP AR]：</strong> 考虑一个具有 N 个 GPU 的单节点。在使用 SHARP（网络内规约）进行 AllReduce 期间，交换机精确地入口和出口多少字节？</p> <details><summary>点击此处查看答案。</summary> <p><strong>答案：</strong> 和以前一样，让我们一步一步来。</p> <ol> <li>每个 GPU 发送 <d-math>B * (N - 1) / N</d-math> 字节，所以我们有 <d-math>N * B * (N - 1) / N = B * (N - 1)</d-math> 字节入口。</li> <li>我们累加部分和，然后向每个 GPU 发回 <d-math>B / N</d-math> 字节，所以 <d-math>N * B / N = B</d-math> 字节出口。</li> <li>我们在本地对残差进行部分求和，然后将其发送回交换机。这总共是 <d-math>N * B / N = B</d-math> 字节入口。</li> <li>我们捕获所有分片并进行多播，向 <d-math>N</d-math> 个目的地发送 <d-math>B * (N - 1) / N</d-math>，总共是 <d-math>B * (N - 1) / N * N = B * (N - 1)</d-math> 字节出口。</li> </ol> <p>因此，总共有 <d-math>B * (N - 1) + B = BN</d-math> 字节入口和出口。这支持总吞吐量恰好是 <d-math>B / W_\text{egress}</d-math>。</p> </details> <p><strong>问题 3 [跨节点 SHARP AR]：</strong> 考虑一个在单个 N GPU 节点上分片的数组 bf16[D<sub>X</sub>, F<sub>Y</sub>]。AllReduce(bf16[D, F<sub>Y</sub>] { U<sub>X</sub> }) 需要多长时间？你可以假设我们进行网络内规约。解释一下如果我们有多个节点，这会有什么不同？</p> <details><summary>点击此处查看答案。</summary> <p><strong>答案：</strong> 我们可以尝试修改上面问题的答案。基本上，我们首先从每个 GPU 出口 <d-math>B * (X - 1) / XY</d-math> 字节，然后向每个 GPU 发回 <d-math>B / XY</d-math>，然后将相同的量发回交换机，然后向每个 GPU 发回 <d-math>B * (X - 1) / XY</d-math>。总共是 <d-math>NB / Y</d-math> 入口和出口，所以总时间是 <d-math>T_\text{comms} = NB / (Y * N * W_\text{link}) = N * 2DF / (Y * N * W_\text{link}) = 2 * D * F / (Y * W_\text{link})</d-math>，所以总时间确实随着 <d-math>Y</d-math> 的增加而减少。</p> <p>如果我们超越单个节点，我们可以进行与上面大致相同的规约，但是当我们从节点级交换机出口时，我们需要发送所有 B 字节，而不仅仅是 <d-math>B / Y</d-math>。这是因为我们需要保持每个分片的分离。</p> </details> <p><strong>问题 4 [脊级别 AR 成本]：</strong> 考虑与上面相同的设置，但是 <d-math>Y = 256</d-math>（所以 AR 发生在脊级别）。AllReduce 需要多长时间？同样，可以假设网络内规约。</p> <details><summary>点击此处查看答案。</summary> <p><strong>答案：</strong> 这让我们能够利用脊级别相当惊人的带宽。我们在 4 个节点上有 25.6TB/s 的带宽，所以 AllReduce 带宽是 6.4TB/s。使用 SHARP，这可能只需要 <code class="language-plaintext highlighter-rouge">2 * D * F / 6.4e12</code> 秒。</p> </details> <p><strong>问题 5 [2 路 AllGather 成本]：</strong> 考虑在恰好 2 个节点上进行 AllGather 的成本。精确地说，它是什么？确保计算精确成本而不是近似值。</p> <details><summary>点击此处查看答案。</summary> <p><strong>答案：</strong> 在节点级别，我们有 <d-math>T_\text{comms} = B * 7 / (8 * \text{450e9}) = B / \text{514e9}</d-math>，而在节点之外，我们实际上有 <d-math>T_\text{comms} = B * (2 - 1) / (2 * \text{400e9}) = B / \text{800e9}</d-math>。因此，我们实际上受节点级规约的限制，而不是叶级别！这激励了例如 DeepSeek v3，它进行 2 路数据并行。</p> </details> <h2 id="rooflines-for-llm-scaling-on-gpus">GPU 上 LLM 扩展的屋顶线模型</h2> <p>现在让我们看看这一切都是为了什么：理解 GPU 上 LLM 扩展的屋顶线模型。这是对 TPU 训练章节<a href="training.html">这里</a>的补充。和那里一样，这里的目标是查看不同并行策略的总 <d-math>T_\text{math}</d-math> 和 <d-math>T_\text{comms}</d-math>，并理解在什么点上 <d-math>T_\text{comms} &gt; T_\text{math}</d-math>。和以前一样，我们只考虑 MLP 块，操作为</p><span> <mjx-container class="MathJax CtxtMenu_Attached_0" ctxtmenu_counter="15" display="true" jax="CHTML" style="font-size: 116.9%; position: relative;" tabindex="0"><mjx-math aria-hidden="true" class="MJX-TEX" display="true" style="margin-left: 0px; margin-right: 0px;"><mjx-mtext class="mjx-n"><mjx-c class="mjx-c4D"></mjx-c><mjx-c class="mjx-c4C"></mjx-c><mjx-c class="mjx-c50"></mjx-c></mjx-mtext><mjx-mo class="mjx-n"><mjx-c class="mjx-c28"></mjx-c></mjx-mo><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D465 TEX-I"></mjx-c></mjx-mi><mjx-mo class="mjx-n"><mjx-c class="mjx-c29"></mjx-c></mjx-mo><mjx-mo class="mjx-n" space="4"><mjx-c class="mjx-c2261"></mjx-c></mjx-mo><mjx-mi class="mjx-i" space="4"><mjx-c class="mjx-c1D465 TEX-I"></mjx-c></mjx-mi><mjx-mo class="mjx-n"><mjx-c class="mjx-c5B"></mjx-c></mjx-mo><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D435 TEX-I"></mjx-c></mjx-mi><mjx-mo class="mjx-n"><mjx-c class="mjx-c2C"></mjx-c></mjx-mo><mjx-mi class="mjx-i" space="2"><mjx-c class="mjx-c1D437 TEX-I"></mjx-c></mjx-mi><mjx-mo class="mjx-n"><mjx-c class="mjx-c5D"></mjx-c></mjx-mo><mjx-msub space="3"><mjx-mo class="mjx-n"><mjx-c class="mjx-c2217"></mjx-c></mjx-mo><mjx-script style="vertical-align: -0.15em;"><mjx-mi class="mjx-i" size="s"><mjx-c class="mjx-c1D437 TEX-I"></mjx-c></mjx-mi></mjx-script></mjx-msub><mjx-msub space="3"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D44A TEX-I"></mjx-c></mjx-mi><mjx-script style="vertical-align: -0.15em; margin-left: -0.104em;"><mjx-mtext class="mjx-n" size="s"><mjx-c class="mjx-c69"></mjx-c><mjx-c class="mjx-c6E"></mjx-c></mjx-mtext></mjx-script></mjx-msub><mjx-mo class="mjx-n"><mjx-c class="mjx-c5B"></mjx-c></mjx-mo><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D437 TEX-I"></mjx-c></mjx-mi><mjx-mo class="mjx-n"><mjx-c class="mjx-c2C"></mjx-c></mjx-mo><mjx-mi class="mjx-i" space="2"><mjx-c class="mjx-c1D439 TEX-I"></mjx-c></mjx-mi><mjx-mo class="mjx-n"><mjx-c class="mjx-c5D"></mjx-c></mjx-mo><mjx-msub space="3"><mjx-mo class="mjx-n"><mjx-c class="mjx-c22C5"></mjx-c></mjx-mo><mjx-script style="vertical-align: -0.15em;"><mjx-mi class="mjx-i" size="s"><mjx-c class="mjx-c1D439 TEX-I"></mjx-c></mjx-mi></mjx-script></mjx-msub><mjx-msub space="3"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D44A TEX-I"></mjx-c></mjx-mi><mjx-script style="vertical-align: -0.15em; margin-left: -0.104em;"><mjx-mtext class="mjx-n" size="s"><mjx-c class="mjx-c6F"></mjx-c><mjx-c class="mjx-c75"></mjx-c><mjx-c class="mjx-c74"></mjx-c></mjx-mtext></mjx-script></mjx-msub><mjx-mo class="mjx-n"><mjx-c class="mjx-c5B"></mjx-c></mjx-mo><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D439 TEX-I"></mjx-c></mjx-mi><mjx-mo class="mjx-n"><mjx-c class="mjx-c2C"></mjx-c></mjx-mo><mjx-mi class="mjx-i" space="2"><mjx-c class="mjx-c1D437 TEX-I"></mjx-c></mjx-mi><mjx-mo class="mjx-n"><mjx-c class="mjx-c5D"></mjx-c></mjx-mo></mjx-math><mjx-assistive-mml display="block" unselectable="on"><math display="block" xmlns="http://www.w3.org/1998/Math/MathML"><mtext>MLP</mtext><mo stretchy="false">(</mo><mi>x</mi><mo stretchy="false">)</mo><mo>≡</mo><mi>x</mi><mo stretchy="false">[</mo><mi>B</mi><mo>,</mo><mi>D</mi><mo stretchy="false">]</mo><msub><mo>∗</mo><mi>D</mi></msub><msub><mi>W</mi><mtext>in</mtext></msub><mo stretchy="false">[</mo><mi>D</mi><mo>,</mo><mi>F</mi><mo stretchy="false">]</mo><msub><mo>⋅</mo><mi>F</mi></msub><msub><mi>W</mi><mtext>out</mtext></msub><mo stretchy="false">[</mo><mi>F</mi><mo>,</mo><mi>D</mi><mo stretchy="false">]</mo></math></mjx-assistive-mml></mjx-container> </span><p>其中 <d-math>B</d-math> 是全局批处理大小（<strong>以 token 为单位</strong>），即 <d-math>B = \text{batch size} \cdot \text{sequence length}</d-math>。</p> <p>这里我们将重现上面的表格，显示 GPU 和节点级别的有效带宽：</p> <table class="table-hover" data-toggle="table"> <thead> <tr> <th style="text-align: center">节点类型</th> <th style="text-align: center">每节点 GPU 数</th> <th style="text-align: center">GPU 出口带宽</th> <th style="text-align: center">节点出口带宽</th> </tr> </thead> <tbody> <tr> <td style="text-align: center">H100</td> <td style="text-align: center">8</td> <td style="text-align: center">450e9</td> <td style="text-align: center">400e9</td> </tr> <tr> <td style="text-align: center">B200</td> <td style="text-align: center">8</td> <td style="text-align: center">900e9</td> <td style="text-align: center">400e9</td> </tr> <tr> <td style="text-align: center">GB200 NVL72</td> <td style="text-align: center">72</td> <td style="text-align: center">900e9</td> <td style="text-align: center">3600e9</td> </tr> </tbody> </table> <p><strong>注意：</strong> GPU 和节点的出口带宽都决定了我们 LLM 的屋顶线模型。我们将使用术语 <d-math>W_\text{collective}</d-math> 来描述 GPU 或节点的带宽，具体取决于我们是在节点内还是节点之上操作。</p> <p>让我们像为 TPU 做的那样，为<strong>数据并行、张量并行、流水线并行、专家并行</strong>以及它们的组合，看看计算通信的屋顶线模型。本节的其余部分，我们将专注于 H100 的屋顶线模型进行具体计算。GB200-NVL72 具有相同的通用屋顶线模型，但因为我们有更大的节点出口带宽，我们有时可能会在节点级别遇到瓶颈。</p> <h3 id="data-parallelism">数据并行性</h3> <p>如前所述，DP 和 ZeRO 分片在反向传播中涉及权重 AllReduce 或 ReduceScatter + AllGather。由于这两者的成本相同，要使纯数据并行或 FSDP <em>没有网络内规约</em>的情况下达到计算密集型，我们每层在反向传播中，对于大小为 X 的轴有：</p><span> <mjx-container class="MathJax CtxtMenu_Attached_0" ctxtmenu_counter="16" display="true" jax="CHTML" style="font-size: 116.9%; position: relative;" tabindex="0"><mjx-math aria-hidden="true" class="MJX-TEX" display="true" style="margin-left: 0px; margin-right: 0px;"><mjx-msub><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D447 TEX-I"></mjx-c></mjx-mi><mjx-script style="vertical-align: -0.15em; margin-left: -0.12em;"><mjx-mtext class="mjx-n" size="s"><mjx-c class="mjx-c6D"></mjx-c><mjx-c class="mjx-c61"></mjx-c><mjx-c class="mjx-c74"></mjx-c><mjx-c class="mjx-c68"></mjx-c></mjx-mtext></mjx-script></mjx-msub><mjx-mo class="mjx-n" space="4"><mjx-c class="mjx-c3D"></mjx-c></mjx-mo><mjx-mfrac space="4"><mjx-frac type="d"><mjx-num><mjx-nstrut type="d"></mjx-nstrut><mjx-mrow><mjx-mn class="mjx-n"><mjx-c class="mjx-c32"></mjx-c></mjx-mn><mjx-mo class="mjx-n" space="3"><mjx-c class="mjx-c22C5"></mjx-c></mjx-mo><mjx-mn class="mjx-n" space="3"><mjx-c class="mjx-c32"></mjx-c></mjx-mn><mjx-mo class="mjx-n" space="3"><mjx-c class="mjx-c22C5"></mjx-c></mjx-mo><mjx-mn class="mjx-n" space="3"><mjx-c class="mjx-c32"></mjx-c></mjx-mn><mjx-mo class="mjx-n" space="3"><mjx-c class="mjx-c22C5"></mjx-c></mjx-mo><mjx-mi class="mjx-i" space="3"><mjx-c class="mjx-c1D435 TEX-I"></mjx-c></mjx-mi><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D437 TEX-I"></mjx-c></mjx-mi><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D439 TEX-I"></mjx-c></mjx-mi></mjx-mrow></mjx-num><mjx-dbox><mjx-dtable><mjx-line type="d"></mjx-line><mjx-row><mjx-den><mjx-dstrut type="d"></mjx-dstrut><mjx-mrow><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D44B TEX-I"></mjx-c></mjx-mi><mjx-mo class="mjx-n" space="3"><mjx-c class="mjx-c22C5"></mjx-c></mjx-mo><mjx-mi class="mjx-i" space="3"><mjx-c class="mjx-c1D436 TEX-I"></mjx-c></mjx-mi></mjx-mrow></mjx-den></mjx-row></mjx-dtable></mjx-dbox></mjx-frac></mjx-mfrac></mjx-math><mjx-assistive-mml display="block" unselectable="on"><math display="block" xmlns="http://www.w3.org/1998/Math/MathML"><msub><mi>T</mi><mtext>math</mtext></msub><mo>=</mo><mfrac><mrow><mn>2</mn><mo>⋅</mo><mn>2</mn><mo>⋅</mo><mn>2</mn><mo>⋅</mo><mi>B</mi><mi>D</mi><mi>F</mi></mrow><mrow><mi>X</mi><mo>⋅</mo><mi>C</mi></mrow></mfrac></math></mjx-assistive-mml></mjx-container> <mjx-container class="MathJax CtxtMenu_Attached_0" ctxtmenu_counter="17" display="true" jax="CHTML" style="font-size: 116.9%; position: relative;" tabindex="0"><mjx-math aria-hidden="true" class="MJX-TEX" display="true" style="margin-left: 0px; margin-right: 0px;"><mjx-msub><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D447 TEX-I"></mjx-c></mjx-mi><mjx-script style="vertical-align: -0.15em; margin-left: -0.12em;"><mjx-mtext class="mjx-n" size="s"><mjx-c class="mjx-c63"></mjx-c><mjx-c class="mjx-c6F"></mjx-c><mjx-c class="mjx-c6D"></mjx-c><mjx-c class="mjx-c6D"></mjx-c><mjx-c class="mjx-c73"></mjx-c></mjx-mtext></mjx-script></mjx-msub><mjx-mo class="mjx-n" space="4"><mjx-c class="mjx-c3D"></mjx-c></mjx-mo><mjx-mfrac space="4"><mjx-frac type="d"><mjx-num><mjx-nstrut type="d"></mjx-nstrut><mjx-mrow><mjx-mn class="mjx-n"><mjx-c class="mjx-c32"></mjx-c></mjx-mn><mjx-mo class="mjx-n" space="3"><mjx-c class="mjx-c22C5"></mjx-c></mjx-mo><mjx-mn class="mjx-n" space="3"><mjx-c class="mjx-c32"></mjx-c></mjx-mn><mjx-mo class="mjx-n" space="3"><mjx-c class="mjx-c22C5"></mjx-c></mjx-mo><mjx-mn class="mjx-n" space="3"><mjx-c class="mjx-c32"></mjx-c></mjx-mn><mjx-mo class="mjx-n" space="3"><mjx-c class="mjx-c22C5"></mjx-c></mjx-mo><mjx-mi class="mjx-i" space="3"><mjx-c class="mjx-c1D437 TEX-I"></mjx-c></mjx-mi><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D439 TEX-I"></mjx-c></mjx-mi></mjx-mrow></mjx-num><mjx-dbox><mjx-dtable><mjx-line type="d"></mjx-line><mjx-row><mjx-den><mjx-dstrut type="d"></mjx-dstrut><mjx-msub><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D44A TEX-I"></mjx-c></mjx-mi><mjx-script style="vertical-align: -0.15em; margin-left: -0.104em;"><mjx-mtext class="mjx-n" size="s"><mjx-c class="mjx-c63"></mjx-c><mjx-c class="mjx-c6F"></mjx-c><mjx-c class="mjx-c6C"></mjx-c><mjx-c class="mjx-c6C"></mjx-c><mjx-c class="mjx-c65"></mjx-c><mjx-c class="mjx-c63"></mjx-c><mjx-c class="mjx-c74"></mjx-c><mjx-c class="mjx-c69"></mjx-c><mjx-c class="mjx-c76"></mjx-c><mjx-c class="mjx-c65"></mjx-c></mjx-mtext></mjx-script></mjx-msub></mjx-den></mjx-row></mjx-dtable></mjx-dbox></mjx-frac></mjx-mfrac></mjx-math><mjx-assistive-mml display="block" unselectable="on"><math display="block" xmlns="http://www.w3.org/1998/Math/MathML"><msub><mi>T</mi><mtext>comms</mtext></msub><mo>=</mo><mfrac><mrow><mn>2</mn><mo>⋅</mo><mn>2</mn><mo>⋅</mo><mn>2</mn><mo>⋅</mo><mi>D</mi><mi>F</mi></mrow><msub><mi>W</mi><mtext>collective</mtext></msub></mfrac></math></mjx-assistive-mml></mjx-container> </span><p>因此，要使 <d-math>T_\text{math} &gt; T_\text{comms}</d-math>，我们需要 <d-math>B / (XC) &gt; 1 / W_\text{collective}</d-math> 或</p><span> <mjx-container class="MathJax CtxtMenu_Attached_0" ctxtmenu_counter="18" display="true" jax="CHTML" style="font-size: 116.9%; position: relative;" tabindex="0"><mjx-math aria-hidden="true" class="MJX-TEX" display="true" style="margin-left: 0px; margin-right: 0px;"><mjx-mfrac><mjx-frac type="d"><mjx-num><mjx-nstrut type="d"></mjx-nstrut><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D435 TEX-I"></mjx-c></mjx-mi></mjx-num><mjx-dbox><mjx-dtable><mjx-line type="d"></mjx-line><mjx-row><mjx-den><mjx-dstrut type="d"></mjx-dstrut><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D44B TEX-I"></mjx-c></mjx-mi></mjx-den></mjx-row></mjx-dtable></mjx-dbox></mjx-frac></mjx-mfrac><mjx-mo class="mjx-n" space="4"><mjx-c class="mjx-c3E"></mjx-c></mjx-mo><mjx-mfrac space="4"><mjx-frac type="d"><mjx-num><mjx-nstrut type="d"></mjx-nstrut><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D436 TEX-I"></mjx-c></mjx-mi></mjx-num><mjx-dbox><mjx-dtable><mjx-line type="d"></mjx-line><mjx-row><mjx-den><mjx-dstrut type="d"></mjx-dstrut><mjx-msub><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D44A TEX-I"></mjx-c></mjx-mi><mjx-script style="vertical-align: -0.15em; margin-left: -0.104em;"><mjx-mtext class="mjx-n" size="s"><mjx-c class="mjx-c63"></mjx-c><mjx-c class="mjx-c6F"></mjx-c><mjx-c class="mjx-c6C"></mjx-c><mjx-c class="mjx-c6C"></mjx-c><mjx-c class="mjx-c65"></mjx-c><mjx-c class="mjx-c63"></mjx-c><mjx-c class="mjx-c74"></mjx-c><mjx-c class="mjx-c69"></mjx-c><mjx-c class="mjx-c76"></mjx-c><mjx-c class="mjx-c65"></mjx-c></mjx-mtext></mjx-script></mjx-msub></mjx-den></mjx-row></mjx-dtable></mjx-dbox></mjx-frac></mjx-mfrac></mjx-math><mjx-assistive-mml display="block" unselectable="on"><math display="block" xmlns="http://www.w3.org/1998/Math/MathML"><mfrac><mi>B</mi><mi>X</mi></mfrac><mo>&gt;</mo><mfrac><mi>C</mi><msub><mi>W</mi><mtext>collective</mtext></msub></mfrac></math></mjx-assistive-mml></mjx-container> </span><p>其中 <d-math>W_\text{collective}</d-math> 是 GPU 或节点级别的出口带宽，取决于我们是在节点内还是跨节点分片。因此：</p> <ul> <li> <strong>在节点内</strong>，我们只需要每个 GPU 的<strong>token</strong>批处理大小 &gt; <d-math>\text{990e12} / \text{450e9} = 2200</d-math>。</li> <li> <strong>在 SU 内或脊级别</strong>，BS &gt; <d-math>\text{990e12} / \text{400e9} = 2475</d-math>。</li> </ul> <p>这比 TPU 上的数字要高得多，TPU 上使用所有三个轴的数字是 850。例如，在 16000 个 H100 上训练的 LLaMA-3 将需要至少 40M token 的批处理大小（作为参考，他们使用了 16M）。在 2048 个 H800 GPU 上训练的 DeepSeek v3，带宽较低，为 300GB/s（而不是 H100 上的 450GB/s），将需要每个 GPU <d-math>\text{990e12} / \text{300e9} = 3300</d-math> token，或约 6.7M（实际上，他们使用了 4M）。</p> <p>启用网络内规约并使用纯数据并行，理论上我们的 AllReduce 带宽是 2 倍，这将使这两个数字减半。然而，实际上收益接近 30%，这仅仅弥补了我们通常难以达到报告数字的事实。此外，由于纯数据并行很少有用，这在实践中基本上无关紧要。</p> <p><strong>MoE 模型：</strong> 对于专家混合 (MoE) 模型，我们有 E 个专家，每个 token k 个专家，这增加到</p><span> <mjx-container class="MathJax CtxtMenu_Attached_0" ctxtmenu_counter="19" display="true" jax="CHTML" style="font-size: 116.9%; position: relative;" tabindex="0"><mjx-math aria-hidden="true" class="MJX-TEX" display="true" style="margin-left: 0px; margin-right: 0px;"><mjx-msub><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D447 TEX-I"></mjx-c></mjx-mi><mjx-script style="vertical-align: -0.15em; margin-left: -0.12em;"><mjx-mtext class="mjx-n" size="s"><mjx-c class="mjx-c6D"></mjx-c><mjx-c class="mjx-c61"></mjx-c><mjx-c class="mjx-c74"></mjx-c><mjx-c class="mjx-c68"></mjx-c></mjx-mtext></mjx-script></mjx-msub><mjx-mo class="mjx-n" space="4"><mjx-c class="mjx-c3D"></mjx-c></mjx-mo><mjx-mfrac space="4"><mjx-frac type="d"><mjx-num><mjx-nstrut type="d"></mjx-nstrut><mjx-mrow><mjx-mn class="mjx-n"><mjx-c class="mjx-c32"></mjx-c></mjx-mn><mjx-mo class="mjx-n" space="3"><mjx-c class="mjx-c22C5"></mjx-c></mjx-mo><mjx-mn class="mjx-n" space="3"><mjx-c class="mjx-c32"></mjx-c></mjx-mn><mjx-mo class="mjx-n" space="3"><mjx-c class="mjx-c22C5"></mjx-c></mjx-mo><mjx-mn class="mjx-n" space="3"><mjx-c class="mjx-c32"></mjx-c></mjx-mn><mjx-mo class="mjx-n" space="3"><mjx-c class="mjx-c22C5"></mjx-c></mjx-mo><mjx-mi class="mjx-i" space="3"><mjx-c class="mjx-c1D458 TEX-I"></mjx-c></mjx-mi><mjx-mo class="mjx-n" space="3"><mjx-c class="mjx-c22C5"></mjx-c></mjx-mo><mjx-mi class="mjx-i" space="3"><mjx-c class="mjx-c1D435 TEX-I"></mjx-c></mjx-mi><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D437 TEX-I"></mjx-c></mjx-mi><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D439 TEX-I"></mjx-c></mjx-mi></mjx-mrow></mjx-num><mjx-dbox><mjx-dtable><mjx-line type="d"></mjx-line><mjx-row><mjx-den><mjx-dstrut type="d"></mjx-dstrut><mjx-mrow><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D44B TEX-I"></mjx-c></mjx-mi><mjx-mo class="mjx-n" space="3"><mjx-c class="mjx-c22C5"></mjx-c></mjx-mo><mjx-mi class="mjx-i" space="3"><mjx-c class="mjx-c1D436 TEX-I"></mjx-c></mjx-mi></mjx-mrow></mjx-den></mjx-row></mjx-dtable></mjx-dbox></mjx-frac></mjx-mfrac></mjx-math><mjx-assistive-mml display="block" unselectable="on"><math display="block" xmlns="http://www.w3.org/1998/Math/MathML"><msub><mi>T</mi><mtext>math</mtext></msub><mo>=</mo><mfrac><mrow><mn>2</mn><mo>⋅</mo><mn>2</mn><mo>⋅</mo><mn>2</mn><mo>⋅</mo><mi>k</mi><mo>⋅</mo><mi>B</mi><mi>D</mi><mi>F</mi></mrow><mrow><mi>X</mi><mo>⋅</mo><mi>C</mi></mrow></mfrac></math></mjx-assistive-mml></mjx-container> <mjx-container class="MathJax CtxtMenu_Attached_0" ctxtmenu_counter="20" display="true" jax="CHTML" style="font-size: 116.9%; position: relative;" tabindex="0"><mjx-math aria-hidden="true" class="MJX-TEX" display="true" style="margin-left: 0px; margin-right: 0px;"><mjx-msub><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D447 TEX-I"></mjx-c></mjx-mi><mjx-script style="vertical-align: -0.15em; margin-left: -0.12em;"><mjx-mtext class="mjx-n" size="s"><mjx-c class="mjx-c63"></mjx-c><mjx-c class="mjx-c6F"></mjx-c><mjx-c class="mjx-c6D"></mjx-c><mjx-c class="mjx-c6D"></mjx-c><mjx-c class="mjx-c73"></mjx-c></mjx-mtext></mjx-script></mjx-msub><mjx-mo class="mjx-n" space="4"><mjx-c class="mjx-c3D"></mjx-c></mjx-mo><mjx-mfrac space="4"><mjx-frac type="d"><mjx-num><mjx-nstrut type="d"></mjx-nstrut><mjx-mrow><mjx-mn class="mjx-n"><mjx-c class="mjx-c32"></mjx-c></mjx-mn><mjx-mo class="mjx-n" space="3"><mjx-c class="mjx-c22C5"></mjx-c></mjx-mo><mjx-mn class="mjx-n" space="3"><mjx-c class="mjx-c32"></mjx-c></mjx-mn><mjx-mo class="mjx-n" space="3"><mjx-c class="mjx-c22C5"></mjx-c></mjx-mo><mjx-mn class="mjx-n" space="3"><mjx-c class="mjx-c32"></mjx-c></mjx-mn><mjx-mo class="mjx-n" space="3"><mjx-c class="mjx-c22C5"></mjx-c></mjx-mo><mjx-mi class="mjx-i" space="3"><mjx-c class="mjx-c1D438 TEX-I"></mjx-c></mjx-mi><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D437 TEX-I"></mjx-c></mjx-mi><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D439 TEX-I"></mjx-c></mjx-mi></mjx-mrow></mjx-num><mjx-dbox><mjx-dtable><mjx-line type="d"></mjx-line><mjx-row><mjx-den><mjx-dstrut type="d"></mjx-dstrut><mjx-msub><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D44A TEX-I"></mjx-c></mjx-mi><mjx-script style="vertical-align: -0.15em; margin-left: -0.104em;"><mjx-mtext class="mjx-n" size="s"><mjx-c class="mjx-c63"></mjx-c><mjx-c class="mjx-c6F"></mjx-c><mjx-c class="mjx-c6C"></mjx-c><mjx-c class="mjx-c6C"></mjx-c><mjx-c class="mjx-c65"></mjx-c><mjx-c class="mjx-c63"></mjx-c><mjx-c class="mjx-c74"></mjx-c><mjx-c class="mjx-c69"></mjx-c><mjx-c class="mjx-c76"></mjx-c><mjx-c class="mjx-c65"></mjx-c></mjx-mtext></mjx-script></mjx-msub></mjx-den></mjx-row></mjx-dtable></mjx-dbox></mjx-frac></mjx-mfrac></mjx-math><mjx-assistive-mml display="block" unselectable="on"><math display="block" xmlns="http://www.w3.org/1998/Math/MathML"><msub><mi>T</mi><mtext>comms</mtext></msub><mo>=</mo><mfrac><mrow><mn>2</mn><mo>⋅</mo><mn>2</mn><mo>⋅</mo><mn>2</mn><mo>⋅</mo><mi>E</mi><mi>D</mi><mi>F</mi></mrow><msub><mi>W</mi><mtext>collective</mtext></msub></mfrac></math></mjx-assistive-mml></mjx-container> </span><p>这将每个 GPU 的 token 批处理大小增加了 <d-math>E/k</d-math> 的因子，即</p><span> <mjx-container class="MathJax CtxtMenu_Attached_0" ctxtmenu_counter="21" display="true" jax="CHTML" style="font-size: 116.9%; position: relative;" tabindex="0"><mjx-math aria-hidden="true" class="MJX-TEX" display="true" style="margin-left: 0px; margin-right: 0px;"><mjx-mfrac><mjx-frac type="d"><mjx-num><mjx-nstrut type="d"></mjx-nstrut><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D435 TEX-I"></mjx-c></mjx-mi></mjx-num><mjx-dbox><mjx-dtable><mjx-line type="d"></mjx-line><mjx-row><mjx-den><mjx-dstrut type="d"></mjx-dstrut><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D44B TEX-I"></mjx-c></mjx-mi></mjx-den></mjx-row></mjx-dtable></mjx-dbox></mjx-frac></mjx-mfrac><mjx-mo class="mjx-n" space="4"><mjx-c class="mjx-c3E"></mjx-c></mjx-mo><mjx-mfrac space="4"><mjx-frac type="d"><mjx-num><mjx-nstrut type="d"></mjx-nstrut><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D438 TEX-I"></mjx-c></mjx-mi></mjx-num><mjx-dbox><mjx-dtable><mjx-line type="d"></mjx-line><mjx-row><mjx-den><mjx-dstrut type="d"></mjx-dstrut><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D458 TEX-I"></mjx-c></mjx-mi></mjx-den></mjx-row></mjx-dtable></mjx-dbox></mjx-frac></mjx-mfrac><mjx-mfrac><mjx-frac type="d"><mjx-num><mjx-nstrut type="d"></mjx-nstrut><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D436 TEX-I"></mjx-c></mjx-mi></mjx-num><mjx-dbox><mjx-dtable><mjx-line type="d"></mjx-line><mjx-row><mjx-den><mjx-dstrut type="d"></mjx-dstrut><mjx-msub><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D44A TEX-I"></mjx-c></mjx-mi><mjx-script style="vertical-align: -0.15em; margin-left: -0.104em;"><mjx-mtext class="mjx-n" size="s"><mjx-c class="mjx-c63"></mjx-c><mjx-c class="mjx-c6F"></mjx-c><mjx-c class="mjx-c6C"></mjx-c><mjx-c class="mjx-c6C"></mjx-c><mjx-c class="mjx-c65"></mjx-c><mjx-c class="mjx-c63"></mjx-c><mjx-c class="mjx-c74"></mjx-c><mjx-c class="mjx-c69"></mjx-c><mjx-c class="mjx-c76"></mjx-c><mjx-c class="mjx-c65"></mjx-c></mjx-mtext></mjx-script></mjx-msub></mjx-den></mjx-row></mjx-dtable></mjx-dbox></mjx-frac></mjx-mfrac></mjx-math><mjx-assistive-mml display="block" unselectable="on"><math display="block" xmlns="http://www.w3.org/1998/Math/MathML"><mfrac><mi>B</mi><mi>X</mi></mfrac><mo>&gt;</mo><mfrac><mi>E</mi><mi>k</mi></mfrac><mfrac><mi>C</mi><msub><mi>W</mi><mtext>collective</mtext></msub></mfrac></math></mjx-assistive-mml></mjx-container> </span><p>例如，对于新的 OpenAI OSS 模型，<d-math>k=4</d-math> 和 <d-math>E=128</d-math>，这增加到跨节点 <code class="language-plaintext highlighter-rouge">32 * 2475 = 79,200</code>，这是一个相当高的数字。</p> <p><strong>当 X 很小时会发生什么？</strong> 当我们只做例如 2 节点数据并行时，我们受益于 <d-math>(X - 1) / X</d-math> 的缩放，这给了我们</p><span> <mjx-container class="MathJax CtxtMenu_Attached_0" ctxtmenu_counter="22" display="true" jax="CHTML" style="font-size: 116.9%; position: relative;" tabindex="0"><mjx-math aria-hidden="true" class="MJX-TEX" display="true" style="margin-left: 0px; margin-right: 0px;"><mjx-msub><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D447 TEX-I"></mjx-c></mjx-mi><mjx-script style="vertical-align: -0.15em; margin-left: -0.12em;"><mjx-mtext class="mjx-n" size="s"><mjx-c class="mjx-c6D"></mjx-c><mjx-c class="mjx-c61"></mjx-c><mjx-c class="mjx-c74"></mjx-c><mjx-c class="mjx-c68"></mjx-c></mjx-mtext></mjx-script></mjx-msub><mjx-mo class="mjx-n" space="4"><mjx-c class="mjx-c3D"></mjx-c></mjx-mo><mjx-mfrac space="4"><mjx-frac type="d"><mjx-num><mjx-nstrut type="d"></mjx-nstrut><mjx-mrow><mjx-mn class="mjx-n"><mjx-c class="mjx-c32"></mjx-c></mjx-mn><mjx-mo class="mjx-n" space="3"><mjx-c class="mjx-c22C5"></mjx-c></mjx-mo><mjx-mn class="mjx-n" space="3"><mjx-c class="mjx-c32"></mjx-c></mjx-mn><mjx-mo class="mjx-n" space="3"><mjx-c class="mjx-c22C5"></mjx-c></mjx-mo><mjx-mn class="mjx-n" space="3"><mjx-c class="mjx-c32"></mjx-c></mjx-mn><mjx-mo class="mjx-n" space="3"><mjx-c class="mjx-c22C5"></mjx-c></mjx-mo><mjx-mi class="mjx-i" space="3"><mjx-c class="mjx-c1D435 TEX-I"></mjx-c></mjx-mi><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D437 TEX-I"></mjx-c></mjx-mi><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D439 TEX-I"></mjx-c></mjx-mi></mjx-mrow></mjx-num><mjx-dbox><mjx-dtable><mjx-line type="d"></mjx-line><mjx-row><mjx-den><mjx-dstrut type="d"></mjx-dstrut><mjx-mrow><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D441 TEX-I"></mjx-c></mjx-mi><mjx-mo class="mjx-n" space="3"><mjx-c class="mjx-c2217"></mjx-c></mjx-mo><mjx-mi class="mjx-i" space="3"><mjx-c class="mjx-c1D436 TEX-I"></mjx-c></mjx-mi></mjx-mrow></mjx-den></mjx-row></mjx-dtable></mjx-dbox></mjx-frac></mjx-mfrac></mjx-math><mjx-assistive-mml display="block" unselectable="on"><math display="block" xmlns="http://www.w3.org/1998/Math/MathML"><msub><mi>T</mi><mtext>math</mtext></msub><mo>=</mo><mfrac><mrow><mn>2</mn><mo>⋅</mo><mn>2</mn><mo>⋅</mo><mn>2</mn><mo>⋅</mo><mi>B</mi><mi>D</mi><mi>F</mi></mrow><mrow><mi>N</mi><mo>∗</mo><mi>C</mi></mrow></mfrac></math></mjx-assistive-mml></mjx-container> <mjx-container class="MathJax CtxtMenu_Attached_0" ctxtmenu_counter="23" display="true" jax="CHTML" style="font-size: 116.9%; position: relative;" tabindex="0"><mjx-math aria-hidden="true" class="MJX-TEX" display="true" style="margin-left: 0px; margin-right: 0px;"><mjx-msub><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D447 TEX-I"></mjx-c></mjx-mi><mjx-script style="vertical-align: -0.15em; margin-left: -0.12em;"><mjx-mtext class="mjx-n" size="s"><mjx-c class="mjx-c63"></mjx-c><mjx-c class="mjx-c6F"></mjx-c><mjx-c class="mjx-c6D"></mjx-c><mjx-c class="mjx-c6D"></mjx-c><mjx-c class="mjx-c73"></mjx-c></mjx-mtext></mjx-script></mjx-msub><mjx-mo class="mjx-n" space="4"><mjx-c class="mjx-c3D"></mjx-c></mjx-mo><mjx-mfrac space="4"><mjx-frac type="d"><mjx-num><mjx-nstrut type="d"></mjx-nstrut><mjx-mrow><mjx-mn class="mjx-n"><mjx-c class="mjx-c32"></mjx-c></mjx-mn><mjx-mo class="mjx-n" space="3"><mjx-c class="mjx-c22C5"></mjx-c></mjx-mo><mjx-mn class="mjx-n" space="3"><mjx-c class="mjx-c32"></mjx-c></mjx-mn><mjx-mo class="mjx-n" space="3"><mjx-c class="mjx-c22C5"></mjx-c></mjx-mo><mjx-mn class="mjx-n" space="3"><mjx-c class="mjx-c32"></mjx-c></mjx-mn><mjx-mo class="mjx-n" space="3"><mjx-c class="mjx-c22C5"></mjx-c></mjx-mo><mjx-mi class="mjx-i" space="3"><mjx-c class="mjx-c1D437 TEX-I"></mjx-c></mjx-mi><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D439 TEX-I"></mjx-c></mjx-mi><mjx-mo class="mjx-n" space="3"><mjx-c class="mjx-c22C5"></mjx-c></mjx-mo><mjx-mo class="mjx-n" space="3"><mjx-c class="mjx-c28"></mjx-c></mjx-mo><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D44B TEX-I"></mjx-c></mjx-mi><mjx-mo class="mjx-n" space="3"><mjx-c class="mjx-c2212"></mjx-c></mjx-mo><mjx-mn class="mjx-n" space="3"><mjx-c class="mjx-c31"></mjx-c></mjx-mn><mjx-mo class="mjx-n"><mjx-c class="mjx-c29"></mjx-c></mjx-mo></mjx-mrow></mjx-num><mjx-dbox><mjx-dtable><mjx-line type="d"></mjx-line><mjx-row><mjx-den><mjx-dstrut type="d"></mjx-dstrut><mjx-mrow><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D44B TEX-I"></mjx-c></mjx-mi><mjx-mo class="mjx-n" space="3"><mjx-c class="mjx-c22C5"></mjx-c></mjx-mo><mjx-msub space="3"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D44A TEX-I"></mjx-c></mjx-mi><mjx-script style="vertical-align: -0.15em; margin-left: -0.104em;"><mjx-mtext class="mjx-n" size="s"><mjx-c class="mjx-c63"></mjx-c><mjx-c class="mjx-c6F"></mjx-c><mjx-c class="mjx-c6C"></mjx-c><mjx-c class="mjx-c6C"></mjx-c><mjx-c class="mjx-c65"></mjx-c><mjx-c class="mjx-c63"></mjx-c><mjx-c class="mjx-c74"></mjx-c><mjx-c class="mjx-c69"></mjx-c><mjx-c class="mjx-c76"></mjx-c><mjx-c class="mjx-c65"></mjx-c></mjx-mtext></mjx-script></mjx-msub></mjx-mrow></mjx-den></mjx-row></mjx-dtable></mjx-dbox></mjx-frac></mjx-mfrac></mjx-math><mjx-assistive-mml display="block" unselectable="on"><math display="block" xmlns="http://www.w3.org/1998/Math/MathML"><msub><mi>T</mi><mtext>comms</mtext></msub><mo>=</mo><mfrac><mrow><mn>2</mn><mo>⋅</mo><mn>2</mn><mo>⋅</mo><mn>2</mn><mo>⋅</mo><mi>D</mi><mi>F</mi><mo>⋅</mo><mo stretchy="false">(</mo><mi>X</mi><mo>−</mo><mn>1</mn><mo stretchy="false">)</mo></mrow><mrow><mi>X</mi><mo>⋅</mo><msub><mi>W</mi><mtext>collective</mtext></msub></mrow></mfrac></math></mjx-assistive-mml></mjx-container> </span><p>其中 X 是节点数，<d-math>N = 8 \cdot X</d-math>。那么对于一个密集模型，我们有 <d-math>B / N &gt; \alpha \cdot (X - 1) / X</d-math>，或者例如 <d-math>B / N &gt; \text{1237}</d-math>，是上面值的一半。你会因此经常看到 2 路数据并行。</p> <p class="takeaway"><strong>要点：</strong>数据并行和 ZeRO 分片需要每个 GPU 大约 2500 个 token 的批处理大小才能在 H100 或 B200 上达到计算密集型，假设完美的重叠和 FLOPs 利用率。对于 MoE 模型，这个数字增加了 <d-math>E / k</d-math> 的因子，即总参数与激活参数的比率。当进行少量数据并行时，临界批处理大小会减小。</p> <h3 id="tensor-parallelism">张量并行性</h3> <p>张量并行需要在激活值上进行 AllGather 和 ReduceScatter，我们需要将其与 MLP FLOPs 重叠。换句话说，在前向传播中，我们有</p><span> <mjx-container class="MathJax CtxtMenu_Attached_0" ctxtmenu_counter="24" display="true" jax="CHTML" style="font-size: 116.9%; position: relative;" tabindex="0"><mjx-math aria-hidden="true" class="MJX-TEX" display="true" style="margin-left: 0px; margin-right: 0px;"><mjx-msub><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D447 TEX-I"></mjx-c></mjx-mi><mjx-script style="vertical-align: -0.15em; margin-left: -0.12em;"><mjx-mtext class="mjx-n" size="s"><mjx-c class="mjx-c6D"></mjx-c><mjx-c class="mjx-c61"></mjx-c><mjx-c class="mjx-c74"></mjx-c><mjx-c class="mjx-c68"></mjx-c></mjx-mtext></mjx-script></mjx-msub><mjx-mo class="mjx-n" space="4"><mjx-c class="mjx-c3D"></mjx-c></mjx-mo><mjx-mfrac space="4"><mjx-frac type="d"><mjx-num><mjx-nstrut type="d"></mjx-nstrut><mjx-mrow><mjx-mn class="mjx-n"><mjx-c class="mjx-c32"></mjx-c></mjx-mn><mjx-mo class="mjx-n" space="3"><mjx-c class="mjx-c22C5"></mjx-c></mjx-mo><mjx-mn class="mjx-n" space="3"><mjx-c class="mjx-c32"></mjx-c></mjx-mn><mjx-mo class="mjx-n" space="3"><mjx-c class="mjx-c22C5"></mjx-c></mjx-mo><mjx-mi class="mjx-i" space="3"><mjx-c class="mjx-c1D435 TEX-I"></mjx-c></mjx-mi><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D437 TEX-I"></mjx-c></mjx-mi><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D439 TEX-I"></mjx-c></mjx-mi></mjx-mrow></mjx-num><mjx-dbox><mjx-dtable><mjx-line type="d"></mjx-line><mjx-row><mjx-den><mjx-dstrut type="d"></mjx-dstrut><mjx-mrow><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D44C TEX-I"></mjx-c></mjx-mi><mjx-mo class="mjx-n" space="3"><mjx-c class="mjx-c22C5"></mjx-c></mjx-mo><mjx-mi class="mjx-i" space="3"><mjx-c class="mjx-c1D436 TEX-I"></mjx-c></mjx-mi></mjx-mrow></mjx-den></mjx-row></mjx-dtable></mjx-dbox></mjx-frac></mjx-mfrac></mjx-math><mjx-assistive-mml display="block" unselectable="on"><math display="block" xmlns="http://www.w3.org/1998/Math/MathML"><msub><mi>T</mi><mtext>math</mtext></msub><mo>=</mo><mfrac><mrow><mn>2</mn><mo>⋅</mo><mn>2</mn><mo>⋅</mo><mi>B</mi><mi>D</mi><mi>F</mi></mrow><mrow><mi>Y</mi><mo>⋅</mo><mi>C</mi></mrow></mfrac></math></mjx-assistive-mml></mjx-container> <mjx-container class="MathJax CtxtMenu_Attached_0" ctxtmenu_counter="25" display="true" jax="CHTML" style="font-size: 116.9%; position: relative;" tabindex="0"><mjx-math aria-hidden="true" class="MJX-TEX" display="true" style="margin-left: 0px; margin-right: 0px;"><mjx-msub><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D447 TEX-I"></mjx-c></mjx-mi><mjx-script style="vertical-align: -0.15em; margin-left: -0.12em;"><mjx-mtext class="mjx-n" size="s"><mjx-c class="mjx-c63"></mjx-c><mjx-c class="mjx-c6F"></mjx-c><mjx-c class="mjx-c6D"></mjx-c><mjx-c class="mjx-c6D"></mjx-c><mjx-c class="mjx-c73"></mjx-c></mjx-mtext></mjx-script></mjx-msub><mjx-mo class="mjx-n" space="4"><mjx-c class="mjx-c3D"></mjx-c></mjx-mo><mjx-mfrac space="4"><mjx-frac type="d"><mjx-num><mjx-nstrut type="d"></mjx-nstrut><mjx-mrow><mjx-mn class="mjx-n"><mjx-c class="mjx-c32"></mjx-c></mjx-mn><mjx-mo class="mjx-n" space="3"><mjx-c class="mjx-c22C5"></mjx-c></mjx-mo><mjx-mn class="mjx-n" space="3"><mjx-c class="mjx-c32"></mjx-c></mjx-mn><mjx-mo class="mjx-n" space="3"><mjx-c class="mjx-c22C5"></mjx-c></mjx-mo><mjx-mi class="mjx-i" space="3"><mjx-c class="mjx-c1D435 TEX-I"></mjx-c></mjx-mi><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D437 TEX-I"></mjx-c></mjx-mi></mjx-mrow></mjx-num><mjx-dbox><mjx-dtable><mjx-line type="d"></mjx-line><mjx-row><mjx-den><mjx-dstrut type="d"></mjx-dstrut><mjx-msub><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D44A TEX-I"></mjx-c></mjx-mi><mjx-script style="vertical-align: -0.15em; margin-left: -0.104em;"><mjx-mtext class="mjx-n" size="s"><mjx-c class="mjx-c63"></mjx-c><mjx-c class="mjx-c6F"></mjx-c><mjx-c class="mjx-c6C"></mjx-c><mjx-c class="mjx-c6C"></mjx-c><mjx-c class="mjx-c65"></mjx-c><mjx-c class="mjx-c63"></mjx-c><mjx-c class="mjx-c74"></mjx-c><mjx-c class="mjx-c69"></mjx-c><mjx-c class="mjx-c76"></mjx-c><mjx-c class="mjx-c65"></mjx-c></mjx-mtext></mjx-script></mjx-msub></mjx-den></mjx-row></mjx-dtable></mjx-dbox></mjx-frac></mjx-mfrac></mjx-math><mjx-assistive-mml display="block" unselectable="on"><math display="block" xmlns="http://www.w3.org/1998/Math/MathML"><msub><mi>T</mi><mtext>comms</mtext></msub><mo>=</mo><mfrac><mrow><mn>2</mn><mo>⋅</mo><mn>2</mn><mo>⋅</mo><mi>B</mi><mi>D</mi></mrow><msub><mi>W</mi><mtext>collective</mtext></msub></mfrac></math></mjx-assistive-mml></mjx-container> </span><p>要达到计算密集型，我们得到规则</p><span> <mjx-container class="MathJax CtxtMenu_Attached_0" ctxtmenu_counter="26" display="true" jax="CHTML" style="font-size: 116.9%; position: relative;" tabindex="0"><mjx-math aria-hidden="true" class="MJX-TEX" display="true" style="margin-left: 0px; margin-right: 0px;"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D44C TEX-I"></mjx-c></mjx-mi><mjx-mo class="mjx-n" space="4"><mjx-c class="mjx-c3C"></mjx-c></mjx-mo><mjx-mfrac space="4"><mjx-frac type="d"><mjx-num><mjx-nstrut type="d"></mjx-nstrut><mjx-mrow><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D439 TEX-I"></mjx-c></mjx-mi><mjx-mo class="mjx-n" space="3"><mjx-c class="mjx-c22C5"></mjx-c></mjx-mo><mjx-msub space="3"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D44A TEX-I"></mjx-c></mjx-mi><mjx-script style="vertical-align: -0.15em; margin-left: -0.104em;"><mjx-mtext class="mjx-n" size="s"><mjx-c class="mjx-c63"></mjx-c><mjx-c class="mjx-c6F"></mjx-c><mjx-c class="mjx-c6C"></mjx-c><mjx-c class="mjx-c6C"></mjx-c><mjx-c class="mjx-c65"></mjx-c><mjx-c class="mjx-c63"></mjx-c><mjx-c class="mjx-c74"></mjx-c><mjx-c class="mjx-c69"></mjx-c><mjx-c class="mjx-c76"></mjx-c><mjx-c class="mjx-c65"></mjx-c></mjx-mtext></mjx-script></mjx-msub></mjx-mrow></mjx-num><mjx-dbox><mjx-dtable><mjx-line type="d"></mjx-line><mjx-row><mjx-den><mjx-dstrut type="d"></mjx-dstrut><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D436 TEX-I"></mjx-c></mjx-mi></mjx-den></mjx-row></mjx-dtable></mjx-dbox></mjx-frac></mjx-mfrac></mjx-math><mjx-assistive-mml display="block" unselectable="on"><math display="block" xmlns="http://www.w3.org/1998/Math/MathML"><mi>Y</mi><mo>&lt;</mo><mfrac><mrow><mi>F</mi><mo>⋅</mo><msub><mi>W</mi><mtext>collective</mtext></msub></mrow><mi>C</mi></mfrac></math></mjx-assistive-mml></mjx-container> </span><p>在节点内，这大约是 <d-math>F / 2200</d-math> 或在节点之外是 <d-math>F / 2475</d-math>。对于像 LLaMA-3 那样的 <d-math>F=\text{28000}</d-math>，这大约是 11 路 TP（或者向下取整，大约 8 路，这是一个节点的大小）。和上面一样，当我们恰好跨越 2 个节点时，我们获得了额外的 2 倍带宽，所以我们通常可以进行 16 路数据并行（<d-math>F &gt; 2475 \cdot (Y - 8)</d-math>），这理论上给了我们最多 19 路模型并行。</p> <p class="takeaway"><strong>要点：</strong>在大小为 Y 的轴上进行张量并行，前馈维度为 F，当 <d-math>Y &gt; F / 2475</d-math> 时会变得通信受限，这通常将我们限制在节点内 TP 或最多 2 节点 TP。</p> <h3 id="expert-parallelism">专家并行性</h3> <p>正如我们上面已经指出的，专家混合 (MoE) 模型的模型权重是 E 倍，而 FLOPs 只有 k 倍，这使得数据并行显著更难。我们可以通过沿专家维度分片我们的权重来缓解这个问题，即 W<sub>in</sub>[E<sub>Z</sub>, D, F]。要执行 MLP 块，我们需要引入 2x AllToAll 将我们的激活值发送到相应的专家。</p> <p>如上所述，如果这个 AllToAll<sub>Z-&gt;k</sub>([B, D, k]) 跨越多个节点，其成本大约是 <d-math>T_\text{AllToAll} = 2 \cdot B \cdot D \cdot (Z-8)/Z \min(8 * k / Z, 1)</d-math>，所以对于纯专家并行，我们需要</p><span> <mjx-container class="MathJax CtxtMenu_Attached_0" ctxtmenu_counter="27" display="true" jax="CHTML" style="font-size: 116.9%; position: relative;" tabindex="0"><mjx-math aria-hidden="true" class="MJX-TEX" display="true" style="margin-left: 0px; margin-right: 0px;"><mjx-msub><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D447 TEX-I"></mjx-c></mjx-mi><mjx-script style="vertical-align: -0.15em; margin-left: -0.12em;"><mjx-mtext class="mjx-n" size="s"><mjx-c class="mjx-c6D"></mjx-c><mjx-c class="mjx-c61"></mjx-c><mjx-c class="mjx-c74"></mjx-c><mjx-c class="mjx-c68"></mjx-c></mjx-mtext></mjx-script></mjx-msub><mjx-mo class="mjx-n" space="4"><mjx-c class="mjx-c3D"></mjx-c></mjx-mo><mjx-mfrac space="4"><mjx-frac type="d"><mjx-num><mjx-nstrut type="d"></mjx-nstrut><mjx-mrow><mjx-mn class="mjx-n"><mjx-c class="mjx-c34"></mjx-c></mjx-mn><mjx-mo class="mjx-n" space="3"><mjx-c class="mjx-c22C5"></mjx-c></mjx-mo><mjx-mi class="mjx-i" space="3"><mjx-c class="mjx-c1D435 TEX-I"></mjx-c></mjx-mi><mjx-mo class="mjx-n" space="3"><mjx-c class="mjx-c22C5"></mjx-c></mjx-mo><mjx-mi class="mjx-i" space="3"><mjx-c class="mjx-c1D458 TEX-I"></mjx-c></mjx-mi><mjx-mo class="mjx-n" space="3"><mjx-c class="mjx-c22C5"></mjx-c></mjx-mo><mjx-mi class="mjx-i" space="3"><mjx-c class="mjx-c1D437 TEX-I"></mjx-c></mjx-mi><mjx-mo class="mjx-n" space="3"><mjx-c class="mjx-c22C5"></mjx-c></mjx-mo><mjx-mi class="mjx-i" space="3"><mjx-c class="mjx-c1D439 TEX-I"></mjx-c></mjx-mi></mjx-mrow></mjx-num><mjx-dbox><mjx-dtable><mjx-line type="d"></mjx-line><mjx-row><mjx-den><mjx-dstrut type="d"></mjx-dstrut><mjx-mrow><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D44D TEX-I"></mjx-c></mjx-mi><mjx-mo class="mjx-n" space="3"><mjx-c class="mjx-c22C5"></mjx-c></mjx-mo><mjx-mi class="mjx-i" space="3"><mjx-c class="mjx-c1D436 TEX-I"></mjx-c></mjx-mi></mjx-mrow></mjx-den></mjx-row></mjx-dtable></mjx-dbox></mjx-frac></mjx-mfrac></mjx-math><mjx-assistive-mml display="block" unselectable="on"><math display="block" xmlns="http://www.w3.org/1998/Math/MathML"><msub><mi>T</mi><mtext>math</mtext></msub><mo>=</mo><mfrac><mrow><mn>4</mn><mo>⋅</mo><mi>B</mi><mo>⋅</mo><mi>k</mi><mo>⋅</mo><mi>D</mi><mo>⋅</mo><mi>F</mi></mrow><mrow><mi>Z</mi><mo>⋅</mo><mi>C</mi></mrow></mfrac></math></mjx-assistive-mml></mjx-container> <mjx-container class="MathJax CtxtMenu_Attached_0" ctxtmenu_counter="28" display="true" jax="CHTML" style="font-size: 116.9%; position: relative;" tabindex="0"><mjx-math aria-hidden="true" class="MJX-TEX" display="true" style="margin-left: 0px; margin-right: 0px;"><mjx-msub><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D447 TEX-I"></mjx-c></mjx-mi><mjx-script style="vertical-align: -0.15em; margin-left: -0.12em;"><mjx-mtext class="mjx-n" size="s"><mjx-c class="mjx-c63"></mjx-c><mjx-c class="mjx-c6F"></mjx-c><mjx-c class="mjx-c6D"></mjx-c><mjx-c class="mjx-c6D"></mjx-c><mjx-c class="mjx-c73"></mjx-c></mjx-mtext></mjx-script></mjx-msub><mjx-mo class="mjx-n" space="4"><mjx-c class="mjx-c3D"></mjx-c></mjx-mo><mjx-mfrac space="4"><mjx-frac type="d"><mjx-num><mjx-nstrut type="d"></mjx-nstrut><mjx-mrow><mjx-mn class="mjx-n"><mjx-c class="mjx-c34"></mjx-c></mjx-mn><mjx-mo class="mjx-n" space="3"><mjx-c class="mjx-c22C5"></mjx-c></mjx-mo><mjx-mi class="mjx-i" space="3"><mjx-c class="mjx-c1D435 TEX-I"></mjx-c></mjx-mi><mjx-mo class="mjx-n" space="3"><mjx-c class="mjx-c22C5"></mjx-c></mjx-mo><mjx-mi class="mjx-i" space="3"><mjx-c class="mjx-c1D437 TEX-I"></mjx-c></mjx-mi><mjx-mo class="mjx-n" space="3"><mjx-c class="mjx-c22C5"></mjx-c></mjx-mo><mjx-mo class="mjx-n" space="3"><mjx-c class="mjx-c28"></mjx-c></mjx-mo><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D44D TEX-I"></mjx-c></mjx-mi><mjx-mo class="mjx-n" space="3"><mjx-c class="mjx-c2212"></mjx-c></mjx-mo><mjx-mn class="mjx-n" space="3"><mjx-c class="mjx-c38"></mjx-c></mjx-mn><mjx-mo class="mjx-n"><mjx-c class="mjx-c29"></mjx-c></mjx-mo></mjx-mrow></mjx-num><mjx-dbox><mjx-dtable><mjx-line type="d"></mjx-line><mjx-row><mjx-den><mjx-dstrut type="d"></mjx-dstrut><mjx-mrow><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D44A TEX-I"></mjx-c></mjx-mi><mjx-mo class="mjx-n" space="3"><mjx-c class="mjx-c22C5"></mjx-c></mjx-mo><mjx-mi class="mjx-i" space="3"><mjx-c class="mjx-c1D44D TEX-I"></mjx-c></mjx-mi></mjx-mrow></mjx-den></mjx-row></mjx-dtable></mjx-dbox></mjx-frac></mjx-mfrac><mjx-mo class="mjx-n" space="3"><mjx-c class="mjx-c22C5"></mjx-c></mjx-mo><mjx-mo class="mjx-n" space="3"><mjx-c class="mjx-c6D"></mjx-c><mjx-c class="mjx-c69"></mjx-c><mjx-c class="mjx-c6E"></mjx-c></mjx-mo><mjx-mrow space="2"><mjx-mo class="mjx-s3"><mjx-c class="mjx-c28 TEX-S3"></mjx-c></mjx-mo><mjx-mfrac><mjx-frac type="d"><mjx-num><mjx-nstrut type="d"></mjx-nstrut><mjx-mrow><mjx-mn class="mjx-n"><mjx-c class="mjx-c38"></mjx-c></mjx-mn><mjx-mo class="mjx-n" space="3"><mjx-c class="mjx-c22C5"></mjx-c></mjx-mo><mjx-mi class="mjx-i" space="3"><mjx-c class="mjx-c1D458 TEX-I"></mjx-c></mjx-mi></mjx-mrow></mjx-num><mjx-dbox><mjx-dtable><mjx-line type="d"></mjx-line><mjx-row><mjx-den><mjx-dstrut type="d"></mjx-dstrut><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D44D TEX-I"></mjx-c></mjx-mi></mjx-den></mjx-row></mjx-dtable></mjx-dbox></mjx-frac></mjx-mfrac><mjx-mo class="mjx-n"><mjx-c class="mjx-c2C"></mjx-c></mjx-mo><mjx-mn class="mjx-n" space="2"><mjx-c class="mjx-c31"></mjx-c></mjx-mn><mjx-mo class="mjx-s3"><mjx-c class="mjx-c29 TEX-S3"></mjx-c></mjx-mo></mjx-mrow></mjx-math><mjx-assistive-mml display="block" unselectable="on"><math display="block" xmlns="http://www.w3.org/1998/Math/MathML"><msub><mi>T</mi><mtext>comms</mtext></msub><mo>=</mo><mfrac><mrow><mn>4</mn><mo>⋅</mo><mi>B</mi><mo>⋅</mo><mi>D</mi><mo>⋅</mo><mo stretchy="false">(</mo><mi>Z</mi><mo>−</mo><mn>8</mn><mo stretchy="false">)</mo></mrow><mrow><mi>W</mi><mo>⋅</mo><mi>Z</mi></mrow></mfrac><mo>⋅</mo><mo data-mjx-texclass="OP" movablelimits="true">min</mo><mrow data-mjx-texclass="INNER"><mo data-mjx-texclass="OPEN">(</mo><mfrac><mrow><mn>8</mn><mo>⋅</mo><mi>k</mi></mrow><mi>Z</mi></mfrac><mo>,</mo><mn>1</mn><mo data-mjx-texclass="CLOSE">)</mo></mrow></math></mjx-assistive-mml></mjx-container> </span><p>我们需要 <d-math>K &gt; Z/8</d-math> 且 <d-math>F &gt; \alpha \cdot (Z - 8)/k</d-math> 或者 <d-math>Z \gg K</d-math> 且 <d-math>F &gt; 8 \cdot \alpha</d-math>，其中 <d-math>\alpha = C/W</d-math>。这给了你两个专家并行可能的领域，一个是有少量专家并行（大约 2 节点）和小 <d-math>F</d-math>，另一个是有大 <d-math>F</d-math> 和任意大的 <d-math>Z</d-math>（最多 E 路专家并行）。</p> <p>在实践中，你会看到这两种情况，要么是少量的专家并行（比如 DeepSeek v3，它的 F 非常小，跨节点专家并行也相对较小且受限），要么是 F 很大的模型，在这种情况下我们可以进行显著的跨节点 EP 和 TP。</p> <p class="takeaway"><strong>要点：</strong>如果 <d-math>F &lt; 8 * C / W_\text{node}</d-math>，专家并行可以跨越 1-2 个节点，成本与 TP 类似（略低），或者如果 <d-math>F &gt; 8 * C / W_\text{node}</d-math>，我们可以进行大量的专家并行（最多 <d-math>E</d-math> 个节点），成本相对较低。</p> <h3 id="pipeline-parallelism">流水线并行性</h3> <p>流水线并行性将层划分到不同的节点上，通信成本极低，因为我们只是每隔几层发送小批量的激活值。历史上，流水线一直受到“流水线气泡”的困扰，但随着新的零气泡流水线方法的出现，通常可以在没有气泡的情况下进行。</p> <p>流水线并行性的总通信成本很小：有 <d-math>N_\text{MB}</d-math> 个微批次和 <d-math>N_\text{stages}</d-math> 个阶段，我们有 <d-math>T_\text{comms per hop} = 2 \cdot B \cdot D / (W \cdot N_\text{MB})</d-math> 和 <d-math>N_\text{MB} + N_\text{stages} - 2</d-math> 跳，所以大约是</p><span> <mjx-container class="MathJax CtxtMenu_Attached_0" ctxtmenu_counter="29" display="true" jax="CHTML" style="font-size: 116.9%; position: relative;" tabindex="0"><mjx-math aria-hidden="true" class="MJX-TEX" display="true" style="margin-left: 0px; margin-right: 0px;"><mjx-msub><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D447 TEX-I"></mjx-c></mjx-mi><mjx-script style="vertical-align: -0.15em; margin-left: -0.12em;"><mjx-mtext class="mjx-n" size="s"><mjx-c class="mjx-c74"></mjx-c><mjx-c class="mjx-c6F"></mjx-c><mjx-c class="mjx-c74"></mjx-c><mjx-c class="mjx-c61"></mjx-c><mjx-c class="mjx-c6C"></mjx-c><mjx-c class="mjx-c20"></mjx-c><mjx-c class="mjx-c50"></mjx-c><mjx-c class="mjx-c50"></mjx-c><mjx-c class="mjx-c20"></mjx-c><mjx-c class="mjx-c63"></mjx-c><mjx-c class="mjx-c6F"></mjx-c><mjx-c class="mjx-c6D"></mjx-c><mjx-c class="mjx-c6D"></mjx-c><mjx-c class="mjx-c73"></mjx-c></mjx-mtext></mjx-script></mjx-msub><mjx-mo class="mjx-n" space="4"><mjx-c class="mjx-c3D"></mjx-c></mjx-mo><mjx-mfrac space="4"><mjx-frac type="d"><mjx-num><mjx-nstrut type="d"></mjx-nstrut><mjx-mrow><mjx-mn class="mjx-n"><mjx-c class="mjx-c32"></mjx-c></mjx-mn><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D435 TEX-I"></mjx-c></mjx-mi><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D437 TEX-I"></mjx-c></mjx-mi></mjx-mrow></mjx-num><mjx-dbox><mjx-dtable><mjx-line type="d"></mjx-line><mjx-row><mjx-den><mjx-dstrut type="d"></mjx-dstrut><mjx-mrow><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D44A TEX-I"></mjx-c></mjx-mi><mjx-mo class="mjx-n" space="3"><mjx-c class="mjx-c22C5"></mjx-c></mjx-mo><mjx-msub space="3"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D441 TEX-I"></mjx-c></mjx-mi><mjx-script style="vertical-align: -0.15em; margin-left: -0.085em;"><mjx-mtext class="mjx-n" size="s"><mjx-c class="mjx-c6D"></mjx-c><mjx-c class="mjx-c69"></mjx-c><mjx-c class="mjx-c63"></mjx-c><mjx-c class="mjx-c72"></mjx-c><mjx-c class="mjx-c6F"></mjx-c><mjx-c class="mjx-c62"></mjx-c><mjx-c class="mjx-c61"></mjx-c><mjx-c class="mjx-c74"></mjx-c><mjx-c class="mjx-c63"></mjx-c><mjx-c class="mjx-c68"></mjx-c><mjx-c class="mjx-c65"></mjx-c><mjx-c class="mjx-c73"></mjx-c></mjx-mtext></mjx-script></mjx-msub></mjx-mrow></mjx-den></mjx-row></mjx-dtable></mjx-dbox></mjx-frac></mjx-mfrac><mjx-mo class="mjx-n" space="3"><mjx-c class="mjx-c22C5"></mjx-c></mjx-mo><mjx-mo class="mjx-n" space="3"><mjx-c class="mjx-c28"></mjx-c></mjx-mo><mjx-msub><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D441 TEX-I"></mjx-c></mjx-mi><mjx-script style="vertical-align: -0.15em; margin-left: -0.085em;"><mjx-mtext class="mjx-n" size="s"><mjx-c class="mjx-c6D"></mjx-c><mjx-c class="mjx-c69"></mjx-c><mjx-c class="mjx-c63"></mjx-c><mjx-c class="mjx-c72"></mjx-c><mjx-c class="mjx-c6F"></mjx-c><mjx-c class="mjx-c62"></mjx-c><mjx-c class="mjx-c61"></mjx-c><mjx-c class="mjx-c74"></mjx-c><mjx-c class="mjx-c63"></mjx-c><mjx-c class="mjx-c68"></mjx-c><mjx-c class="mjx-c65"></mjx-c><mjx-c class="mjx-c73"></mjx-c></mjx-mtext></mjx-script></mjx-msub><mjx-mo class="mjx-n" space="3"><mjx-c class="mjx-c2B"></mjx-c></mjx-mo><mjx-msub space="3"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D441 TEX-I"></mjx-c></mjx-mi><mjx-script style="vertical-align: -0.15em; margin-left: -0.085em;"><mjx-mtext class="mjx-n" size="s"><mjx-c class="mjx-c73"></mjx-c><mjx-c class="mjx-c74"></mjx-c><mjx-c class="mjx-c61"></mjx-c><mjx-c class="mjx-c67"></mjx-c><mjx-c class="mjx-c65"></mjx-c><mjx-c class="mjx-c73"></mjx-c></mjx-mtext></mjx-script></mjx-msub><mjx-mo class="mjx-n" space="3"><mjx-c class="mjx-c2212"></mjx-c></mjx-mo><mjx-mn class="mjx-n" space="3"><mjx-c class="mjx-c32"></mjx-c></mjx-mn><mjx-mo class="mjx-n"><mjx-c class="mjx-c29"></mjx-c></mjx-mo></mjx-math><mjx-assistive-mml display="block" unselectable="on"><math display="block" xmlns="http://www.w3.org/1998/Math/MathML"><msub><mi>T</mi><mtext>total PP comms</mtext></msub><mo>=</mo><mfrac><mrow><mn>2</mn><mi>B</mi><mi>D</mi></mrow><mrow><mi>W</mi><mo>⋅</mo><msub><mi>N</mi><mtext>microbatches</mtext></msub></mrow></mfrac><mo>⋅</mo><mo stretchy="false">(</mo><msub><mi>N</mi><mtext>microbatches</mtext></msub><mo>+</mo><msub><mi>N</mi><mtext>stages</mtext></msub><mo>−</mo><mn>2</mn><mo stretchy="false">)</mo></math></mjx-assistive-mml></mjx-container> <mjx-container class="MathJax CtxtMenu_Attached_0" ctxtmenu_counter="30" display="true" jax="CHTML" style="font-size: 116.9%; position: relative;" tabindex="0"><mjx-math aria-hidden="true" class="MJX-TEX" display="true" style="margin-left: 0px; margin-right: 0px;"><mjx-msub><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D447 TEX-I"></mjx-c></mjx-mi><mjx-script style="vertical-align: -0.15em; margin-left: -0.12em;"><mjx-mtext class="mjx-n" size="s"><mjx-c class="mjx-c70"></mjx-c><mjx-c class="mjx-c65"></mjx-c><mjx-c class="mjx-c72"></mjx-c><mjx-c class="mjx-c2D"></mjx-c><mjx-c class="mjx-c6C"></mjx-c><mjx-c class="mjx-c61"></mjx-c><mjx-c class="mjx-c79"></mjx-c><mjx-c class="mjx-c65"></mjx-c><mjx-c class="mjx-c72"></mjx-c><mjx-c class="mjx-c20"></mjx-c><mjx-c class="mjx-c63"></mjx-c><mjx-c class="mjx-c6F"></mjx-c><mjx-c class="mjx-c6D"></mjx-c><mjx-c class="mjx-c6D"></mjx-c><mjx-c class="mjx-c73"></mjx-c></mjx-mtext></mjx-script></mjx-msub><mjx-mo class="mjx-n" space="4"><mjx-c class="mjx-c2248"></mjx-c></mjx-mo><mjx-mn class="mjx-n" space="4"><mjx-c class="mjx-c31"></mjx-c><mjx-c class="mjx-c2E"></mjx-c><mjx-c class="mjx-c35"></mjx-c></mjx-mn><mjx-mo class="mjx-n" space="3"><mjx-c class="mjx-c22C5"></mjx-c></mjx-mo><mjx-mfrac space="3"><mjx-frac type="d"><mjx-num><mjx-nstrut type="d"></mjx-nstrut><mjx-mrow><mjx-mn class="mjx-n"><mjx-c class="mjx-c32"></mjx-c></mjx-mn><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D435 TEX-I"></mjx-c></mjx-mi><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D437 TEX-I"></mjx-c></mjx-mi></mjx-mrow></mjx-num><mjx-dbox><mjx-dtable><mjx-line type="d"></mjx-line><mjx-row><mjx-den><mjx-dstrut type="d"></mjx-dstrut><mjx-mrow><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D44A TEX-I"></mjx-c></mjx-mi><mjx-mo class="mjx-n" space="3"><mjx-c class="mjx-c22C5"></mjx-c></mjx-mo><mjx-msub space="3"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D441 TEX-I"></mjx-c></mjx-mi><mjx-script style="vertical-align: -0.15em; margin-left: -0.085em;"><mjx-mtext class="mjx-n" size="s"><mjx-c class="mjx-c6C"></mjx-c><mjx-c class="mjx-c61"></mjx-c><mjx-c class="mjx-c79"></mjx-c><mjx-c class="mjx-c65"></mjx-c><mjx-c class="mjx-c72"></mjx-c><mjx-c class="mjx-c73"></mjx-c></mjx-mtext></mjx-script></mjx-msub></mjx-mrow></mjx-den></mjx-row></mjx-dtable></mjx-dbox></mjx-frac></mjx-mfrac></mjx-math><mjx-assistive-mml display="block" unselectable="on"><math display="block" xmlns="http://www.w3.org/1998/Math/MathML"><msub><mi>T</mi><mtext>per-layer comms</mtext></msub><mo>≈</mo><mn>1.5</mn><mo>⋅</mo><mfrac><mrow><mn>2</mn><mi>B</mi><mi>D</mi></mrow><mrow><mi>W</mi><mo>⋅</mo><msub><mi>N</mi><mtext>layers</mtext></msub></mrow></mfrac></math></mjx-assistive-mml></mjx-container> </span><p>由于我们除以了 <d-math>N_\text{layers}</d-math>，这个成本远小于其他任何成本。换句话说，从通信的角度来看，流水线基本上是免费的。那么为什么我们不只做流水线呢？有几个原因：</p> <p>(1) <strong>代码复杂性：</strong> 流水线不像其他方法那样能很好地融入自动并行框架（如 XLA 的 GSPMD）。因为它引入了微批次来隐藏流水线气泡，它改变了程序的结构，而定制的零气泡流水线调度通过要求前向和后向传播的复杂交错而加剧了这个问题。</p> <p>(2) <strong>流水线使得数据并行和 FSDP 变得困难：</strong> 可能不做流水线的最大原因是它与 FSDP 和数据并行的兼容性不好。特别是 ZeRO-3 分片效果很差，因为它要求我们在每个微批次上 AllGather 权重，而当我们只有 <d-math>B / N_\text{microbatches}</d-math> 个 token 来摊销 AllGather 成本时，这是行不通的。此外，在反向传播期间，<em>我们无法 AllReduce 或 ReduceScatter 梯度，直到最后一个微批次通过给定阶段，这意味着我们有显著的非重叠通信时间。</em></p> <figure> <picture> <img class="img-fluid" height="auto" loading="lazy" onerror="this.onerror=null; $('.responsive-img-srcset').remove();" src="https://jax-ml.github.io/scaling-book/assets/gpu/pipeline-bubble.png" width="100%"/> </picture> <figcaption class="caption"><b>图：</b>一个 2 阶段、2 微批次流水线的示例。F 表示阶段前向传播，B 是阶段后向传播（成本是 2 倍）。G 表示数据并行 AllReduces，它可能比单个微批次的时间长得多。</figcaption> </figure> <p>(3) <strong>流水线气泡和步骤不平衡：</strong> 正如你在上面（糟糕的）流水线调度中看到的，在一个简单的流水线调度中很容易出现显著的气泡（意味着计算浪费）。在上面，第二阶段在步骤 0 是空闲的，第一阶段在步骤 2 到 3 是空闲的，第二阶段在最后一步再次是空闲的。虽然我们可以通过仔细的调度来在一定程度上避免这些，但我们仍然经常有一些气泡。我们还必须在关键路径上将激活值从一个阶段传递到下一个阶段，这会增加开销：</p> <figure> <picture> <img class="img-fluid" height="auto" loading="lazy" onerror="this.onerror=null; $('.responsive-img-srcset').remove();" src="https://jax-ml.github.io/scaling-book/assets/gpu/pipeline-transfer.png" width="100%"/> </picture> <figcaption class="caption"><b>图：</b>一个示例流水线，显示了红色的传输成本。这会使阶段相互移动，并增加流水线气泡开销。</figcaption> </figure> <p>每个问题都有解决方法，但它们往往实现复杂且难以维护，但流水线仍然是一种相对于其他方法通信成本较低的技术。</p> <p><strong>关于延迟的警告：</strong> 如前所述，即使消息相当大，GPU 也很难达到完整的 AllReduce 带宽。这意味着即使我们理论上可以在多个节点上扩展例如专家并行的 AllToAlls，我们也可能难以达到总带宽的 50%。这意味着我们确实试图将 TP 或 EP 保持在较少数量的节点内，以最小化延迟开销。</p> <h3 id="examples">示例</h3> <p><strong>DeepSeek 是如何做的？</strong> 作为参考，<a href="https://arxiv.org/abs/2412.19437" rel="external nofollow noopener" target="_blank">DeepSeek V3</a> 是用 2048 个 H800 GPU 训练的，配置如下：</p> <ul> <li>64 路专家并行 (EP)，跨越 8 个节点</li> <li>16 路流水线并行 (PP)</li> <li>2 路 ZeRO-1 数据并行 (DP)</li> </ul> <p>它们的稳态批处理大小为 <code class="language-plaintext highlighter-rouge">4096 * 15360 = 62,914,560</code> 个 token，或每个 GPU 30k token。你可以看到这已经相当大了，但它们的模型也非常稀疏（k=8, E=256），所以你需要一个相当大的批处理大小。你可以看到，通过 64 路 EP 和 16 路 PP，我们总共得到了 1024 路模型并行，这意味着 AllReduce 是在脊级别完成的，并且因为只有 2 路，我们实际上获得了 <d-math>2 / (2 - 1) = 2</d-math> 倍的带宽。这也帮助减少了最终数据并行 AllReduce 与最终流水线阶段重叠的成本。</p> <p><strong>LLaMA-3 是如何做的？</strong> LLaMA-3 在 16k 个 GPU 上以 16M token 的批处理大小进行训练，或每个 GPU 约 1k token。他们做了：</p> <ul> <li>节点内 8 路张量并行 (TP)</li> <li>16 路流水线并行 (PP)</li> <li>128 路 ZeRO-1 数据并行</li> </ul> <p>这也是一个密集模型，所以总的来说这些事情都相当简单。16 路 PP 将数据并行 AllReduce 的成本降低了 16 倍，这帮助我们减少了临界批处理大小。</p> <h3 id="tldr-of-llm-scaling-on-gpus">GPU 上 LLM 扩展总结</h3> <p>让我们退一步，总结一下到目前为止我们学到的东西：</p> <ul> <li> <strong>数据并行或 FSDP (ZeRO-1/3) 需要每个 GPU 约 2500 个 token 的本地批处理大小</strong>，尽管理论上网络内规约 + 纯 DP 可以稍微减少这个数字。</li> <li> <strong>张量并行在最多约 8 路时是计算受限的</strong>，但我们缺乏带宽来扩展到更远，否则会变得通信受限。这主要将我们限制在单个 NVLink 域内（即单节点或需要使用 GB200NVL72，最多 72 个 GPU）。</li> <li> <strong>任何跨越多个节点的模型并行形式都可以进一步降低 FSDP 的成本</strong>，所以我们经常希望混合 PP + EP + TP 来跨越许多节点并降低 FSDP 成本。</li> <li> <strong>如果你能处理零气泡流水线的代码复杂性，并保持相当大的批处理大小以避免数据并行瓶颈，那么流水线并行效果很好。</strong> 流水线通常使得 ZeRO-3 不可能（因为你需要在每个流水线阶段都进行 AllGather），但你可以做 ZeRO-1。</li> </ul> <p><strong>从高层次上看，这为我们在 GPU 上分片大型模型提供了一个方案：</strong></p> <ul> <li>对于相对较小的密集模型，如果你有足够的批处理大小，积极的 FSDP 效果很好，如果需要，可能还可以加上一些流水线或张量并行。</li> <li>对于较大的密集模型，1-2 节点 TP + 多节点 PP + 纯 DP 的组合效果很好。</li> <li>对于 MoE，上述规则适用，但我们也可以做专家并行，我们通常更喜欢它而不是 TP。如果 <d-math>F &gt; 8 * C / W_\text{node}</d-math>，我们可以做大量的多节点专家并行，否则我们被限制在大约 2 节点 EP。</li> </ul> <h3 id="quiz-5-llm-rooflines">测验 5：LLM 屋顶线模型</h3> <p><strong>问题 1 [B200 屋顶线模型]：</strong> 一个 B200 DGX SuperPod（<strong>不是 GB200 NVL72</strong>）在一个节点内的带宽是 2 倍（900GB/s 出口），但在扩展网络中的带宽相同（400GB/s）（<a href="https://docs.nvidia.com/dgx-superpod/reference-architecture-scalable-infrastructure-b200/latest/network-fabrics.html" rel="external nofollow noopener" target="_blank">来源</a>）。总 FLOPs 如上所述。这对模型和数据并行的屋顶线模型有什么影响？</p> <details><summary>点击此处查看答案。</summary> <p><strong>答案：</strong> 我们的 bfloat16 FLOPs/s 从 990 增加到 2250 TFLOPs，增加了 2.25 倍。在节点内，带宽是 2 倍，我们的屋顶线模型大致保持不变。例如，对于 TP，临界强度上升到 <code class="language-plaintext highlighter-rouge">2250e12 / 900e9 = 2500</code>，所以我们的限制是 <d-math>Y &lt; F / 2500</d-math>，只高了一点点（而且除非节点大小增加，否则这对我们没有帮助）。</p> <p>然而，在节点之外，缺乏额外的带宽实际上使得我们更难达到计算受限！例如，对于数据并行，我们的临界批处理大小增加到 <code class="language-plaintext highlighter-rouge">2250e12 / 400e9 = 5625</code>，因为我们的 GPU 可以在相同带宽下执行显著更多的 FLOPs。</p> <p>具有 72-GPU 节点的 GB200 SuperPods 通过增加更多的出口带宽来改变这一点（<a href="https://docs.nvidia.com/dgx-superpod/reference-architecture-scalable-infrastructure-gb200/latest/network-fabrics.html#compute-fabric-576" rel="external nofollow noopener" target="_blank">来源</a>）。</p> </details> <p><strong>问题 2 [如何分片 LLaMA-3 70B]：</strong> 考虑 LLaMA-3 70B，用 bfloat16 训练，优化器状态为 fp32，使用 Adam。</p> <ol> <li>至少需要多少个 H100 才能存储权重和优化器？</li> <li>假设我们想在 4096 个 H100 GPU 上训练 15T token。假设我们达到了 45% 的 MFU（模型 FLOPs 利用率）。训练需要多长时间？</li> <li>LLaMA-3 70B 的 <code class="language-plaintext highlighter-rouge">F = 28,672</code>，训练时的批处理大小约为 4M token。在不成为通信受限的情况下，我们最多可以做多少模型并行？用这个加上纯 DP，我们能在保持计算受限的情况下训练 LLaMA-3 吗？ZeRO-3 呢？8 路流水线呢？</li> </ol> <details><summary>点击此处查看答案。</summary> <ol> <li>我们需要 2 字节用于权重，8 字节用于优化器状态，所以至少 700GB。每个 H100 有 80GB 的 DRAM，所以我们至少需要 9 个 GPU，或者（向上取整）至少 2 个 8xH100 节点。这需要很长时间来训练，并且无法保存梯度检查点，但这是一个下限。</li> <li>这总共需要 <code class="language-plaintext highlighter-rouge">6 * 70e9 * 15e12 = 6.3e24 bf16 FLOPs</code>。每个 GPU 可以执行 <code class="language-plaintext highlighter-rouge">990e12</code> FLOPs，所以在 40% MFU 下我们可以执行 1.6e18 FLOPs/s。因此整个过程需要 3.9e6 秒，或 45 天。</li> <li>在节点内，我们有 450GB/s 的带宽，所以限制大约是 <code class="language-plaintext highlighter-rouge">F / 1995 = 28672 / 1995 = 14.372</code>。由于这不会跨越 2 个节点，实际意味着我们会做到 8 路模型并行。 <ol> <li>这需要我们做 512 路 DP。首先，我们需要看是否有足够的内存。由于我们的模型只分片 8 路，这意味着 <code class="language-plaintext highlighter-rouge">700GB / 8 = 87.5GB / GPU</code>，这放不下，所以不行！</li> <li>使用 ZeRO-3 和 8 路 TP，我们将进行 512 路 ZeRO-3。这不会有任何内存问题，因为我们积极地分片了一切。我们将有每个 GPU <code class="language-plaintext highlighter-rouge">4e6 / 4096 = 976</code> 的批处理大小。这相当低，甚至低于我们的纯 DP 限制，而且这是该限制的两倍，因为我们必须移动我们的权重。所以不行。</li> <li>使用 8 路流水线，每个模型并行分片现在跨越 8 个节点。正如我们所见，这将我们叶级别的 AllGathers 成本降低了 8 倍，所以那里的总 AllReduce/AllGather 带宽从 400GB/s 增加到 <code class="language-plaintext highlighter-rouge">8 * 400GB/s = 3200GB/s</code>。那么屋顶线模型就是 <code class="language-plaintext highlighter-rouge">989e12 / 3200e9 = 309</code>，所以我们应该没问题！我们只需要高效地实现流水线。</li> </ol> </li> </ol> </details> <p><strong>问题 3 [Megatron-LM 超参数]：</strong> 考虑<a href="https://github.com/NVIDIA/Megatron-LM" rel="external nofollow noopener" target="_blank">Megatron-LM 仓库</a>中的这张图，突出了他们的高 MFU 数字。</p> <figure> <picture> <img class="img-fluid" height="auto" loading="lazy" onerror="this.onerror=null; $('.responsive-img-srcset').remove();" src="https://jax-ml.github.io/scaling-book/assets/gpu/megatron-hparams.png" width="100%"/> </picture> </figure> <p>请注意，他们的序列长度到处都是 4096。对于 16B、70B 和 314B 模型，每个 GPU 的 token 批处理大小是多少？假设数据并行是最外层的轴，并假设 bfloat16 规约，确定这些模型中的每一个在理论上是计算受限还是通信受限，以及是否有更优的配置可用？</p> <details><summary>点击此处查看答案。</summary> <p><strong>答案：</strong> 让我们从每个 GPU 的批处理大小开始。</p> <ul> <li> <strong>16B</strong>: <code class="language-plaintext highlighter-rouge">192 * 4096 / 192 = 4096</code> token / GPU</li> <li> <strong>70B</strong>: <code class="language-plaintext highlighter-rouge">384 * 4096 / 768 = 2048</code> token / GPU</li> <li> <strong>314B</strong>: <code class="language-plaintext highlighter-rouge">1536 * 4096 / 3072 = 2048</code> token / GPU</li> </ul> <p>这意味着除了第一个，这些都徘徊在每个批次 2k token 左右，这恰好是我们为 FSDP 计算的临界阈值附近。我们计算出该界限为 2,472 token / GPU，基于脊级别的规约，这应该在这里大致适用。然而，对于 70B 和 314B，因为我们分别有 16 路和 64 路模型分片，我们在脊级别获得了 2 倍和 8 倍的吞吐量提升，这意味着我们应该分别在大约 1k 和 300 token / 步时达到计算受限。</p> </details> <h2 id="acknowledgements-and-further-reading">致谢与延伸阅读</h2> <p>本章严重依赖于许多知识渊博的 GPU 专家的帮助，包括：</p> <ul> <li>Adam Paszke，他帮助解释了在 GPU 上进行内核编程的现实情况。</li> <li>Swapnil Patil，他首先解释了 GPU 网络的工作原理。</li> <li>Stas Bekman，他指出 GPU 的经验现实往往与声称的规格不同。</li> <li>Reiner Pope，他帮助阐明了 GPU 和 TPU 在硬件层面的比较。</li> <li>Frédéric Bastien，他对芯片级的故事提供了详细的反馈。</li> <li>Nouamane Tazi，他在 GPU 上进行 LLM 训练的经验帮助改进了屋顶线模型部分。</li> <li>Sanford Miller，他帮助我理解了 GPU 是如何联网的，以及 NVIDIA 的规格与实际部署的规格有何不同。</li> </ul> <p>关于 GPU 有很多好的读物，但我最喜欢的一些包括：</p> <ul> <li> <a href="https://semianalysis.com/2025/06/23/nvidia-tensor-core-evolution-from-volta-to-blackwell/" rel="external nofollow noopener" target="_blank">SemiAnalysis 的 NVIDIA Tensor Core 历史</a>：一篇精彩的文章，描述了 GPU 如何从视频游戏引擎转变为 ML 加速器。</li> <li> <a href="https://semianalysis.com/2024/04/10/nvidia-blackwell-perf-tco-analysis/" rel="external nofollow noopener" target="_blank">SemiAnalysis 对 Blackwell 性能的分析</a>：值得一读，以了解下一代 NVIDIA GPU。</li> <li> <a href="https://docs.nvidia.com/dgx-superpod-reference-architecture-dgx-h100.pdf" rel="external nofollow noopener" target="_blank">H100 DGX SuperPod 参考</a>：关于大型 GPU 集群如何联网的枯燥但有用的读物。<a href="https://docs.nvidia.com/dgx-superpod/reference-architecture-scalable-infrastructure-gb200/latest/network-fabrics.html#compute-fabric-576" rel="external nofollow noopener" target="_blank">这里</a>是关于 GB200 系统的类似文档。</li> <li> <a href="https://hc34.hotchips.org/assets/program/conference/day2/Network%20and%20Switches/NVSwitch%20HotChips%202022%20r5.pdf" rel="external nofollow noopener" target="_blank">关于 NVLink Switch 的 Hot Chips 演讲</a>：关于 NVLink 和 NCCL 集合通信的有趣读物，特别包括网络内规约。</li> <li> <a href="https://arxiv.org/pdf/2412.19437" rel="external nofollow noopener" target="_blank">DeepSeek-V3 技术报告</a>：一个大型半开放 LLM 训练报告的好例子，描述了他们如何选择分片设置。</li> <li> <a href="https://siboehm.com/articles/22/CUDA-MMM" rel="external nofollow noopener" target="_blank">如何优化 CUDA 矩阵乘法</a>：一篇很棒的博客，描述了如何使用 CUDA 核心实现高效的矩阵乘法，并着眼于 GPU 上的缓存一致性。</li> <li> <a href="https://huggingface.co/spaces/nanotron/ultrascale-playbook" rel="external nofollow noopener" target="_blank">HuggingFace 超大规模手册：</a>一个关于 GPU 上 LLM 并行性的指南，本章部分灵感来源于此。</li> <li> <a href="https://horace.io/brrr_intro.html" rel="external nofollow noopener" target="_blank">从第一性原理让深度学习飞速发展：</a>一个更侧重于 GPU 和 PyTorch 的关于 LLM 屋顶线模型和性能工程的教程。</li> </ul> <h2 id="appendix-a-how-does-this-change-with-gb200">附录 A：GB200 会带来哪些变化？</h2> <p>Blackwell 引入了一系列重大的网络变化，包括 NVLink 5，其总 NVLink 带宽是原来的两倍（900GB/s）。B200 仍然有 8-GPU 节点，就像 H100s 一样，但 GB200 系统（将 B200 GPU 与 Grace CPU 结合）引入了更大的 NVLink 域（NVL72 中有 72 个 GPU，理论上最多 576 个）。这个更大的 NVLink 域也有效地增加了节点出口带宽，从而降低了节点之上的集合通信成本。</p> <figure> <picture> <img class="img-small" height="auto" loading="lazy" onerror="this.onerror=null; $('.responsive-img-srcset').remove();" src="https://jax-ml.github.io/scaling-book/assets/gpu/b200-node.png" width="100%"/> </picture> <figcaption class="caption"><b>图：</b>一个展示 GB200 NVL72 单元如何构建的图表，包含 18 个交换机和 72 个 GPU。</figcaption> </figure> <p>在节点内，这种增加的带宽（从 450GB/s 到 900GB/s）并没有太大区别，因为我们也使每个 GPU 的总 FLOPs/s 翻倍。我们的屋顶线模型基本保持不变，尽管因为 NVLink 有更好的带宽，专家并行变得更容易。</p> <p>在节点之外，情况变化更大。这是来自<a href="https://docs.nvidia.com/dgx-superpod/reference-architecture-scalable-infrastructure-gb200/latest/network-fabrics.html#compute-fabric-576" rel="external nofollow noopener" target="_blank">这里</a>的 SuperPod 图。</p> <figure> <picture> <img class="img-fluid" height="auto" loading="lazy" onerror="this.onerror=null; $('.responsive-img-srcset').remove();" src="https://jax-ml.github.io/scaling-book/assets/gpu/gb200-superpod.png" width="100%"/> </picture> <figcaption class="caption"><b>图：</b>一个包含 576 个 GPU 的 GB200 DGX SuperPod 的示意图。</figcaption> </figure> <p>如你所见，每个节点的出口带宽增加到 <code class="language-plaintext highlighter-rouge">4 * 18 * 400 / 8 = 3.6TB/s</code>，而 H100 中是 400GB/s。由于我们的 FLOPs/芯片也翻倍，这使得有效的跨节点屋顶线模型提高了约 4 倍。现在我们可能开始担心我们是否在节点级别而不是扩展级别遇到瓶颈。</p> <p><strong>Grace Hopper：</strong> NVIDIA 还销售 GH200 和 GB200 系统，它们将一定数量的 GPU 与一个 Grace CPU 配对。例如，一个 GH200 有 1 个 H200 和 1 个 Grace CPU，而一个 GB200 系统有 2 个 B200 和 1 个 Grace CPU。这个系统的一个优点是 CPU 通过一个全带宽的 NVLink 连接（称为 NVLink C2C）连接到 GPU，所以你有非常高的 CPU 到 GPU 带宽，这对于将参数卸载到主机 RAM 很有用。换句话说，对于任何给定的 GPU，到达主机内存的带宽与到达另一个 GPU 的 HBM 的带宽相同。</p> <h2 id="appendix-b-more-networking-details">附录 B：更多网络细节</h2> <p>这是一张 NVLink 4 交换机的图。总共有 64 个 NVLink4 端口（每个使用 2 个物理通道），以及一个处理通道间交换的大型交叉开关。相比之下，TPU 使用可以动态重新配置的带反射镜的光学交换机。</p> <figure> <picture> <img class="img-fluid" height="auto" loading="lazy" onerror="this.onerror=null; $('.responsive-img-srcset').remove();" src="https://jax-ml.github.io/scaling-book/assets/gpu/nvlink4.png" width="100%"/> </picture> <figcaption class="caption"><b>图：</b>一个单个 NVLink4 交换机的底层视图。</figcaption> </figure> <p>在每个级别，我们都可能受限于可用的链接带宽或总交换机带宽。</p> <ul> <li> <strong>节点级别：</strong> 在节点级别，我们有 4 * 1.6TB/s = 6.4TB/s 的 NVSwitch 带宽，但我们的 8 个 GPU 每个只能向交换机出口 450GB/s，这意味着我们实际上在节点内的峰值带宽是 450e9 * 8 = 3.6TB/s（全双工）。</li> <li> <strong>SU/叶级别：</strong> 在 SU 级别，我们有 8 个交换机以全对全的方式连接 32 个节点，使用 1x400 Gbps Infiniband。这给了我们 8 * 32 * 400 / 8 = 12.8TB/s 的节点出口带宽，我们在交换机级别有 8 * 1.6TB/s = 12.8TB/s，所以两者精确一致。</li> <li> <strong>脊级别：</strong> 在脊级别，我们有 16 个交换机连接 32 个叶交换机，使用 2x400 Gbps 链接，所以我们有 32 * 16 * 400 * 2 / 8 = 51.2TB/s 的出口带宽。16 个交换机给了我们 16 * 1.6TB/s = 25.6TB/s 的带宽，所以这是这个级别的瓶颈。</li> </ul> <p>每个 GPU，这给了我们节点级别 450GB/s 的 GPU 间带宽，SU 级别 50GB/s，脊级别 25 GB/s。</p> <p><strong>GPU 经验 AR 带宽：</strong></p> <figure> <picture> <img class="img-fluid" height="auto" loading="lazy" onerror="this.onerror=null; $('.responsive-img-srcset').remove();" src="https://jax-ml.github.io/scaling-book/assets/gpu/gpu-all-reduce-bw.png" width="100%"/> </picture> <figcaption class="caption"><b>图：</b>一个 8xH100 集群上的 AllReduce 带宽（节点内，禁用 SHARP）。</figcaption> </figure> <p>TPU v5p 带宽（1 轴）：</p> <figure> <picture> <img class="img-fluid" height="auto" loading="lazy" onerror="this.onerror=null; $('.responsive-img-srcset').remove();" src="https://jax-ml.github.io/scaling-book/assets/gpu/tpu-all-reduce-bw.png" width="100%"/> </picture> <figcaption class="caption"><b>图：</b>一个 TPU v5p 4x4x4 集群上的 AllReduce 带宽（沿一个轴）。</figcaption> </figure> <p>这里还有 AllGather 带宽：</p> <figure> <picture> <img class="img-fluid" height="auto" loading="lazy" onerror="this.onerror=null; $('.responsive-img-srcset').remove();" src="https://jax-ml.github.io/scaling-book/assets/gpu/gpu-all-gather-bw.png" width="100%"/> </picture> <figcaption class="caption"><b>图：</b>一个 8xH100 集群上的 AllGather 带宽（节点内）。</figcaption> </figure> <figure> <picture> <img class="img-fluid" height="auto" loading="lazy" onerror="this.onerror=null; $('.responsive-img-srcset').remove();" src="https://jax-ml.github.io/scaling-book/assets/gpu/tpu-all-gather-bw.png" width="100%"/> </picture> <figcaption class="caption"><b>图：</b>一个 TPU v5e 8x16 集群上的 AllGather 带宽（沿一个轴）。</figcaption> </figure> <p><strong>更多关于 AllToAll 成本的信息：</strong></p> <p>这里我们可以比较近似值 <d-math>\min(K / Z) * (Z - 1) / Z</d-math> 和真实值 <d-math>(1 - ((Z - 1) / Z) ** K) * (Z - 1) / Z</d-math>。除了 <d-math>Z</d-math> 值较小时，它们是相似的。</p> <figure> <picture> <img class="img-fluid" height="auto" loading="lazy" onerror="this.onerror=null; $('.responsive-img-srcset').remove();" src="https://jax-ml.github.io/scaling-book/assets/gpu/all-to-all-approx.png" width="100%"/> </picture> <figcaption class="caption"><b>图：</b>随着分片数量增加，不规则 AllToAll 的近似成本与真实成本的比较。</figcaption> </figure> </d-article> <d-appendix>
<style>

d-appendix {
  contain: layout style;
  font-size: 0.8em;
  line-height: 1.7em;
  margin-top: 60px;
  margin-bottom: 0;
  border-top: 1px solid rgba(0, 0, 0, 0.1);
  color: rgba(0,0,0,0.5);
  padding-top: 60px;
  padding-bottom: 48px;
}

d-appendix h3 {
  grid-column: page-start / text-start;
  font-size: 15px;
  font-weight: 500;
  margin-top: 1em;
  margin-bottom: 0;
  color: rgba(0,0,0,0.65);
}

d-appendix h3 + * {
  margin-top: 1em;
}

d-appendix ol {
  padding: 0 0 0 15px;
}

@media (min-width: 768px) {
  d-appendix ol {
    padding: 0 0 0 30px;
    margin-left: -30px;
  }
}

d-appendix li {
  margin-bottom: 1em;
}

d-appendix a {
  color: rgba(0, 0, 0, 0.6);
}

d-appendix > * {
  grid-column: text;
}

d-appendix > d-footnote-list,
d-appendix > d-citation-list,
d-appendix > distill-appendix {
  grid-column: screen;
}

</style>
<d-footnote-list style="">
<style>

d-footnote-list {
  contain: layout style;
}

d-footnote-list > * {
  grid-column: text;
}

d-footnote-list a.footnote-backlink {
  color: rgba(0,0,0,0.3);
  padding-left: 0.5em;
}

</style>
<h3>脚注</h3>
<ol><li id="d-footnote-1-listing">GPU 的 Tensor Core 是 SM 的矩阵乘法子单元，而 TPU 的 TensorCore 是包含 MXU、VPU 和其他组件的总称单元。<a class="footnote-backlink" href="#d-footnote-1">[↩]</a></li><li id="d-footnote-2-listing">NVIDIA 对此没有一个好的命名，所以我们只是在几个糟糕的选项中选择了最好的一个。Warp 调度器主要是向一组 CUDA 核心分派工作的单元，但我们在这里用它来描述控制单元和它所控制的核心集合。<a class="footnote-backlink" href="#d-footnote-2">[↩]</a></li><li id="d-footnote-3-listing">虽然 SM 是独立的，但为了达到峰值性能，它们通常被迫进行协调，因为它们都共享一个容量有限的 L2 缓存。<a class="footnote-backlink" href="#d-footnote-3">[↩]</a></li><li id="d-footnote-4-listing">较新的 GPU 支持 FMA（融合乘加）指令，理论上每个周期执行两个 FLOPs，NVIDIA 无情地利用这一事实将其报告的规格翻倍。<a class="footnote-backlink" href="#d-footnote-4">[↩]</a></li><li id="d-footnote-5-listing">历史上，在引入 Tensor Core 之前，CUDA 核心是 GPU 的主要组件，用于渲染，包括光线-三角形相交和着色。在今天的游戏 GPU 上，它们仍然承担大部分渲染工作，而 TensorCore 用于上采样（DLSS），这使得 GPU 可以在较低分辨率下渲染（像素越少 = 工作量越少），然后使用机器学习进行上采样。<a class="footnote-backlink" href="#d-footnote-5">[↩]</a></li><li id="d-footnote-6-listing">NVIDIA 没有分享很多 TC 硬件细节，所以这更多的是猜测而非确切事实——当然，这并不能说明 TC 是如何实现的。我们知道 V100 每个 TC 每周期可以执行 256 FLOPs。A100 可以做到 512，H100 可以做到 1024，而 B200 的细节尚未公布，但似乎可能是 2048 FLOPs/TC/周期，因为 `2250e12 / (148 * 4 * 1.86e9)` 大约是 2048。更多细节在<a href="https://forums.developer.nvidia.com/t/how-to-calculate-the-tensor-core-fp16-performance-of-h100/244727" rel="external nofollow noopener" target="_blank">这里</a>得到确认。<a class="footnote-backlink" href="#d-footnote-6">[↩]</a></li><li id="d-footnote-7-listing">在 Ampere 中，Tensor Core 可以由单个 warp 提供数据，而在 Hopper 中则需要一个完整的 SM（warpgroup），在 Blackwell 中则由 2 个 SM 提供数据。在 Blackwell 中，矩阵乘法也变得如此之大，以至于参数（特别是累加器）不再适合寄存器内存/SMEM，因此 Blackwell 增加了 TMEM 来解决这个问题。<a class="footnote-backlink" href="#d-footnote-7">[↩]</a></li><li id="d-footnote-8-listing">在给定 SM 上调度的 Warp 称为“驻留”。<a class="footnote-backlink" href="#d-footnote-8">[↩]</a></li><li id="d-footnote-9-listing">技术上，L2 缓存被分成两半，因此在 H100 上，一半的 SM 可以各自访问 25MB。有一个连接这两半的链接，但带宽较低。<a class="footnote-backlink" href="#d-footnote-9">[↩]</a></li><li id="d-footnote-10-listing">L2 缓存被所有 SM 共享这一事实，实际上迫使程序员以一种相当协调的方式运行 SM，尽管原则上它们是独立的单元。<a class="footnote-backlink" href="#d-footnote-10">[↩]</a></li><li id="d-footnote-11-listing">虽然 NVIDIA 制造了 B100 代，但它们只短暂销售和生产，据称是由于设计缺陷导致它们无法接近其声称的规格运行。它们在不因散热和功耗问题而降频的情况下难以达到峰值 FLOPs。<a class="footnote-backlink" href="#d-footnote-11">[↩]</a></li><li id="d-footnote-12-listing">在深度学习热潮之前，GPU（“图形处理单元”）做的是，嗯，图形处理——主要是为了视频游戏。视频游戏用数百万个小三角形来表示物体，游戏将这些三角形渲染（或“光栅化”）成一个二维图像，每秒在屏幕上显示 30-60 次（这个频率称为帧率）。光栅化涉及将这些三角形投影到相机的坐标系中，并计算哪些三角形与哪些像素重叠，每秒数十亿次。可以想象，这是非常昂贵的，而这仅仅是开始。然后你必须通过组合可能与光线相交的几个半透明三角形的颜色来为每个像素着色。GPU 被设计用来极快地执行这些操作，并着眼于通用性；你需要同时运行许多不同的 GPU 工作负载（称为“着色器”），而没有任何单一操作占主导地位。因此，面向消费者的图形 GPU 可以进行矩阵乘法，但这并不是它们的主要功能。<a class="footnote-backlink" href="#d-footnote-12">[↩]</a></li><li id="d-footnote-13-listing">值得注意的是，这个强度在最近几代 GPU 中保持不变。对于 H100s 是 33.5 / 3.5，对于 B200 是 80 / 8。为什么会这样尚不清楚，但这是一个有趣的观察。<a class="footnote-backlink" href="#d-footnote-13">[↩]</a></li><li id="d-footnote-14-listing">术语“节点”是重载的，可以指两件事：NVLink 域，即通过 NVLink 互连完全连接的 GPU 集合，或者连接到单个 CPU 主机的 GPU 集合。在 B200 之前，这两者通常是相同的，但在 GB200 NVL72 中，我们有一个包含 72 个 GPU 的 NVLink 域，但每个主机仍然只连接 8 个 GPU。我们在这里使用术语“节点”来指代 NVLink 域，但这有争议。<a class="footnote-backlink" href="#d-footnote-14">[↩]</a></li><li id="d-footnote-15-listing">有人向我描述 NVLink 就像一个增强版的 PCIe 连接，具有低延迟和协议开销，但不是为可扩展性/容错性设计的，而 InfiniBand 更像以太网，专为更大的有损网络设计。<a class="footnote-backlink" href="#d-footnote-15">[↩]</a></li><li id="d-footnote-16-listing">这里的全双工意味着每个方向 25GB/s，两个方向相互独立。你可以在链路上总共发送 50GB/s，但每个方向最多 25GB/s。<a class="footnote-backlink" href="#d-footnote-16">[↩]</a></li><li id="d-footnote-17-listing">例如，Meta 在一个与此描述显著不同的数据中心网络上训练了 LLaMA-3，该网络使用以太网、一个三层交换结构，并且在顶层有一个超额订阅的交换机。<a class="footnote-backlink" href="#d-footnote-17">[↩]</a></li><li id="d-footnote-18-listing">你也可以认为每个 GPU 将其大小为 <d-math>\text{bytes} / N</d-math> 的块发送给其他 <d-math>N - 1</d-math> 个 GPU，总共通信了 <d-math>(N - 1) * N * bytes / N</d-math> 字节，这给了我们<a class="footnote-backlink" href="#d-footnote-18">[↩]</a></li><li id="d-footnote-19-listing">真实成本实际上是 <mjx-container class="MathJax CtxtMenu_Attached_0" ctxtmenu_counter="3" display="true" jax="CHTML" style="font-size: 113.1%; position: relative;" tabindex="0"><mjx-math aria-hidden="true" class="MJX-TEX" display="true" style="margin-left: 0px; margin-right: 0px;"><mjx-mo class="mjx-n"><mjx-c class="mjx-c28"></mjx-c></mjx-mo><mjx-mn class="mjx-n"><mjx-c class="mjx-c31"></mjx-c></mjx-mn><mjx-mo class="mjx-n" space="3"><mjx-c class="mjx-c2212"></mjx-c></mjx-mo><mjx-msup space="3"><mjx-mrow><mjx-mo class="mjx-s3"><mjx-c class="mjx-c28 TEX-S3"></mjx-c></mjx-mo><mjx-mfrac><mjx-frac type="d"><mjx-num><mjx-nstrut type="d"></mjx-nstrut><mjx-mrow><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D44D TEX-I"></mjx-c></mjx-mi><mjx-mo class="mjx-n" space="3"><mjx-c class="mjx-c2212"></mjx-c></mjx-mo><mjx-mn class="mjx-n" space="3"><mjx-c class="mjx-c31"></mjx-c></mjx-mn></mjx-mrow></mjx-num><mjx-dbox><mjx-dtable><mjx-line type="d"></mjx-line><mjx-row><mjx-den><mjx-dstrut type="d"></mjx-dstrut><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D44D TEX-I"></mjx-c></mjx-mi></mjx-den></mjx-row></mjx-dtable></mjx-dbox></mjx-frac></mjx-mfrac><mjx-mo class="mjx-s3"><mjx-c class="mjx-c29 TEX-S3"></mjx-c></mjx-mo></mjx-mrow><mjx-script style="vertical-align: 1.177em;"><mjx-mi class="mjx-i" size="s"><mjx-c class="mjx-c1D43E TEX-I"></mjx-c></mjx-mi></mjx-script></mjx-msup><mjx-mo class="mjx-n"><mjx-c class="mjx-c29"></mjx-c></mjx-mo><mjx-mo class="mjx-n" space="3"><mjx-c class="mjx-c22C5"></mjx-c></mjx-mo><mjx-mfrac space="3"><mjx-frac type="d"><mjx-num><mjx-nstrut type="d"></mjx-nstrut><mjx-mrow><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D44D TEX-I"></mjx-c></mjx-mi><mjx-mo class="mjx-n" space="3"><mjx-c class="mjx-c2212"></mjx-c></mjx-mo><mjx-mn class="mjx-n" space="3"><mjx-c class="mjx-c31"></mjx-c></mjx-mn></mjx-mrow></mjx-num><mjx-dbox><mjx-dtable><mjx-line type="d"></mjx-line><mjx-row><mjx-den><mjx-dstrut type="d"></mjx-dstrut><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D44D TEX-I"></mjx-c></mjx-mi></mjx-den></mjx-row></mjx-dtable></mjx-dbox></mjx-frac></mjx-mfrac></mjx-math><mjx-assistive-mml display="block" unselectable="on"><math display="block" xmlns="http://www.w3.org/1998/Math/MathML"><mo stretchy="false">(</mo><mn>1</mn><mo>−</mo><msup><mrow data-mjx-texclass="INNER"><mo data-mjx-texclass="OPEN">(</mo><mfrac><mrow><mi>Z</mi><mo>−</mo><mn>1</mn></mrow><mi>Z</mi></mfrac><mo data-mjx-texclass="CLOSE">)</mo></mrow><mi>K</mi></msup><mo stretchy="false">)</mo><mo>⋅</mo><mfrac><mrow><mi>Z</mi><mo>−</mo><mn>1</mn></mrow><mi>Z</mi></mfrac></math></mjx-assistive-mml></mjx-container> 在 <d-math>K</d-math> 次掷骰子中不同结果的期望数量，但它非常接近给出的近似值。更多细节请参见附录。<a class="footnote-backlink" href="#d-footnote-19">[↩]</a></li></ol>
</d-footnote-list> <d-citation-list style="display: none;"></d-citation-list> <div class="base-grid appendix-entry"> <h3 style="grid-column: 0;">其他</h3> <p class="author-footnote" style="grid-column: text;"><sup>*</sup>在 Google DeepMind 完成的工作，现就职于 MatX。</p> </div> <div class="base-grid appendix-entry"> <h3 style="grid-column: 0;">引用</h3> <p class="author-footnote">在学术背景下引用，请按如下格式引用本作品：</p> <div class="author-footnote"> <div class="language-bibtex highlighter-rouge"><div class="highlight"><div class="code-display-wrapper"><pre class="highlight"><code>    <span class="c">Austin et al., "How to Scale Your Model", Google DeepMind, online, 2025.</span>
</code></pre><button aria-label="Copy code to clipboard" class="copy" type="button"><i class="fa-solid fa-clipboard"></i></button></div></div></div> </div> <p class="author-footnote">或作为 BibTeX 条目：</p> <div class="author-footnote"> <div class="language-bibtex highlighter-rouge"><div class="highlight"><div class="code-display-wrapper"><pre class="highlight"><code>    <span class="nc">@article</span><span class="p">{</span><span class="nl">scaling-book</span><span class="p">,</span>
      <span class="na">title</span> <span class="p">=</span> <span class="s">{How to Scale Your Model}</span><span class="p">,</span>
      <span class="na">author</span> <span class="p">=</span> <span class="s">{Austin, Jacob and Douglas, Sholto and Frostig, Roy and Levskaya, Anselm and Chen, Charlie and Vikram, Sharad
      and Lebron, Federico and Choy, Peter and Ramasesh, Vinay and Webson, Albert and Pope, Reiner}</span><span class="p">,</span>
      <span class="na">publisher</span> <span class="p">=</span> <span class="s">{Google DeepMind}</span><span class="p">,</span>
      <span class="na">howpublished</span> <span class="p">=</span> <span class="s">{Online}</span><span class="p">,</span>
      <span class="na">note</span> <span class="p">=</span> <span class="s">{Retrieved from https://jax-ml.github.io/scaling-book/}</span><span class="p">,</span>
      <span class="na">year</span> <span class="p">=</span> <span class="s">{2025}</span>
    <span class="p">}</span>
</code></pre><button aria-label="Copy code to clipboard" class="copy" type="button"><i class="fa-solid fa-clipboard"></i></button></div></div></div> </div> </div> </d-appendix> <d-bibliography src="/scaling-book/assets/bibliography/main.bib"></d-bibliography> <div id="giscus_thread" style="max-width: 930px; margin: 0 auto;"> <script>
      let giscusTheme = determineComputedTheme();
      let giscusAttributes = {
        src: 'https://giscus.app/client.js',
        'data-repo': 'jax-ml/scaling-book',
        'data-repo-id': '',
        'data-category': 'General',
        'data-category-id': '',
        'data-mapping': 'title',
        'data-strict': '0',
        'data-reactions-enabled': '1',
        'data-emit-metadata': '0',
        'data-input-position': 'bottom',
        'data-theme': giscusTheme,
        'data-loading': '1',
        'data-lang': 'en',
        crossorigin: 'anonymous',
        async: '',
      };

      let giscusScript = document.createElement('script');
      Object.entries(giscusAttributes).forEach(([key, value]) => giscusScript.setAttribute(key, value));
      document.getElementById('giscus_thread').appendChild(giscusScript);
    </script><script async="" crossorigin="anonymous" data-category="General" data-category-id="" data-emit-metadata="0" data-input-position="bottom" data-lang="en" data-loading="1" data-mapping="title" data-reactions-enabled="1" data-repo="jax-ml/scaling-book" data-repo-id="" data-strict="0" data-theme="light" src="https://giscus.app/client.js"></script><div class="giscus"><iframe allow="clipboard-write" class="giscus-frame giscus-frame--loading" scrolling="no" src="https://giscus.app/en/widget?origin=https%3A%2F%2Fjax-ml.github.io%2Fscaling-book%2Fgpus%2F&amp;session=&amp;theme=light&amp;reactionsEnabled=1&amp;emitMetadata=0&amp;inputPosition=bottom&amp;repo=jax-ml%2Fscaling-book&amp;repoId=&amp;category=General&amp;categoryId=&amp;strict=0&amp;description=We+love+TPUs+at+Google%2C+but+GPUs+are+great+too.+This+chapter+takes+a+deep+dive+into+the+world+of+NVIDIA+GPUs+%E2%80%93+how+each+chip+works%2C+how+they%E2%80%99re+networked+together%2C+and+what+that+means+for+LLMs%2C+especially+compared+to+TPUs.+This+section+builds+on+%3Ca+href%3D%27https%3A%2F%2Fjax-ml.github.io%2Fscaling-book%2Ftpus%2F%27%3EChapter+2%3C%2Fa%3E+and+%3Ca+href%3D%27https%3A%2F%2Fjax-ml.github.io%2Fscaling-book%2Ftraining%27%3EChapter+5%3C%2Fa%3E%2C+so+you+are+encouraged+to+read+them+first.&amp;backLink=https%3A%2F%2Fjax-ml.github.io%2Fscaling-book%2Fgpus%2F&amp;term=How+to+Think+About+GPUs+%7C+How+To+Scale+Your+Model" style="opacity: 0;" title="Comments"></iframe></div> <noscript>请启用 JavaScript 以查看由 giscus 驱动的<a href="http://giscus.app/?ref_noscript" rel="external nofollow noopener" target="_blank">评论</a>。 </noscript> </div> </div> <footer class="sticky-bottom mt-5" role="contentinfo"> <div class="container"> © 版权所有 2025。由 <a href="https://jekyllrb.com/" rel="external nofollow noopener" target="_blank">Jekyll</a> 驱动，使用 <a href="https://github.com/alshedivat/al-folio" rel="external nofollow noopener" target="_blank">al-folio</a> 主题。托管于 <a href="https://pages.github.com/" rel="external nofollow noopener" target="_blank">GitHub Pages</a>。 </div> </footer> <script crossorigin="anonymous" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js"></script> <script src="https://jax-ml.github.io/scaling-book/assets/js/bootstrap.bundle.min.js"></script> <script crossorigin="anonymous" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js"></script> <script crossorigin="anonymous" defer="" integrity="sha256-ZgMyDAIYDYGxbcpJcfUnYwNevG/xi9OHKaR/8GK+jWc=" src="https://cdn.jsdelivr.net/npm/medium-zoom@1.1.0/dist/medium-zoom.min.js"></script> <script defer="" src="https://jax-ml.github.io/scaling-book/assets/js/zoom.js?85ddb88934d28b74e78031fd54cf8308"></script> <script src="https://jax-ml.github.io/scaling-book/assets/js/no_defer.js?2781658a0a2b13ed609542042a859126"></script> <script defer="" src="https://jax-ml.github.io/scaling-book/assets/js/common.js?e0514a05c5c95ac1a93a8dfd5249b92e"></script> <script defer="" src="https://jax-ml.github.io/scaling-book/assets/js/copy_code.js?12775fdf7f95e901d7119054556e495f" type="text/javascript"></script> <script defer="" src="https://jax-ml.github.io/scaling-book/assets/js/jupyter_new_tab.js?d9f17b6adc2311cbabd747f4538bb15f"></script> <script crossorigin="anonymous" defer="" id="MathJax-script" integrity="sha256-MASABpB4tYktI2Oitl4t+78w/lyA+D7b/s9GEP0JOGI=" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.2/es5/tex-mml-chtml.js" type="text/javascript"></script> <script src="https://jax-ml.github.io/scaling-book/assets/js/mathjax-setup.js?70d799092f862ad98c7876aa47712e20"></script> <script crossorigin="anonymous" defer="" src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6"></script> <script defer="" src="https://jax-ml.github.io/scaling-book/assets/js/progress-bar.js?2f30e0e6801ea8f5036fa66e1ab0a71a" type="text/javascript"></script> <script src="https://jax-ml.github.io/scaling-book/assets/js/vanilla-back-to-top.min.js?f40d453793ff4f64e238e420181a1d17"></script> <script>
    addBackToTop();
  </script><div class="hidden" id="back-to-top"><svg viewbox="0 0 24 24"><path d="M7.41 15.41L12 10.83l4.59 4.58L18 14l-6-6-6 6z"></path></svg></div> <div class="hiddendiv common"></div></body>
</html>