<!DOCTYPE html>

<html class="" data-theme="light" data-theme-setting="system" lang="zh-CN">
<head><link href="https://giscus.app/default.css" id="giscus-css" rel="stylesheet"/><style>#back-to-top{background:#000;-webkit-border-radius:50%;-moz-border-radius:50%;border-radius:50%;bottom:20px;-webkit-box-shadow:0 2px 5px 0 rgba(0,0,0,.26);-moz-box-shadow:0 2px 5px 0 rgba(0,0,0,.26);box-shadow:0 2px 5px 0 rgba(0,0,0,.26);color:#fff;cursor:pointer;display:block;height:56px;opacity:1;outline:0;position:fixed;right:20px;-webkit-tap-highlight-color:transparent;-webkit-touch-callout:none;-webkit-transition:bottom .2s,opacity .2s;-o-transition:bottom .2s,opacity .2s;-moz-transition:bottom .2s,opacity .2s;transition:bottom .2s,opacity .2s;-webkit-user-select:none;-moz-user-select:none;-ms-user-select:none;user-select:none;width:56px;z-index:1}#back-to-top svg{display:block;fill:currentColor;height:20px;margin:11px auto 0;width:20px}#back-to-top.hidden{bottom:-56px;opacity:0}</style> <meta content="text/html; charset=utf-8" http-equiv="Content-Type"/> <meta charset="utf-8"/> <meta content="width=device-width, initial-scale=1, shrink-to-fit=no" name="viewport"/> <meta content="IE=edge" http-equiv="X-UA-Compatible"/> <title>Transformer 推理全解析 | 如何扩展您的模型</title> <meta content=" " name="author"/> <meta content="对 Transformer 执行推理与训练可能大相径庭。部分原因在于，推理增加了一个需要考虑的新因素：延迟。在本节中，我们将全面介绍从模型中采样单个新词元，到作为推理引擎的一部分在多个加速器切片上高效扩展大型 Transformer 的整个过程。" name="description"/> <meta content="scaling, jax, llms, transformers, tpus, google, deepmind, parallelism, pallas" name="keywords"/> <link href="https://jax-ml.github.io/scaling-book/assets/css/bootstrap.min.css?a4b3f509e79c54a512b890d73235ef04" rel="stylesheet"/> <link crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" rel="stylesheet"/> <link defer="" href="https://jax-ml.github.io/scaling-book/assets/css/academicons.min.css?f0b7046b84e425c55f3463ac249818f5" rel="stylesheet"/> <link defer="" href="https://jax-ml.github.io/scaling-book/assets/css/scholar-icons.css?62b2ac103a88034e6882a5be5f3e2772" rel="stylesheet"/> <link defer="" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons&amp;display=swap" rel="stylesheet" type="text/css"/> <link defer="" href="https://jax-ml.github.io/scaling-book/assets/css/jekyll-pygments-themes-vs.css?4ee1a2facd1a8a76347f4bd43a740500" id="highlight_theme_light" media="" rel="stylesheet"/> <link href="https://jax-ml.github.io/scaling-book/assets/img/favicon.png?fddbd8c2ec231ba2060e67c85de32a55" rel="shortcut icon"/> <link href="https://jax-ml.github.io/scaling-book/assets/css/main.css?d41d8cd98f00b204e9800998ecf8427e" rel="stylesheet"/> <link href="inference.html" rel="canonical"/> <style id="distill-prerendered-styles" type="text/css">/*
 * Copyright 2018 The Distill Template Authors
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 *      http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

html {
  font-size: 14px;
	line-height: 1.6em;
  /* font-family: "Libre Franklin", "Helvetica Neue", sans-serif; */
  font-family: -apple-system, BlinkMacSystemFont, "Segoe UI", Roboto, Oxygen, Ubuntu, Cantarell, "Fira Sans", "Droid Sans", "Helvetica Neue", Arial, sans-serif;
  /*, "Apple Color Emoji", "Segoe UI Emoji", "Segoe UI Symbol";*/
  text-size-adjust: 100%;
  -ms-text-size-adjust: 100%;
  -webkit-text-size-adjust: 100%;
}

@media(min-width: 768px) {
  html {
    font-size: 16px;
  }
}

body {
  margin: 0;
}

a {
  color: #004276;
}

figure {
  margin: 0;
}

table {
	border-collapse: collapse;
	border-spacing: 0;
}

table th {
	text-align: left;
}

table thead {
  border-bottom: 1px solid rgba(0, 0, 0, 0.05);
}

table thead th {
  padding-bottom: 0.5em;
}

table tbody :first-child td {
  padding-top: 0.5em;
}

pre {
  overflow: auto;
  max-width: 100%;
}

p {
  margin-top: 0;
  margin-bottom: 1em;
}

sup, sub {
  vertical-align: baseline;
  position: relative;
  top: -0.4em;
  line-height: 1em;
}

sub {
  top: 0.4em;
}

.kicker,
.marker {
  font-size: 15px;
  font-weight: 600;
  color: rgba(0, 0, 0, 0.5);
}


/* Headline */

@media(min-width: 1024px) {
  d-title h1 span {
    display: block;
  }
}

/* Figure */

figure {
  position: relative;
  margin-bottom: 2.5em;
  margin-top: 1.5em;
}

figcaption+figure {

}

figure img {
  width: 100%;
}

figure svg text,
figure svg tspan {
}

figcaption,
.figcaption {
  color: rgba(0, 0, 0, 0.6);
  font-size: 12px;
  line-height: 1.5em;
}

@media(min-width: 1024px) {
figcaption,
.figcaption {
    font-size: 13px;
  }
}

figure.external img {
  background: white;
  border: 1px solid rgba(0, 0, 0, 0.1);
  box-shadow: 0 1px 8px rgba(0, 0, 0, 0.1);
  padding: 18px;
  box-sizing: border-box;
}

figcaption a {
  color: rgba(0, 0, 0, 0.6);
}

figcaption b,
figcaption strong, {
  font-weight: 600;
  color: rgba(0, 0, 0, 1.0);
}
/*
 * Copyright 2018 The Distill Template Authors
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 *      http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

@supports not (display: grid) {
  .base-grid,
  distill-header,
  d-title,
  d-abstract,
  d-article,
  d-appendix,
  distill-appendix,
  d-byline,
  d-footnote-list,
  d-citation-list,
  distill-footer {
    display: block;
    padding: 8px;
  }
}

.base-grid,
distill-header,
d-title,
d-abstract,
d-article,
d-appendix,
distill-appendix,
d-byline,
d-footnote-list,
d-citation-list,
distill-footer {
  display: grid;
  justify-items: stretch;
  grid-template-columns: [screen-start] 8px [page-start kicker-start text-start gutter-start middle-start] 1fr 1fr 1fr 1fr 1fr 1fr 1fr 1fr [text-end page-end gutter-end kicker-end middle-end] 8px [screen-end];
  grid-column-gap: 8px;
}

.grid {
  display: grid;
  grid-column-gap: 8px;
}

@media(min-width: 768px) {
  .base-grid,
  distill-header,
  d-title,
  d-abstract,
  d-article,
  d-appendix,
  distill-appendix,
  d-byline,
  d-footnote-list,
  d-citation-list,
  distill-footer {
    grid-template-columns: [screen-start] 1fr [page-start kicker-start middle-start text-start] 45px 45px 45px 45px 45px 45px 45px 45px [ kicker-end text-end gutter-start] 45px [middle-end] 45px [page-end gutter-end] 1fr [screen-end];
    grid-column-gap: 16px;
  }

  .grid {
    grid-column-gap: 16px;
  }
}

@media(min-width: 1000px) {
  .base-grid,
  distill-header,
  d-title,
  d-abstract,
  d-article,
  d-appendix,
  distill-appendix,
  d-byline,
  d-footnote-list,
  d-citation-list,
  distill-footer {
    grid-template-columns: [screen-start] 1fr [page-start kicker-start] 50px [middle-start] 50px [text-start kicker-end] 50px 50px 50px 50px 50px 50px 50px 50px [text-end gutter-start] 50px [middle-end] 50px [page-end gutter-end] 1fr [screen-end];
    grid-column-gap: 16px;
  }

  .grid {
    grid-column-gap: 16px;
  }
}

@media(min-width: 1180px) {
  .base-grid,
  distill-header,
  d-title,
  d-abstract,
  d-article,
  d-appendix,
  distill-appendix,
  d-byline,
  d-footnote-list,
  d-citation-list,
  distill-footer {
    grid-template-columns: [screen-start] 1fr [page-start kicker-start] 60px [middle-start] 60px [text-start kicker-end] 60px 60px 60px 60px 60px 60px 60px 60px [text-end gutter-start] 60px [middle-end] 60px [page-end gutter-end] 1fr [screen-end];
    grid-column-gap: 32px;
  }

  .grid {
    grid-column-gap: 32px;
  }
}




.base-grid {
  grid-column: screen;
}

/* .l-body,
d-article > *  {
  grid-column: text;
}

.l-page,
d-title > *,
d-figure {
  grid-column: page;
} */

.l-gutter {
  grid-column: gutter;
}

.l-text,
.l-body {
  grid-column: text;
}

.l-page {
  grid-column: page;
}

.l-body-outset {
  grid-column: middle;
}

.l-page-outset {
  grid-column: page;
}

.l-screen {
  grid-column: screen;
}

.l-screen-inset {
  grid-column: screen;
  padding-left: 16px;
  padding-left: 16px;
}


/* Aside */

d-article aside {
  grid-column: gutter;
  font-size: 12px;
  line-height: 1.6em;
  color: rgba(0, 0, 0, 0.6)
}

@media(min-width: 768px) {
  aside {
    grid-column: gutter;
  }

  .side {
    grid-column: gutter;
  }
}
/*
 * Copyright 2018 The Distill Template Authors
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 *      http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

d-title {
  padding: 2rem 0 1.5rem;
  contain: layout style;
  overflow-x: hidden;
}

@media(min-width: 768px) {
  d-title {
    padding: 4rem 0 1.5rem;
  }
}

d-title h1 {
  grid-column: text;
  font-size: 40px;
  font-weight: 700;
  line-height: 1.1em;
  margin: 0 0 0.5rem;
}

@media(min-width: 768px) {
  d-title h1 {
    font-size: 50px;
  }
}

d-title p {
  font-weight: 300;
  font-size: 1.2rem;
  line-height: 1.55em;
  grid-column: text;
}

d-title .status {
  margin-top: 0px;
  font-size: 12px;
  color: #009688;
  opacity: 0.8;
  grid-column: kicker;
}

d-title .status span {
  line-height: 1;
  display: inline-block;
  padding: 6px 0;
  border-bottom: 1px solid #80cbc4;
  font-size: 11px;
  text-transform: uppercase;
}
/*
 * Copyright 2018 The Distill Template Authors
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 *      http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

d-byline {
  contain: style;
  overflow: hidden;
  border-top: 1px solid rgba(0, 0, 0, 0.1);
  font-size: 0.8rem;
  line-height: 1.8em;
  padding: 1.5rem 0;
  min-height: 1.8em;
}


d-byline .byline {
  grid-template-columns: 1fr 1fr;
  grid-column: text;
}

@media(min-width: 768px) {
  d-byline .byline {
    grid-template-columns: 1fr 1fr 1fr 1fr;
  }
}

d-byline .authors-affiliations {
  grid-column-end: span 3;
  grid-template-columns: 1fr 1fr 1fr;
  margin-bottom: 1em;
}

@media(min-width: 768px) {
  d-byline .authors-affiliations {
    margin-bottom: 0;
  }
}

d-byline h3 {
  font-size: 0.6rem;
  font-weight: 400;
  color: rgba(0, 0, 0, 0.5);
  margin: 0;
  text-transform: uppercase;
}

d-byline p {
  margin: 0;
}

d-byline a,
d-article d-byline a {
  color: rgba(0, 0, 0, 0.8);
  text-decoration: none;
  border-bottom: none;
}

d-article d-byline a:hover {
  text-decoration: underline;
  border-bottom: none;
}

d-byline p.author {
  font-weight: 500;
}

d-byline .affiliations {

}
/*
 * Copyright 2018 The Distill Template Authors
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 *      http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

d-article {
  contain: layout style;
 border-top: 1px solid rgba(0, 0, 0, 0.1);
  padding-top: 2rem;
  color: rgba(0, 0, 0, 0.8);
}

d-article > * {
  grid-column: text;
}

@media(min-width: 768px) {
  d-article {
    font-size: 16px;
  }
}

@media(min-width: 1024px) {
  d-article {
    font-size: 1.06rem;
    line-height: 1.7em;
  }
}


/* H2 */


d-article .marker {
  text-decoration: none;
  border: none;
  counter-reset: section;
  grid-column: kicker;
  line-height: 1.7em;
}

d-article .marker:hover {
  border: none;
}

d-article .marker span {
  padding: 0 3px 4px;
  border-bottom: 1px solid rgba(0, 0, 0, 0.2);
  position: relative;
  top: 4px;
}

d-article .marker:hover span {
  color: rgba(0, 0, 0, 0.7);
  border-bottom: 1px solid rgba(0, 0, 0, 0.7);
}

d-article h2 {
  font-weight: 600;
  font-size: 24px;
  line-height: 1.25em;
  margin: 2rem 0 1.5rem 0;
  border-bottom: 1px solid rgba(0, 0, 0, 0.1);
  padding-bottom: 1rem;
}

@media(min-width: 1024px) {
  d-article h2 {
    font-size: 36px;
  }
}

/* H3 */

d-article h3 {
  font-weight: 700;
  font-size: 18px;
  line-height: 1.4em;
  margin-bottom: 1em;
  margin-top: 2em;
}

@media(min-width: 1024px) {
  d-article h3 {
    font-size: 20px;
  }
}

/* H4 */

d-article h4 {
  font-weight: 600;
  text-transform: uppercase;
  font-size: 14px;
  line-height: 1.4em;
}

d-article a {
  color: inherit;
}

d-article p,
d-article ul,
d-article ol,
d-article blockquote {
  margin-top: 0;
  margin-bottom: 1em;
  margin-left: 0;
  margin-right: 0;
}

d-article blockquote {
  border-left: 2px solid rgba(0, 0, 0, 0.2);
  padding-left: 2em;
  font-style: italic;
  color: rgba(0, 0, 0, 0.6);
}

d-article a {
  border-bottom: 1px solid var(--global-underline-color);
  text-decoration: none;
}

d-article a:hover {
  border-bottom: 1px solid rgba(0, 0, 0, 0.8);
}

d-article .link {
  text-decoration: underline;
  cursor: pointer;
}

d-article ul,
d-article ol {
  padding-left: 24px;
}

d-article li {
  margin-bottom: 1em;
  margin-left: 0;
  padding-left: 0;
}

d-article li:last-child {
  margin-bottom: 0;
}

d-article pre {
  font-size: 14px;
  margin-bottom: 20px;
}

d-article hr {
  grid-column: screen;
  width: 100%;
  border: none;
  border-bottom: 1px solid rgba(0, 0, 0, 0.1);
  margin-top: 60px;
  margin-bottom: 60px;
}

d-article section {
  margin-top: 60px;
  margin-bottom: 60px;
}

d-article span.equation-mimic {
  font-family: georgia;
  font-size: 115%;
  font-style: italic;
}

d-article > d-code,
d-article section > d-code  {
  display: block;
}

d-article > d-math[block],
d-article section > d-math[block]  {
  display: block;
}

@media (max-width: 768px) {
  d-article > d-code,
  d-article section > d-code,
  d-article > d-math[block],
  d-article section > d-math[block] {
      overflow-x: scroll;
      -ms-overflow-style: none;  // IE 10+
      overflow: -moz-scrollbars-none;  // Firefox
  }

  d-article > d-code::-webkit-scrollbar,
  d-article section > d-code::-webkit-scrollbar,
  d-article > d-math[block]::-webkit-scrollbar,
  d-article section > d-math[block]::-webkit-scrollbar {
    display: none;  // Safari and Chrome
  }
}

d-article .citation {
  color: #668;
  cursor: pointer;
}

d-include {
  width: auto;
  display: block;
}

d-figure {
  contain: layout style;
}

/* KaTeX */

.katex, .katex-prerendered {
  contain: style;
  display: inline-block;
}

/* Tables */

d-article table {
  border-collapse: collapse;
  margin-bottom: 1.5rem;
  border-bottom: 1px solid rgba(0, 0, 0, 0.2);
}

d-article table th {
  border-bottom: 1px solid rgba(0, 0, 0, 0.2);
}

d-article table td {
  border-bottom: 1px solid rgba(0, 0, 0, 0.05);
}

d-article table tr:last-of-type td {
  border-bottom: none;
}

d-article table th,
d-article table td {
  font-size: 15px;
  padding: 2px 8px;
}

d-article table tbody :first-child td {
  padding-top: 2px;
}
/*
 * Copyright 2018 The Distill Template Authors
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 *      http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

span.katex-display {
  text-align: left;
  padding: 8px 0 8px 0;
  margin: 0.5em 0 0.5em 1em;
}

span.katex {
  -webkit-font-smoothing: antialiased;
;
  font-size: 1.18em;
}

/*
 * Copyright 2018 The Distill Template Authors
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 *      http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

@media print {

  @page {
    size: 8in 11in;
    @bottom-right {
      content: counter(page) " of " counter(pages);
    }
  }

  html {
    /* no general margins -- CSS Grid takes care of those */
  }

  p, code {
    page-break-inside: avoid;
  }

  h2, h3 {
    page-break-after: avoid;
  }

  d-header {
    visibility: hidden;
  }

  d-footer {
    display: none!important;
  }

}
</style><script src="https://jax-ml.github.io/scaling-book/assets/js/theme.js?9a0c749ec5240d9cda97bc72359a72c0"></script> <link defer="" href="https://jax-ml.github.io/scaling-book/assets/css/jekyll-pygments-themes-native.css?5847e5ed4a4568527aa6cfab446049ca" id="highlight_theme_dark" media="none" rel="stylesheet"/> <script>
    initTheme();
  </script> <script src="https://jax-ml.github.io/scaling-book/assets/js/distillpub/template.v2.js"></script> <script src="https://jax-ml.github.io/scaling-book/assets/js/distillpub/transforms.v2.js"></script> <style type="text/css">{{page._styles}}</style> <style type="text/css">/* Chart.js */
@-webkit-keyframes chartjs-render-animation{from{opacity:0.99}to{opacity:1}}@keyframes chartjs-render-animation{from{opacity:0.99}to{opacity:1}}.chartjs-render-monitor{-webkit-animation:chartjs-render-animation 0.001s;animation:chartjs-render-animation 0.001s;}</style><style type="text/css">.medium-zoom-overlay{position:fixed;top:0;right:0;bottom:0;left:0;opacity:0;transition:opacity .3s;will-change:opacity}.medium-zoom--opened .medium-zoom-overlay{cursor:pointer;cursor:zoom-out;opacity:1}.medium-zoom-image{cursor:pointer;cursor:zoom-in;transition:transform .3s cubic-bezier(.2,0,.2,1)!important}.medium-zoom-image--hidden{visibility:hidden}.medium-zoom-image--opened{position:relative;cursor:pointer;cursor:zoom-out;will-change:transform}</style><style type="text/css">.CtxtMenu_InfoClose {  top:.2em; right:.2em;}
.CtxtMenu_InfoContent {  overflow:auto; text-align:left; font-size:80%;  padding:.4em .6em; border:1px inset; margin:1em 0px;  max-height:20em; max-width:30em; background-color:#EEEEEE;  white-space:normal;}
.CtxtMenu_Info.CtxtMenu_MousePost {outline:none;}
.CtxtMenu_Info {  position:fixed; left:50%; width:auto; text-align:center;  border:3px outset; padding:1em 2em; background-color:#DDDDDD;  color:black;  cursor:default; font-family:message-box; font-size:120%;  font-style:normal; text-indent:0; text-transform:none;  line-height:normal; letter-spacing:normal; word-spacing:normal;  word-wrap:normal; white-space:nowrap; float:none; z-index:201;  border-radius: 15px;                     /* Opera 10.5 and IE9 */  -webkit-border-radius:15px;               /* Safari and Chrome */  -moz-border-radius:15px;                  /* Firefox */  -khtml-border-radius:15px;                /* Konqueror */  box-shadow:0px 10px 20px #808080;         /* Opera 10.5 and IE9 */  -webkit-box-shadow:0px 10px 20px #808080; /* Safari 3 & Chrome */  -moz-box-shadow:0px 10px 20px #808080;    /* Forefox 3.5 */  -khtml-box-shadow:0px 10px 20px #808080;  /* Konqueror */  filter:progid:DXImageTransform.Microsoft.dropshadow(OffX=2, OffY=2, Color="gray", Positive="true"); /* IE */}
</style><style type="text/css">.CtxtMenu_MenuClose {  position:absolute;  cursor:pointer;  display:inline-block;  border:2px solid #AAA;  border-radius:18px;  -webkit-border-radius: 18px;             /* Safari and Chrome */  -moz-border-radius: 18px;                /* Firefox */  -khtml-border-radius: 18px;              /* Konqueror */  font-family: "Courier New", Courier;  font-size:24px;  color:#F0F0F0}
.CtxtMenu_MenuClose span {  display:block; background-color:#AAA; border:1.5px solid;  border-radius:18px;  -webkit-border-radius: 18px;             /* Safari and Chrome */  -moz-border-radius: 18px;                /* Firefox */  -khtml-border-radius: 18px;              /* Konqueror */  line-height:0;  padding:8px 0 6px     /* may need to be browser-specific */}
.CtxtMenu_MenuClose:hover {  color:white!important;  border:2px solid #CCC!important}
.CtxtMenu_MenuClose:hover span {  background-color:#CCC!important}
.CtxtMenu_MenuClose:hover:focus {  outline:none}
</style><style type="text/css">.CtxtMenu_Menu {  position:absolute;  background-color:white;  color:black;  width:auto; padding:5px 0px;  border:1px solid #CCCCCC; margin:0; cursor:default;  font: menu; text-align:left; text-indent:0; text-transform:none;  line-height:normal; letter-spacing:normal; word-spacing:normal;  word-wrap:normal; white-space:nowrap; float:none; z-index:201;  border-radius: 5px;                     /* Opera 10.5 and IE9 */  -webkit-border-radius: 5px;             /* Safari and Chrome */  -moz-border-radius: 5px;                /* Firefox */  -khtml-border-radius: 5px;              /* Konqueror */  box-shadow:0px 10px 20px #808080;         /* Opera 10.5 and IE9 */  -webkit-box-shadow:0px 10px 20px #808080; /* Safari 3 & Chrome */  -moz-box-shadow:0px 10px 20px #808080;    /* Forefox 3.5 */  -khtml-box-shadow:0px 10px 20px #808080;  /* Konqueror */}
.CtxtMenu_MenuItem {  padding: 1px 2em;  background:transparent;}
.CtxtMenu_MenuArrow {  position:absolute; right:.5em; padding-top:.25em; color:#666666;  font-family: null; font-size: .75em}
.CtxtMenu_MenuActive .CtxtMenu_MenuArrow {color:white}
.CtxtMenu_MenuArrow.CtxtMenu_RTL {left:.5em; right:auto}
.CtxtMenu_MenuCheck {  position:absolute; left:.7em;  font-family: null}
.CtxtMenu_MenuCheck.CtxtMenu_RTL { right:.7em; left:auto }
.CtxtMenu_MenuRadioCheck {  position:absolute; left: .7em;}
.CtxtMenu_MenuRadioCheck.CtxtMenu_RTL {  right: .7em; left:auto}
.CtxtMenu_MenuInputBox {  padding-left: 1em; right:.5em; color:#666666;  font-family: null;}
.CtxtMenu_MenuInputBox.CtxtMenu_RTL {  left: .1em;}
.CtxtMenu_MenuComboBox {  left:.1em; padding-bottom:.5em;}
.CtxtMenu_MenuSlider {  left: .1em;}
.CtxtMenu_SliderValue {  position:absolute; right:.1em; padding-top:.25em; color:#333333;  font-size: .75em}
.CtxtMenu_SliderBar {  outline: none; background: #d3d3d3}
.CtxtMenu_MenuLabel {  padding: 1px 2em 3px 1.33em;  font-style:italic}
.CtxtMenu_MenuRule {  border-top: 1px solid #DDDDDD;  margin: 4px 3px;}
.CtxtMenu_MenuDisabled {  color:GrayText}
.CtxtMenu_MenuActive {  background-color: #606872;  color: white;}
.CtxtMenu_MenuDisabled:focus {  background-color: #E8E8E8}
.CtxtMenu_MenuLabel:focus {  background-color: #E8E8E8}
.CtxtMenu_ContextMenu:focus {  outline:none}
.CtxtMenu_ContextMenu .CtxtMenu_MenuItem:focus {  outline:none}
.CtxtMenu_SelectionMenu {  position:relative; float:left;  border-bottom: none; -webkit-box-shadow:none; -webkit-border-radius:0px; }
.CtxtMenu_SelectionItem {  padding-right: 1em;}
.CtxtMenu_Selection {  right: 40%; width:50%; }
.CtxtMenu_SelectionBox {  padding: 0em; max-height:20em; max-width: none;  background-color:#FFFFFF;}
.CtxtMenu_SelectionDivider {  clear: both; border-top: 2px solid #000000;}
.CtxtMenu_Menu .CtxtMenu_MenuClose {  top:-10px; left:-10px}
</style><style id="MJX-CHTML-styles">
mjx-container[jax="CHTML"] {
  line-height: 0;
}

mjx-container [space="1"] {
  margin-left: .111em;
}

mjx-container [space="2"] {
  margin-left: .167em;
}

mjx-container [space="3"] {
  margin-left: .222em;
}

mjx-container [space="4"] {
  margin-left: .278em;
}

mjx-container [space="5"] {
  margin-left: .333em;
}

mjx-container [rspace="1"] {
  margin-right: .111em;
}

mjx-container [rspace="2"] {
  margin-right: .167em;
}

mjx-container [rspace="3"] {
  margin-right: .222em;
}

mjx-container [rspace="4"] {
  margin-right: .278em;
}

mjx-container [rspace="5"] {
  margin-right: .333em;
}

mjx-container [size="s"] {
  font-size: 70.7%;
}

mjx-container [size="ss"] {
  font-size: 50%;
}

mjx-container [size="Tn"] {
  font-size: 60%;
}

mjx-container [size="sm"] {
  font-size: 85%;
}

mjx-container [size="lg"] {
  font-size: 120%;
}

mjx-container [size="Lg"] {
  font-size: 144%;
}

mjx-container [size="LG"] {
  font-size: 173%;
}

mjx-container [size="hg"] {
  font-size: 207%;
}

mjx-container [size="HG"] {
  font-size: 249%;
}

mjx-container [width="full"] {
  width: 100%;
}

mjx-box {
  display: inline-block;
}

mjx-block {
  display: block;
}

mjx-itable {
  display: inline-table;
}

mjx-row {
  display: table-row;
}

mjx-row > * {
  display: table-cell;
}

mjx-mtext {
  display: inline-block;
  text-align: left;
}

mjx-mstyle {
  display: inline-block;
}

mjx-merror {
  display: inline-block;
  color: red;
  background-color: yellow;
}

mjx-mphantom {
  visibility: hidden;
}

_::-webkit-full-page-media, _:future, :root mjx-container {
  will-change: opacity;
}

mjx-assistive-mml {
  position: absolute !important;
  top: 0px;
  left: 0px;
  clip: rect(1px, 1px, 1px, 1px);
  padding: 1px 0px 0px 0px !important;
  border: 0px !important;
  display: block !important;
  width: auto !important;
  overflow: hidden !important;
  -webkit-touch-callout: none;
  -webkit-user-select: none;
  -khtml-user-select: none;
  -moz-user-select: none;
  -ms-user-select: none;
  user-select: none;
}

mjx-assistive-mml[display="block"] {
  width: 100% !important;
}

mjx-math {
  display: inline-block;
  text-align: left;
  line-height: 0;
  text-indent: 0;
  font-style: normal;
  font-weight: normal;
  font-size: 100%;
  font-size-adjust: none;
  letter-spacing: normal;
  border-collapse: collapse;
  word-wrap: normal;
  word-spacing: normal;
  white-space: nowrap;
  direction: ltr;
  padding: 1px 0;
}

mjx-container[jax="CHTML"][display="true"] {
  display: block;
  text-align: center;
  margin: 1em 0;
}

mjx-container[jax="CHTML"][display="true"][width="full"] {
  display: flex;
}

mjx-container[jax="CHTML"][display="true"] mjx-math {
  padding: 0;
}

mjx-container[jax="CHTML"][justify="left"] {
  text-align: left;
}

mjx-container[jax="CHTML"][justify="right"] {
  text-align: right;
}

mjx-mi {
  display: inline-block;
  text-align: left;
}

mjx-c {
  display: inline-block;
}

mjx-utext {
  display: inline-block;
  padding: .75em 0 .2em 0;
}

mjx-mo {
  display: inline-block;
  text-align: left;
}

mjx-stretchy-h {
  display: inline-table;
  width: 100%;
}

mjx-stretchy-h > * {
  display: table-cell;
  width: 0;
}

mjx-stretchy-h > * > mjx-c {
  display: inline-block;
  transform: scalex(1.0000001);
}

mjx-stretchy-h > * > mjx-c::before {
  display: inline-block;
  width: initial;
}

mjx-stretchy-h > mjx-ext {
  /* IE */ overflow: hidden;
  /* others */ overflow: clip visible;
  width: 100%;
}

mjx-stretchy-h > mjx-ext > mjx-c::before {
  transform: scalex(500);
}

mjx-stretchy-h > mjx-ext > mjx-c {
  width: 0;
}

mjx-stretchy-h > mjx-beg > mjx-c {
  margin-right: -.1em;
}

mjx-stretchy-h > mjx-end > mjx-c {
  margin-left: -.1em;
}

mjx-stretchy-v {
  display: inline-block;
}

mjx-stretchy-v > * {
  display: block;
}

mjx-stretchy-v > mjx-beg {
  height: 0;
}

mjx-stretchy-v > mjx-end > mjx-c {
  display: block;
}

mjx-stretchy-v > * > mjx-c {
  transform: scaley(1.0000001);
  transform-origin: left center;
  overflow: hidden;
}

mjx-stretchy-v > mjx-ext {
  display: block;
  height: 100%;
  box-sizing: border-box;
  border: 0px solid transparent;
  /* IE */ overflow: hidden;
  /* others */ overflow: visible clip;
}

mjx-stretchy-v > mjx-ext > mjx-c::before {
  width: initial;
  box-sizing: border-box;
}

mjx-stretchy-v > mjx-ext > mjx-c {
  transform: scaleY(500) translateY(.075em);
  overflow: visible;
}

mjx-mark {
  display: inline-block;
  height: 0px;
}

mjx-msub {
  display: inline-block;
  text-align: left;
}

mjx-msup {
  display: inline-block;
  text-align: left;
}

mjx-mn {
  display: inline-block;
  text-align: left;
}

mjx-mfrac {
  display: inline-block;
  text-align: left;
}

mjx-frac {
  display: inline-block;
  vertical-align: 0.17em;
  padding: 0 .22em;
}

mjx-frac[type="d"] {
  vertical-align: .04em;
}

mjx-frac[delims] {
  padding: 0 .1em;
}

mjx-frac[atop] {
  padding: 0 .12em;
}

mjx-frac[atop][delims] {
  padding: 0;
}

mjx-dtable {
  display: inline-table;
  width: 100%;
}

mjx-dtable > * {
  font-size: 2000%;
}

mjx-dbox {
  display: block;
  font-size: 5%;
}

mjx-num {
  display: block;
  text-align: center;
}

mjx-den {
  display: block;
  text-align: center;
}

mjx-mfrac[bevelled] > mjx-num {
  display: inline-block;
}

mjx-mfrac[bevelled] > mjx-den {
  display: inline-block;
}

mjx-den[align="right"], mjx-num[align="right"] {
  text-align: right;
}

mjx-den[align="left"], mjx-num[align="left"] {
  text-align: left;
}

mjx-nstrut {
  display: inline-block;
  height: .054em;
  width: 0;
  vertical-align: -.054em;
}

mjx-nstrut[type="d"] {
  height: .217em;
  vertical-align: -.217em;
}

mjx-dstrut {
  display: inline-block;
  height: .505em;
  width: 0;
}

mjx-dstrut[type="d"] {
  height: .726em;
}

mjx-line {
  display: block;
  box-sizing: border-box;
  min-height: 1px;
  height: .06em;
  border-top: .06em solid;
  margin: .06em -.1em;
  overflow: hidden;
}

mjx-line[type="d"] {
  margin: .18em -.1em;
}

mjx-mrow {
  display: inline-block;
  text-align: left;
}

mjx-munder {
  display: inline-block;
  text-align: left;
}

mjx-over {
  text-align: left;
}

mjx-munder:not([limits="false"]) {
  display: inline-table;
}

mjx-munder > mjx-row {
  text-align: left;
}

mjx-under {
  padding-bottom: .1em;
}

mjx-mtable {
  display: inline-block;
  text-align: center;
  vertical-align: .25em;
  position: relative;
  box-sizing: border-box;
  border-spacing: 0;
  border-collapse: collapse;
}

mjx-mstyle[size="s"] mjx-mtable {
  vertical-align: .354em;
}

mjx-labels {
  position: absolute;
  left: 0;
  top: 0;
}

mjx-table {
  display: inline-block;
  vertical-align: -.5ex;
  box-sizing: border-box;
}

mjx-table > mjx-itable {
  vertical-align: middle;
  text-align: left;
  box-sizing: border-box;
}

mjx-labels > mjx-itable {
  position: absolute;
  top: 0;
}

mjx-mtable[justify="left"] {
  text-align: left;
}

mjx-mtable[justify="right"] {
  text-align: right;
}

mjx-mtable[justify="left"][side="left"] {
  padding-right: 0 ! important;
}

mjx-mtable[justify="left"][side="right"] {
  padding-left: 0 ! important;
}

mjx-mtable[justify="right"][side="left"] {
  padding-right: 0 ! important;
}

mjx-mtable[justify="right"][side="right"] {
  padding-left: 0 ! important;
}

mjx-mtable[align] {
  vertical-align: baseline;
}

mjx-mtable[align="top"] > mjx-table {
  vertical-align: top;
}

mjx-mtable[align="bottom"] > mjx-table {
  vertical-align: bottom;
}

mjx-mtable[side="right"] mjx-labels {
  min-width: 100%;
}

mjx-mtr {
  display: table-row;
  text-align: left;
}

mjx-mtr[rowalign="top"] > mjx-mtd {
  vertical-align: top;
}

mjx-mtr[rowalign="center"] > mjx-mtd {
  vertical-align: middle;
}

mjx-mtr[rowalign="bottom"] > mjx-mtd {
  vertical-align: bottom;
}

mjx-mtr[rowalign="baseline"] > mjx-mtd {
  vertical-align: baseline;
}

mjx-mtr[rowalign="axis"] > mjx-mtd {
  vertical-align: .25em;
}

mjx-mtd {
  display: table-cell;
  text-align: center;
  padding: .215em .4em;
}

mjx-mtd:first-child {
  padding-left: 0;
}

mjx-mtd:last-child {
  padding-right: 0;
}

mjx-mtable > * > mjx-itable > *:first-child > mjx-mtd {
  padding-top: 0;
}

mjx-mtable > * > mjx-itable > *:last-child > mjx-mtd {
  padding-bottom: 0;
}

mjx-tstrut {
  display: inline-block;
  height: 1em;
  vertical-align: -.25em;
}

mjx-labels[align="left"] > mjx-mtr > mjx-mtd {
  text-align: left;
}

mjx-labels[align="right"] > mjx-mtr > mjx-mtd {
  text-align: right;
}

mjx-mtd[extra] {
  padding: 0;
}

mjx-mtd[rowalign="top"] {
  vertical-align: top;
}

mjx-mtd[rowalign="center"] {
  vertical-align: middle;
}

mjx-mtd[rowalign="bottom"] {
  vertical-align: bottom;
}

mjx-mtd[rowalign="baseline"] {
  vertical-align: baseline;
}

mjx-mtd[rowalign="axis"] {
  vertical-align: .25em;
}

mjx-mspace {
  display: inline-block;
  text-align: left;
}

mjx-TeXAtom {
  display: inline-block;
  text-align: left;
}

mjx-mlabeledtr {
  display: table-row;
  text-align: left;
}

mjx-mlabeledtr[rowalign="top"] > mjx-mtd {
  vertical-align: top;
}

mjx-mlabeledtr[rowalign="center"] > mjx-mtd {
  vertical-align: middle;
}

mjx-mlabeledtr[rowalign="bottom"] > mjx-mtd {
  vertical-align: bottom;
}

mjx-mlabeledtr[rowalign="baseline"] > mjx-mtd {
  vertical-align: baseline;
}

mjx-mlabeledtr[rowalign="axis"] > mjx-mtd {
  vertical-align: .25em;
}

mjx-msqrt {
  display: inline-block;
  text-align: left;
}

mjx-root {
  display: inline-block;
  white-space: nowrap;
}

mjx-surd {
  display: inline-block;
  vertical-align: top;
}

mjx-sqrt {
  display: inline-block;
  padding-top: .07em;
}

mjx-sqrt > mjx-box {
  border-top: .07em solid;
}

mjx-sqrt.mjx-tall > mjx-box {
  padding-left: .3em;
  margin-left: -.3em;
}

mjx-c::before {
  display: block;
  width: 0;
}

.MJX-TEX {
  font-family: MJXZERO, MJXTEX;
}

.TEX-B {
  font-family: MJXZERO, MJXTEX-B;
}

.TEX-I {
  font-family: MJXZERO, MJXTEX-I;
}

.TEX-MI {
  font-family: MJXZERO, MJXTEX-MI;
}

.TEX-BI {
  font-family: MJXZERO, MJXTEX-BI;
}

.TEX-S1 {
  font-family: MJXZERO, MJXTEX-S1;
}

.TEX-S2 {
  font-family: MJXZERO, MJXTEX-S2;
}

.TEX-S3 {
  font-family: MJXZERO, MJXTEX-S3;
}

.TEX-S4 {
  font-family: MJXZERO, MJXTEX-S4;
}

.TEX-A {
  font-family: MJXZERO, MJXTEX-A;
}

.TEX-C {
  font-family: MJXZERO, MJXTEX-C;
}

.TEX-CB {
  font-family: MJXZERO, MJXTEX-CB;
}

.TEX-FR {
  font-family: MJXZERO, MJXTEX-FR;
}

.TEX-FRB {
  font-family: MJXZERO, MJXTEX-FRB;
}

.TEX-SS {
  font-family: MJXZERO, MJXTEX-SS;
}

.TEX-SSB {
  font-family: MJXZERO, MJXTEX-SSB;
}

.TEX-SSI {
  font-family: MJXZERO, MJXTEX-SSI;
}

.TEX-SC {
  font-family: MJXZERO, MJXTEX-SC;
}

.TEX-T {
  font-family: MJXZERO, MJXTEX-T;
}

.TEX-V {
  font-family: MJXZERO, MJXTEX-V;
}

.TEX-VB {
  font-family: MJXZERO, MJXTEX-VB;
}

mjx-stretchy-v mjx-c, mjx-stretchy-h mjx-c {
  font-family: MJXZERO, MJXTEX-S1, MJXTEX-S4, MJXTEX, MJXTEX-A ! important;
}

@font-face /* 0 */ {
  font-family: MJXZERO;
  src: url("https://cdn.jsdelivr.net/npm/mathjax@3.2.2/es5/output/chtml/fonts/woff-v2/MathJax_Zero.woff") format("woff");
}

@font-face /* 1 */ {
  font-family: MJXTEX;
  src: url("https://cdn.jsdelivr.net/npm/mathjax@3.2.2/es5/output/chtml/fonts/woff-v2/MathJax_Main-Regular.woff") format("woff");
}

@font-face /* 2 */ {
  font-family: MJXTEX-B;
  src: url("https://cdn.jsdelivr.net/npm/mathjax@3.2.2/es5/output/chtml/fonts/woff-v2/MathJax_Main-Bold.woff") format("woff");
}

@font-face /* 3 */ {
  font-family: MJXTEX-I;
  src: url("https://cdn.jsdelivr.net/npm/mathjax@3.2.2/es5/output/chtml/fonts/woff-v2/MathJax_Math-Italic.woff") format("woff");
}

@font-face /* 4 */ {
  font-family: MJXTEX-MI;
  src: url("https://cdn.jsdelivr.net/npm/mathjax@3.2.2/es5/output/chtml/fonts/woff-v2/MathJax_Main-Italic.woff") format("woff");
}

@font-face /* 5 */ {
  font-family: MJXTEX-BI;
  src: url("https://cdn.jsdelivr.net/npm/mathjax@3.2.2/es5/output/chtml/fonts/woff-v2/MathJax_Math-BoldItalic.woff") format("woff");
}

@font-face /* 6 */ {
  font-family: MJXTEX-S1;
  src: url("https://cdn.jsdelivr.net/npm/mathjax@3.2.2/es5/output/chtml/fonts/woff-v2/MathJax_Size1-Regular.woff") format("woff");
}

@font-face /* 7 */ {
  font-family: MJXTEX-S2;
  src: url("https://cdn.jsdelivr.net/npm/mathjax@3.2.2/es5/output/chtml/fonts/woff-v2/MathJax_Size2-Regular.woff") format("woff");
}

@font-face /* 8 */ {
  font-family: MJXTEX-S3;
  src: url("https://cdn.jsdelivr.net/npm/mathjax@3.2.2/es5/output/chtml/fonts/woff-v2/MathJax_Size3-Regular.woff") format("woff");
}

@font-face /* 9 */ {
  font-family: MJXTEX-S4;
  src: url("https://cdn.jsdelivr.net/npm/mathjax@3.2.2/es5/output/chtml/fonts/woff-v2/MathJax_Size4-Regular.woff") format("woff");
}

@font-face /* 10 */ {
  font-family: MJXTEX-A;
  src: url("https://cdn.jsdelivr.net/npm/mathjax@3.2.2/es5/output/chtml/fonts/woff-v2/MathJax_AMS-Regular.woff") format("woff");
}

@font-face /* 11 */ {
  font-family: MJXTEX-C;
  src: url("https://cdn.jsdelivr.net/npm/mathjax@3.2.2/es5/output/chtml/fonts/woff-v2/MathJax_Calligraphic-Regular.woff") format("woff");
}

@font-face /* 12 */ {
  font-family: MJXTEX-CB;
  src: url("https://cdn.jsdelivr.net/npm/mathjax@3.2.2/es5/output/chtml/fonts/woff-v2/MathJax_Calligraphic-Bold.woff") format("woff");
}

@font-face /* 13 */ {
  font-family: MJXTEX-FR;
  src: url("https://cdn.jsdelivr.net/npm/mathjax@3.2.2/es5/output/chtml/fonts/woff-v2/MathJax_Fraktur-Regular.woff") format("woff");
}

@font-face /* 14 */ {
  font-family: MJXTEX-FRB;
  src: url("https://cdn.jsdelivr.net/npm/mathjax@3.2.2/es5/output/chtml/fonts/woff-v2/MathJax_Fraktur-Bold.woff") format("woff");
}

@font-face /* 15 */ {
  font-family: MJXTEX-SS;
  src: url("https://cdn.jsdelivr.net/npm/mathjax@3.2.2/es5/output/chtml/fonts/woff-v2/MathJax_SansSerif-Regular.woff") format("woff");
}

@font-face /* 16 */ {
  font-family: MJXTEX-SSB;
  src: url("https://cdn.jsdelivr.net/npm/mathjax@3.2.2/es5/output/chtml/fonts/woff-v2/MathJax_SansSerif-Bold.woff") format("woff");
}

@font-face /* 17 */ {
  font-family: MJXTEX-SSI;
  src: url("https://cdn.jsdelivr.net/npm/mathjax@3.2.2/es5/output/chtml/fonts/woff-v2/MathJax_SansSerif-Italic.woff") format("woff");
}

@font-face /* 18 */ {
  font-family: MJXTEX-SC;
  src: url("https://cdn.jsdelivr.net/npm/mathjax@3.2.2/es5/output/chtml/fonts/woff-v2/MathJax_Script-Regular.woff") format("woff");
}

@font-face /* 19 */ {
  font-family: MJXTEX-T;
  src: url("https://cdn.jsdelivr.net/npm/mathjax@3.2.2/es5/output/chtml/fonts/woff-v2/MathJax_Typewriter-Regular.woff") format("woff");
}

@font-face /* 20 */ {
  font-family: MJXTEX-V;
  src: url("https://cdn.jsdelivr.net/npm/mathjax@3.2.2/es5/output/chtml/fonts/woff-v2/MathJax_Vector-Regular.woff") format("woff");
}

@font-face /* 21 */ {
  font-family: MJXTEX-VB;
  src: url("https://cdn.jsdelivr.net/npm/mathjax@3.2.2/es5/output/chtml/fonts/woff-v2/MathJax_Vector-Bold.woff") format("woff");
}

mjx-stretchy-h.mjx-c23DF mjx-beg mjx-c::before {
  content: "\E152";
  padding: 0.32em 0 0.2em 0;
}

mjx-stretchy-h.mjx-c23DF mjx-ext mjx-c::before {
  content: "\E154";
  padding: 0.32em 0 0.2em 0;
}

mjx-stretchy-h.mjx-c23DF mjx-end mjx-c::before {
  content: "\E153";
  padding: 0.32em 0 0.2em 0;
}

mjx-stretchy-h.mjx-c23DF mjx-mid mjx-c::before {
  content: "\E151\E150";
  padding: 0.32em 0 0.2em 0;
}

mjx-stretchy-h.mjx-c23DF > mjx-ext {
  width: 50%;
}

mjx-c.mjx-c6C::before {
  padding: 0.694em 0.278em 0 0;
  content: "l";
}

mjx-c.mjx-c6F::before {
  padding: 0.448em 0.5em 0.01em 0;
  content: "o";
}

mjx-c.mjx-c67::before {
  padding: 0.453em 0.5em 0.206em 0;
  content: "g";
}

mjx-c.mjx-c2061::before {
  padding: 0 0 0 0;
  content: "";
}

mjx-c.mjx-c1D45D.TEX-I::before {
  padding: 0.442em 0.503em 0.194em 0;
  content: "p";
}

mjx-c.mjx-c28::before {
  padding: 0.75em 0.389em 0.25em 0;
  content: "(";
}

mjx-c.mjx-c6E::before {
  padding: 0.442em 0.556em 0 0;
  content: "n";
}

mjx-c.mjx-c65::before {
  padding: 0.448em 0.444em 0.011em 0;
  content: "e";
}

mjx-c.mjx-c78::before {
  padding: 0.431em 0.528em 0 0;
  content: "x";
}

mjx-c.mjx-c74::before {
  padding: 0.615em 0.389em 0.01em 0;
  content: "t";
}

mjx-c.mjx-c20::before {
  padding: 0 0.25em 0 0;
  content: " ";
}

mjx-c.mjx-c6B::before {
  padding: 0.694em 0.528em 0 0;
  content: "k";
}

mjx-c.mjx-c1D456.TEX-I::before {
  padding: 0.661em 0.345em 0.011em 0;
  content: "i";
}

mjx-c.mjx-c7C::before {
  padding: 0.75em 0.278em 0.249em 0;
  content: "|";
}

mjx-c.mjx-c70::before {
  padding: 0.442em 0.556em 0.194em 0;
  content: "p";
}

mjx-c.mjx-c72::before {
  padding: 0.442em 0.392em 0 0;
  content: "r";
}

mjx-c.mjx-c76::before {
  padding: 0.431em 0.528em 0.011em 0;
  content: "v";
}

mjx-c.mjx-c69::before {
  padding: 0.669em 0.278em 0 0;
  content: "i";
}

mjx-c.mjx-c75::before {
  padding: 0.442em 0.556em 0.011em 0;
  content: "u";
}

mjx-c.mjx-c73::before {
  padding: 0.448em 0.394em 0.011em 0;
  content: "s";
}

mjx-c.mjx-c29::before {
  padding: 0.75em 0.389em 0.25em 0;
  content: ")";
}

mjx-c.mjx-c1D442.TEX-I::before {
  padding: 0.704em 0.763em 0.022em 0;
  content: "O";
}

mjx-c.mjx-c1D45B.TEX-I::before {
  padding: 0.442em 0.6em 0.011em 0;
  content: "n";
}

mjx-c.mjx-c32::before {
  padding: 0.666em 0.5em 0 0;
  content: "2";
}

mjx-c.mjx-c33::before {
  padding: 0.665em 0.5em 0.022em 0;
  content: "3";
}

mjx-c.mjx-c1D45E.TEX-I::before {
  padding: 0.442em 0.46em 0.194em 0;
  content: "q";
}

mjx-c.mjx-c22C5::before {
  padding: 0.31em 0.278em 0 0;
  content: "\22C5";
}

mjx-c.mjx-c1D458.TEX-I::before {
  padding: 0.694em 0.521em 0.011em 0;
  content: "k";
}

mjx-c.mjx-c1D457.TEX-I::before {
  padding: 0.661em 0.412em 0.204em 0;
  content: "j";
}

mjx-c.mjx-c1D447.TEX-I::before {
  padding: 0.677em 0.704em 0 0;
  content: "T";
}

mjx-c.mjx-c6D::before {
  padding: 0.442em 0.833em 0 0;
  content: "m";
}

mjx-c.mjx-c61::before {
  padding: 0.448em 0.5em 0.011em 0;
  content: "a";
}

mjx-c.mjx-c68::before {
  padding: 0.694em 0.556em 0 0;
  content: "h";
}

mjx-c.mjx-c3D::before {
  padding: 0.583em 0.778em 0.082em 0;
  content: "=";
}

mjx-c.mjx-c43::before {
  padding: 0.705em 0.722em 0.021em 0;
  content: "C";
}

mjx-c.mjx-c46::before {
  padding: 0.68em 0.653em 0 0;
  content: "F";
}

mjx-c.mjx-c4C::before {
  padding: 0.683em 0.625em 0 0;
  content: "L";
}

mjx-c.mjx-c4F::before {
  padding: 0.705em 0.778em 0.022em 0;
  content: "O";
}

mjx-c.mjx-c50::before {
  padding: 0.683em 0.681em 0 0;
  content: "P";
}

mjx-c.mjx-c41::before {
  padding: 0.716em 0.75em 0 0;
  content: "A";
}

mjx-c.mjx-c63::before {
  padding: 0.448em 0.444em 0.011em 0;
  content: "c";
}

mjx-c.mjx-c2F::before {
  padding: 0.75em 0.5em 0.25em 0;
  content: "/";
}

mjx-c.mjx-c1D435.TEX-I::before {
  padding: 0.683em 0.759em 0 0;
  content: "B";
}

mjx-c.mjx-c1D437.TEX-I::before {
  padding: 0.683em 0.828em 0 0;
  content: "D";
}

mjx-c.mjx-c1D439.TEX-I::before {
  padding: 0.68em 0.749em 0 0;
  content: "F";
}

mjx-c.mjx-c42::before {
  padding: 0.683em 0.708em 0 0;
  content: "B";
}

mjx-c.mjx-c79::before {
  padding: 0.431em 0.528em 0.204em 0;
  content: "y";
}

mjx-c.mjx-c64::before {
  padding: 0.694em 0.556em 0.011em 0;
  content: "d";
}

mjx-c.mjx-c77::before {
  padding: 0.431em 0.722em 0.011em 0;
  content: "w";
}

mjx-c.mjx-c2B::before {
  padding: 0.583em 0.778em 0.082em 0;
  content: "+";
}

mjx-c.mjx-c2265::before {
  padding: 0.636em 0.778em 0.138em 0;
  content: "\2265";
}

mjx-c.mjx-c54::before {
  padding: 0.677em 0.722em 0 0;
  content: "T";
}

mjx-c.mjx-c55::before {
  padding: 0.683em 0.75em 0.022em 0;
  content: "U";
}

mjx-c.mjx-c35::before {
  padding: 0.666em 0.5em 0.022em 0;
  content: "5";
}

mjx-c.mjx-c31::before {
  padding: 0.666em 0.5em 0 0;
  content: "1";
}

mjx-c.mjx-c2E::before {
  padding: 0.12em 0.278em 0 0;
  content: ".";
}

mjx-c.mjx-c39::before {
  padding: 0.666em 0.5em 0.022em 0;
  content: "9";
}

mjx-c.mjx-c37::before {
  padding: 0.676em 0.5em 0.022em 0;
  content: "7";
}

mjx-c.mjx-c1D438.TEX-I::before {
  padding: 0.68em 0.764em 0 0;
  content: "E";
}

mjx-c.mjx-c34::before {
  padding: 0.677em 0.5em 0 0;
  content: "4";
}

mjx-c.mjx-c38::before {
  padding: 0.666em 0.5em 0.022em 0;
  content: "8";
}

mjx-c.mjx-c30::before {
  padding: 0.666em 0.5em 0.022em 0;
  content: "0";
}

mjx-c.mjx-c224A.TEX-A::before {
  padding: 0.579em 0.778em 0.039em 0;
  content: "\224A";
}

mjx-c.mjx-c27F9::before {
  padding: 0.525em 1.638em 0.024em 0;
  content: "\27F9";
}

mjx-c.mjx-c1D444.TEX-I::before {
  padding: 0.704em 0.791em 0.194em 0;
  content: "Q";
}

mjx-c.mjx-c1D43E.TEX-I::before {
  padding: 0.683em 0.889em 0 0;
  content: "K";
}

mjx-c.mjx-c1D434.TEX-I::before {
  padding: 0.716em 0.75em 0 0;
  content: "A";
}

mjx-c.mjx-c1D449.TEX-I::before {
  padding: 0.683em 0.769em 0.022em 0;
  content: "V";
}

mjx-c.mjx-c4D::before {
  padding: 0.683em 0.917em 0 0;
  content: "M";
}

mjx-c.mjx-c49::before {
  padding: 0.683em 0.361em 0 0;
  content: "I";
}

mjx-c.mjx-c1D446.TEX-I::before {
  padding: 0.705em 0.645em 0.022em 0;
  content: "S";
}

mjx-c.mjx-c226B::before {
  padding: 0.567em 1em 0.067em 0;
  content: "\226B";
}

mjx-c.mjx-c2248::before {
  padding: 0.483em 0.778em 0 0;
  content: "\2248";
}

mjx-c.mjx-c53::before {
  padding: 0.705em 0.556em 0.022em 0;
  content: "S";
}

mjx-c.mjx-c7A::before {
  padding: 0.431em 0.444em 0 0;
  content: "z";
}

mjx-c.mjx-cD7::before {
  padding: 0.491em 0.778em 0 0;
  content: "\D7";
}

mjx-c.mjx-c4B::before {
  padding: 0.683em 0.778em 0 0;
  content: "K";
}

mjx-c.mjx-c56::before {
  padding: 0.683em 0.75em 0.022em 0;
  content: "V";
}

mjx-c.mjx-c47::before {
  padding: 0.705em 0.785em 0.022em 0;
  content: "G";
}

mjx-c.mjx-c62::before {
  padding: 0.694em 0.556em 0.011em 0;
  content: "b";
}

mjx-c.mjx-c2D::before {
  padding: 0.252em 0.333em 0 0;
  content: "-";
}

mjx-c.mjx-c28.TEX-S3::before {
  padding: 1.45em 0.736em 0.949em 0;
  content: "(";
}

mjx-c.mjx-c2C::before {
  padding: 0.121em 0.278em 0.194em 0;
  content: ",";
}

mjx-c.mjx-c29.TEX-S3::before {
  padding: 1.45em 0.736em 0.949em 0;
  content: ")";
}

mjx-c.mjx-c66::before {
  padding: 0.705em 0.372em 0 0;
  content: "f";
}

mjx-c.mjx-c1D43B.TEX-I::before {
  padding: 0.683em 0.888em 0 0;
  content: "H";
}

mjx-c.mjx-c1D43F.TEX-I::before {
  padding: 0.683em 0.681em 0 0;
  content: "L";
}

mjx-c.mjx-cA0::before {
  padding: 0 0.25em 0 0;
  content: "\A0";
}

mjx-c.mjx-c36::before {
  padding: 0.666em 0.5em 0.022em 0;
  content: "6";
}

mjx-c.mjx-c48::before {
  padding: 0.683em 0.75em 0 0;
  content: "H";
}

mjx-c.mjx-c1D44C.TEX-I::before {
  padding: 0.683em 0.763em 0 0;
  content: "Y";
}

mjx-c.mjx-c1D44A.TEX-I::before {
  padding: 0.683em 1.048em 0.022em 0;
  content: "W";
}

mjx-c.mjx-c3E::before {
  padding: 0.54em 0.778em 0.04em 0;
  content: ">";
}

mjx-c.mjx-c2192::before {
  padding: 0.511em 1em 0.011em 0;
  content: "\2192";
}

mjx-c.mjx-c1D6FD.TEX-I::before {
  padding: 0.705em 0.566em 0.194em 0;
  content: "\3B2";
}

mjx-c.mjx-c44::before {
  padding: 0.683em 0.764em 0 0;
  content: "D";
}

mjx-c.mjx-c1D44B.TEX-I::before {
  padding: 0.683em 0.852em 0 0;
  content: "X";
}

mjx-c.mjx-c1D44D.TEX-I::before {
  padding: 0.683em 0.723em 0 0;
  content: "Z";
}

mjx-c.mjx-c221A::before {
  padding: 0.8em 0.853em 0.2em 0;
  content: "\221A";
}

mjx-c.mjx-c1D441.TEX-I::before {
  padding: 0.683em 0.888em 0 0;
  content: "N";
}

mjx-c.mjx-c27FA::before {
  padding: 0.525em 1.858em 0.024em 0;
  content: "\27FA";
}

mjx-c.mjx-c1D451.TEX-I::before {
  padding: 0.694em 0.52em 0.01em 0;
  content: "d";
}

mjx-c.mjx-c1D461.TEX-I::before {
  padding: 0.626em 0.361em 0.011em 0;
  content: "t";
}

mjx-c.mjx-c1D45C.TEX-I::before {
  padding: 0.441em 0.485em 0.011em 0;
  content: "o";
}

mjx-c.mjx-c1D44E.TEX-I::before {
  padding: 0.441em 0.529em 0.01em 0;
  content: "a";
}

mjx-c.mjx-c1D459.TEX-I::before {
  padding: 0.694em 0.298em 0.011em 0;
  content: "l";
}

mjx-c.mjx-c1D45A.TEX-I::before {
  padding: 0.442em 0.878em 0.011em 0;
  content: "m";
}

mjx-c.mjx-c1D43C.TEX-I::before {
  padding: 0.683em 0.504em 0 0;
  content: "I";
}

mjx-c.mjx-c1D436.TEX-I::before {
  padding: 0.705em 0.76em 0.022em 0;
  content: "C";
}

mjx-c.mjx-c1D452.TEX-I::before {
  padding: 0.442em 0.466em 0.011em 0;
  content: "e";
}

mjx-c.mjx-c3C::before {
  padding: 0.54em 0.778em 0.04em 0;
  content: "<";
}

mjx-c.mjx-c2212::before {
  padding: 0.583em 0.778em 0.082em 0;
  content: "\2212";
}

mjx-c.mjx-c1D443.TEX-I::before {
  padding: 0.683em 0.751em 0 0;
  content: "P";
}
</style><link crossorigin="anonymous" href="https://distill.pub/third-party/katex/katex.min.css" rel="stylesheet"/><script async="" src="https://distill.pub/third-party/katex/katex.min.js"></script></head>
<body> <d-front-matter> <script async="" type="text/json">
      {
            "title": "Transformer 推理全解析",
            "description": "对 Transformer 执行推理与训练可能大不相同。部分原因在于推理引入了一个需要考虑的新因素：延迟。在本节中，我们将从模型中采样单个新令牌开始，一直到作为推理引擎的一部分，在多个加速器切片上高效扩展大型 Transformer。",
            "published": "2025年2月4日",
            "authors": [

              {
                "author": "Jacob Austin",
                "authorURL": "https://www.jacobaustin.org/",
                "affiliations": [
                  {
                    "name": "Google DeepMind",
                    "url": ""
                  }
                ]
              },

              {
                "author": "Sholto Douglas",
                "authorURL": "https://x.com/_sholtodouglas",
                "affiliations": [
                  {
                    "name": "",
                    "url": ""
                  }
                ]
              },

              {
                "author": "Roy Frostig",
                "authorURL": "https://cs.stanford.edu/~rfrostig/",
                "affiliations": [
                  {
                    "name": "",
                    "url": ""
                  }
                ]
              },

              {
                "author": "Anselm Levskaya",
                "authorURL": "https://anselmlevskaya.com/",
                "affiliations": [
                  {
                    "name": "",
                    "url": ""
                  }
                ]
              },

              {
                "author": "Charlie Chen",
                "authorURL": "https://x.com/charliexychen",
                "affiliations": [
                  {
                    "name": "",
                    "url": ""
                  }
                ]
              },

              {
                "author": "Sharad Vikram",
                "authorURL": "https://sharadvikram.com/",
                "affiliations": [
                  {
                    "name": "",
                    "url": ""
                  }
                ]
              },

              {
                "author": "Federico Lebron",
                "authorURL": "https://fedelebron.com/",
                "affiliations": [
                  {
                    "name": "",
                    "url": ""
                  }
                ]
              },

              {
                "author": "Peter Choy",
                "authorURL": "https://x.com/pchoy95",
                "affiliations": [
                  {
                    "name": "",
                    "url": ""
                  }
                ]
              },

              {
                "author": "Vinay Ramasesh",
                "authorURL": "https://x.com/vinayramasesh",
                "affiliations": [
                  {
                    "name": "",
                    "url": ""
                  }
                ]
              },

              {
                "author": "Albert Webson",
                "authorURL": "https://representation.ai/",
                "affiliations": [
                  {
                    "name": "",
                    "url": ""
                  }
                ]
              },

              {
                "author": "Reiner Pope<sup>*</sup>",
                "authorURL": "https://x.com/reinerpope",
                "affiliations": [
                  {
                    "name": "",
                    "url": ""
                  }
                ]
              }

            ],
            "katex": {
              "delimiters": [
                {
                  "left": "$",
                  "right": "$",
                  "display": false
                },
                {
                  "left": "$$",
                  "right": "$$",
                  "display": true
                }
              ]
            }
          }
    </script> </d-front-matter> <header> <script>
    function goToTop() {
      document.body.scrollTop = 0; // For Safari
      document.documentElement.scrollTop = 0; // For Chrome, Firefox, IE and Opera
    }

    // When the user scrolls down 20px from the top of the document, show the button
    window.onscroll = function() {scrollFunction()};

    function scrollFunction() {
      // Get the button:
      let mybutton = document.getElementById("top-button");

      if (document.body.scrollTop > 40 || document.documentElement.scrollTop > 40) {
        mybutton.style.display = "block";
      } else {
        mybutton.style.display = "none";
      }
  }
  </script> <nav class="navbar navbar-light navbar-expand-sm fixed-top" id="navbar" role="navigation"> <div class="container"> <a class="navbar-brand title font-weight-lighter" href="scaling-book.html"> 如何扩展你的模型 </a> <button aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation" class="navbar-toggler collapsed ml-auto" data-target="#navbarNav" data-toggle="collapse" type="button"> <span class="sr-only">切换导航</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="left-button section-button"><a href="applied-training.html"><svg viewbox="-78.5 0 512 512"><path d="M257 64L291 98 128 262 291 426 257 460 61 262 257 64Z"></path></svg></a></div> <div class="right-button section-button"><a href="applied-inference.html"><svg viewbox="-78.5 0 512 512"><path d="M98 460L64 426 227 262 64 98 98 64 294 262 98 460Z"></path></svg></a></div> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item"> <a class="nav-link" href="scaling-book.html"> </a> </li> <li class="nav-item nav-hidden"><a class="nav-link" id="top-button" onclick="goToTop()" style="display: none;">返回顶部</a></li> <li class="nav-item nav-hidden"><p class="nav-link"></p></li> <li class="nav-item nav-hidden"><a class="nav-link" href="applied-training.html">上一部分</a></li> <li class="nav-item nav-hidden"><a class="nav-link" href="applied-inference.html">下一部分</a></li> <li class="nav-item nav-hidden"><p class="nav-link"></p></li> <li class="nav-item dropdown"> <a aria-expanded="false" aria-haspopup="true" class="nav-link dropdown-toggle" data-toggle="dropdown" href="#" id="navbarDropdown" role="button">章节 </a> <div aria-labelledby="navbarDropdown" class="dropdown-menu dropdown-menu-right"> <a class="dropdown-item" href="https://jax-ml.github.io/scaling-book/index">第0部分. 引言</a> <a class="dropdown-item" href="roofline.html">第1部分. 屋顶线模型入门</a> <a class="dropdown-item" href="tpus.html">第2部分. TPU 全解析</a> <a class="dropdown-item" href="sharding.html">第3部分. 分片矩阵乘法</a> <a class="dropdown-item" href="transformers.html">第4部分. Transformer</a> <a class="dropdown-item" href="training.html">第5部分. 训练</a> <a class="dropdown-item" href="applied-training.html">第6部分. 训练 LLaMA</a> <a class="dropdown-item" href="inference.html">第7部分. 推理</a> <a class="dropdown-item" href="applied-inference.html">第8部分. 服务 LLaMA</a> <a class="dropdown-item" href="profiling.html">第9部分. 性能分析</a> <a class="dropdown-item" href="jax-stuff.html">第10部分. JAX 全解析</a> <a class="dropdown-item" href="conclusion.html">第11部分. 结论</a> <a class="dropdown-item" href="gpus.html">第12部分. GPU</a> </div> </li> <li class="toggle-container"> <button id="light-toggle" title="更改主题"> <i class="ti ti-sun-moon" id="light-toggle-system"></i> <i class="ti ti-moon-filled" id="light-toggle-dark"></i> <i class="ti ti-sun-filled" id="light-toggle-light"></i> </button> </li> </ul> </div> </div> </nav> <progress id="progress" value="0"> <div class="progress-container"> <span class="progress-bar"></span> </div> </progress> </header> <div class="post distill"><div class="translation-info base-grid" style="margin-bottom: 20px;">
<div style="grid-column: text;
                       display: flex;
                       align-items: center;
                       justify-content: space-between;
                       padding: 16px 0;
                       border-bottom: 1px solid var(--global-text-color-light, rgba(0,0,0,0.15));
                       font-size: 16px;
                       line-height: 1.5;
                       color: var(--global-text-color, currentColor);">
<div style="display: flex;
                           flex-direction: column;
                           gap: 8px;">
<div>
<span style="font-weight: 600; color: var(--global-text-color, currentColor);">🔗 英文原文：</span>
<a href="https://jax-ml.github.io/scaling-book/inference/" onmouseout="this.style.textDecoration='none'" onmouseover="this.style.textDecoration='underline'" rel="noopener noreferrer" style="color: var(--global-theme-color, #004276);
                                  text-decoration: none;
                                  margin-left: 4px;" target="_blank">
                           https://jax-ml.github.io/scaling-book/inference/
                        </a>
</div>
<div>
<span style="font-weight: 600; color: var(--global-text-color, currentColor);">✍️ 翻译：</span>
<a href="https://github.com/skindhu/Build-A-Large-Language-Model-CN" target="_blank" style="margin-left: 4px; color: var(--global-theme-color, #004276); text-decoration: none;">北极的树</a>
</div>
</div>
<div style="flex-shrink: 0;
                           display: flex;
                           flex-direction: column;
                           align-items: center;
                           gap: 6px;
                           margin-left: 20px;">
<img alt="微信二维码" loading="lazy" src="https://wechat-account-1251781786.cos.ap-guangzhou.myqcloud.com/wechat_account.jpeg" style="width: 80px;
                                height: 80px;
                                border-radius: 6px;
                                opacity: 0.9;"/>
<span style="font-size: 12px;
                                 color: var(--global-text-color-light, currentColor);
                                 opacity: 0.8;
                                 text-align: center;">
                        微信公众号
                    </span>
</div>
</div>
</div> <d-title> <h1>Transformer 推理全解析</h1> <p>《<a href="scaling-book.html">如何扩展你的模型</a>》第 7 部分 (<a href="applied-training.html">第 6 部分：训练 LLaMA</a> | <a href="applied-inference.html">第 8 部分：服务 LLaMA</a>)</p> <p>对 Transformer 执行推理与训练可能大不相同。部分原因在于推理引入了一个需要考虑的新因素：延迟。在本节中，我们将从模型中采样单个新词元开始，一直到作为推理引擎的一部分，在多个加速器切片上高效扩展大型 Transformer。</p> </d-title> <d-byline>
<div class="byline grid">
<div class="authors-affiliations grid">
<h3 style="grid-column: 1; grid-row: 1;">作者</h3>
<h3></h3>
<h3>单位</h3>
<p class="author" style="grid-column: 1; grid-row: 2;">
<a class="name" href="https://www.jacobaustin.org/">Jacob Austin</a>
</p>
<p class="affiliation" style="grid-column: 3; grid-row: 2;">
<span class="affiliation">Google DeepMind</span>
</p>
<p class="author" style="grid-column: 1; grid-row: 3;">
<a class="name" href="https://x.com/_sholtodouglas">Sholto Douglas</a>
</p>
<p class="affiliation" style="grid-column: 3; grid-row: 3;">
<span class="affiliation"></span>
</p>
<p class="author" style="grid-column: 1; grid-row: 4;">
<a class="name" href="https://cs.stanford.edu/~rfrostig/">Roy Frostig</a>
</p>
<p class="affiliation" style="grid-column: 3; grid-row: 4;">
<span class="affiliation"></span>
</p>
<p class="author" style="grid-column: 1; grid-row: 5;">
<a class="name" href="https://anselmlevskaya.com/">Anselm Levskaya</a>
</p>
<p class="affiliation" style="grid-column: 3; grid-row: 5;">
<span class="affiliation"></span>
</p>
<p class="author" style="grid-column: 1; grid-row: 6;">
<a class="name" href="https://x.com/charliexychen">Charlie Chen</a>
</p>
<p class="affiliation" style="grid-column: 3; grid-row: 6;">
<span class="affiliation"></span>
</p>
<p class="author" style="grid-column: 1; grid-row: 7;">
<a class="name" href="https://sharadvikram.com/">Sharad Vikram</a>
</p>
<p class="affiliation" style="grid-column: 3; grid-row: 7;">
<span class="affiliation"></span>
</p>
<p class="author" style="grid-column: 2; grid-row: 2;">
<a class="name" href="https://fedelebron.com/">Federico Lebron</a>
</p>
<p class="affiliation" style="grid-column: 3; grid-row: 2;">
<span class="affiliation"></span>
</p>
<p class="author" style="grid-column: 2; grid-row: 3;">
<a class="name" href="https://x.com/pchoy95">Peter Choy</a>
</p>
<p class="affiliation" style="grid-column: 3; grid-row: 3;">
<span class="affiliation"></span>
</p>
<p class="author" style="grid-column: 2; grid-row: 4;">
<a class="name" href="https://x.com/vinayramasesh">Vinay Ramasesh</a>
</p>
<p class="affiliation" style="grid-column: 3; grid-row: 4;">
<span class="affiliation"></span>
</p>
<p class="author" style="grid-column: 2; grid-row: 5;">
<a class="name" href="https://representation.ai/">Albert Webson</a>
</p>
<p class="affiliation" style="grid-column: 3; grid-row: 5;">
<span class="affiliation"></span>
</p>
<p class="author" style="grid-column: 2; grid-row: 6;">
<a class="name" href="https://x.com/reinerpope">Reiner Pope<sup>*</sup></a>
</p>
<p class="affiliation" style="grid-column: 3; grid-row: 6;">
<span class="affiliation"></span>
</p>
</div>
<div>
<h3>发布日期</h3>
<p>2025年2月4日</p>
</div>
</div>
</d-byline> <d-article> <d-contents> <nav class="l-text figcaption"> <h3>目录</h3> <div> <a href="#the-basics-of-transformer-inference">Transformer 推理基础</a> </div> <div> <a href="#"></a> </div> <ul> <li> <a href="#what-do-we-actually-want-to-optimize">我们究竟想优化什么？</a> </li> <li> <a href="#linear-operations-what-bottlenecks-us">线性操作：瓶颈何在？</a> </li> <li> <a href="#what-about-attention">注意力机制呢？</a> </li> <li> <a href="#theoretical-estimates-for-llm-latency-and-throughput">LLM 延迟和吞吐量的理论估算</a> </li> <li> <a href="#what-about-memory">内存方面呢？</a> </li> <li> <a href="#modeling-throughput-and-latency-for-llama-2-13b">为 LLaMA 2-13B 的吞吐量和延迟建模</a> </li> </ul> <div> <a href="#tricks-for-improving-generation-throughput-and-latency">提升生成吞吐量和延迟的技巧</a> </div> <div> <a href="#distributing-inference-over-multiple-accelerators">在多个加速器上分布推理</a> </div> <div> <a href="#"></a> </div> <ul> <li> <a href="#prefill">预填充</a> </li> <li> <a href="#generation">生成</a> </li> <li> <a href="#sharding-the-kv-cache">分片 KV 缓存</a> </li> </ul> <div> <a href="#designing-an-effective-inference-engine">设计高效的推理引擎</a> </div> <div> <a href="#"></a> </div> <ul> <li> <a href="#continuous-batching">连续批处理</a> </li> <li> <a href="#prefix-caching">前缀缓存</a> </li> <li> <a href="#let-s-look-at-an-implementation-jetstream">来看一个实现：JetStream</a> </li> </ul> <div> <a href="#worked-problems">习题</a> </div> <div> <a href="#appendix">附录</a> </div> </nav> </d-contents> <h2 id="the-basics-of-transformer-inference">Transformer 推理基础</h2> <p>你已经训练好一个 Transformer，想用它来生成一些新序列。<em>说到底，基准分数上升和损失曲线下降，只是衡量模型在实际应用中能否产生有趣结果的代理指标！</em><d-footnote id="d-footnote-1">从历史上看，你可以在完全不接触推理的情况下，对 Transformer 进行大量研究——LLM 损失、多项选择基准测试都可以在没有合适的 KV 缓存或生成循环实现的情况下高效运行。这意味着，尤其是在研究代码库中，推理代码路径上通常有很多容易摘取的低垂果实。</d-footnote></p> <p>采样在概念上很简单。我们输入一个序列，我们钟爱的 Transformer 就会输出 <mjx-container class="MathJax CtxtMenu_Attached_0" ctxtmenu_counter="0" jax="CHTML" style="font-size: 116.9%; position: relative;" tabindex="0"><mjx-math aria-hidden="true" class="MJX-TEX"><mjx-mi class="mjx-n"><mjx-c class="mjx-c6C"></mjx-c><mjx-c class="mjx-c6F"></mjx-c><mjx-c class="mjx-c67"></mjx-c></mjx-mi><mjx-mo class="mjx-n"><mjx-c class="mjx-c2061"></mjx-c></mjx-mo><mjx-mi class="mjx-i" space="2"><mjx-c class="mjx-c1D45D TEX-I"></mjx-c></mjx-mi><mjx-mo class="mjx-n"><mjx-c class="mjx-c28"></mjx-c></mjx-mo><mjx-msub><mjx-mtext class="mjx-n"><mjx-c class="mjx-c6E"></mjx-c><mjx-c class="mjx-c65"></mjx-c><mjx-c class="mjx-c78"></mjx-c><mjx-c class="mjx-c74"></mjx-c><mjx-c class="mjx-c20"></mjx-c><mjx-c class="mjx-c74"></mjx-c><mjx-c class="mjx-c6F"></mjx-c><mjx-c class="mjx-c6B"></mjx-c><mjx-c class="mjx-c65"></mjx-c><mjx-c class="mjx-c6E"></mjx-c></mjx-mtext><mjx-script style="vertical-align: -0.15em;"><mjx-mi class="mjx-i" size="s"><mjx-c class="mjx-c1D456 TEX-I"></mjx-c></mjx-mi></mjx-script></mjx-msub><mjx-mo class="mjx-n"><mjx-c class="mjx-c7C"></mjx-c></mjx-mo><mjx-mtext class="mjx-n"><mjx-c class="mjx-c70"></mjx-c><mjx-c class="mjx-c72"></mjx-c><mjx-c class="mjx-c65"></mjx-c><mjx-c class="mjx-c76"></mjx-c><mjx-c class="mjx-c69"></mjx-c><mjx-c class="mjx-c6F"></mjx-c><mjx-c class="mjx-c75"></mjx-c><mjx-c class="mjx-c73"></mjx-c><mjx-c class="mjx-c20"></mjx-c><mjx-c class="mjx-c74"></mjx-c><mjx-c class="mjx-c6F"></mjx-c><mjx-c class="mjx-c6B"></mjx-c><mjx-c class="mjx-c65"></mjx-c><mjx-c class="mjx-c6E"></mjx-c><mjx-c class="mjx-c73"></mjx-c></mjx-mtext><mjx-mo class="mjx-n"><mjx-c class="mjx-c29"></mjx-c></mjx-mo></mjx-math><mjx-assistive-mml display="inline" unselectable="on"><math xmlns="http://www.w3.org/1998/Math/MathML"><mi>log</mi><mo data-mjx-texclass="NONE">⁡</mo><mi>p</mi><mo stretchy="false">(</mo><msub><mtext>next token</mtext><mi>i</mi></msub><mo data-mjx-texclass="ORD" fence="false" stretchy="false">|</mo><mtext>previous tokens</mtext><mo stretchy="false">)</mo></math></mjx-assistive-mml></mjx-container>，即所有可能的下一个词元的对数概率。我们可以从这个分布中采样，得到一个新的词元。将这个词元追加到序列中，重复这个过程，我们就得到了一个作为提示延续的词元序列。</p> <figure> <picture> <source class="responsive-img-srcset" sizes="95vw" srcset="https://jax-ml.github.io/scaling-book/assets/img/naive-inference-480.webp 480w, https://jax-ml.github.io/scaling-book/assets/img/naive-inference-800.webp 800w, https://jax-ml.github.io/scaling-book/assets/img/naive-inference-1400.webp 1400w" type="image/webp"/> <img class="img-fluid" height="440" loading="lazy" onerror="this.onerror=null; $('.responsive-img-srcset').remove();" src="https://jax-ml.github.io/scaling-book/assets/img/naive-inference.png" width="1026"/> </picture> <figcaption class="caption"><b>图：</b>从 Transformer 进行朴素采样。蓝色的 logits 为我们提供了下一个词元的分布，我们可以从中采样。注意，每一步都会重新处理整个前缀，导致算法的运行时间为 <d-math>\Theta(n^2)</d-math>。</figcaption> </figure> <p>我们刚刚描述了 Transformer 采样的朴素实现，虽然它能工作，但<strong>我们在实践中从不这样做</strong>，因为每次生成一个词元时，我们都在重新处理整个序列。这个算法在 FFW 上的复杂度是 <mjx-container class="MathJax CtxtMenu_Attached_0" ctxtmenu_counter="1" jax="CHTML" style="font-size: 116.9%; position: relative;" tabindex="0"><mjx-math aria-hidden="true" class="MJX-TEX"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D442 TEX-I"></mjx-c></mjx-mi><mjx-mo class="mjx-n"><mjx-c class="mjx-c28"></mjx-c></mjx-mo><mjx-msup><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D45B TEX-I"></mjx-c></mjx-mi><mjx-script style="vertical-align: 0.363em;"><mjx-mn class="mjx-n" size="s"><mjx-c class="mjx-c32"></mjx-c></mjx-mn></mjx-script></mjx-msup><mjx-mo class="mjx-n"><mjx-c class="mjx-c29"></mjx-c></mjx-mo></mjx-math><mjx-assistive-mml display="inline" unselectable="on"><math xmlns="http://www.w3.org/1998/Math/MathML"><mi>O</mi><mo stretchy="false">(</mo><msup><mi>n</mi><mn>2</mn></msup><mo stretchy="false">)</mo></math></mjx-assistive-mml></mjx-container>，在注意力机制上的复杂度是 <mjx-container class="MathJax CtxtMenu_Attached_0" ctxtmenu_counter="2" jax="CHTML" style="font-size: 116.9%; position: relative;" tabindex="0"><mjx-math aria-hidden="true" class="MJX-TEX"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D442 TEX-I"></mjx-c></mjx-mi><mjx-mo class="mjx-n"><mjx-c class="mjx-c28"></mjx-c></mjx-mo><mjx-msup><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D45B TEX-I"></mjx-c></mjx-mi><mjx-script style="vertical-align: 0.363em;"><mjx-mn class="mjx-n" size="s"><mjx-c class="mjx-c33"></mjx-c></mjx-mn></mjx-script></mjx-msup><mjx-mo class="mjx-n"><mjx-c class="mjx-c29"></mjx-c></mjx-mo></mjx-math><mjx-assistive-mml display="inline" unselectable="on"><math xmlns="http://www.w3.org/1998/Math/MathML"><mi>O</mi><mo stretchy="false">(</mo><msup><mi>n</mi><mn>3</mn></msup><mo stretchy="false">)</mo></math></mjx-assistive-mml></mjx-container>，才能生成 <mjx-container class="MathJax CtxtMenu_Attached_0" ctxtmenu_counter="3" jax="CHTML" style="font-size: 116.9%; position: relative;" tabindex="0"><mjx-math aria-hidden="true" class="MJX-TEX"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D45B TEX-I"></mjx-c></mjx-mi></mjx-math><mjx-assistive-mml display="inline" unselectable="on"><math xmlns="http://www.w3.org/1998/Math/MathML"><mi>n</mi></math></mjx-assistive-mml></mjx-container> 个词元！</p> <p><strong>我们如何避免这种情况？</strong> 事实证明，我们不必每次都进行完整的正向传播，而是可以保存每次正向传播的一些中间激活值，从而避免重新处理之前的词元。具体来说，由于在点积注意力中，一个给定的词元只关注之前的词元，我们可以简单地将每个词元的键（key）和值（value）投影写入一个名为 <strong>KV 缓存</strong> 的新数据结构中。一旦我们为过去的词元保存了这些键/值投影，未来的词元就可以简单地计算它们的 <mjx-container class="MathJax CtxtMenu_Attached_0" ctxtmenu_counter="4" jax="CHTML" style="font-size: 116.9%; position: relative;" tabindex="0"><mjx-math aria-hidden="true" class="MJX-TEX"><mjx-msub><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D45E TEX-I"></mjx-c></mjx-mi><mjx-script style="vertical-align: -0.15em; margin-left: -0.014em;"><mjx-mi class="mjx-i" size="s"><mjx-c class="mjx-c1D456 TEX-I"></mjx-c></mjx-mi></mjx-script></mjx-msub><mjx-mo class="mjx-n" space="3"><mjx-c class="mjx-c22C5"></mjx-c></mjx-mo><mjx-msub space="3"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D458 TEX-I"></mjx-c></mjx-mi><mjx-script style="vertical-align: -0.15em;"><mjx-mi class="mjx-i" size="s"><mjx-c class="mjx-c1D457 TEX-I"></mjx-c></mjx-mi></mjx-script></mjx-msub></mjx-math><mjx-assistive-mml display="inline" unselectable="on"><math xmlns="http://www.w3.org/1998/Math/MathML"><msub><mi>q</mi><mi>i</mi></msub><mo>⋅</mo><msub><mi>k</mi><mi>j</mi></msub></math></mjx-assistive-mml></mjx-container> 乘积，而无需对早期的词元执行任何新的 FLOPs。太棒了！</p> <p>考虑到这一点，推理有两个关键部分：</p> <ul> <li> <b style="color: red;">预填充</b>：给定一个长提示，我们同时处理提示中的所有词元，并将生成的激活值（特别是键值投影）保存在一个 <strong>“KV 缓存”</strong> 中。我们还保存最后一个词元的 logits。</li> <li> <b style="color: blue;">生成</b>：给定一个 KV 缓存和前一个 logits，我们从 logits 中增量地采样一个词元，将该词元反馈给 Transformer，并为下一步生成一组新的 logits。我们还将新词元的 KV 激活值附加到 KV 缓存中。我们重复这个过程，直到遇到一个特殊的 <code class="language-plaintext highlighter-rouge">&lt;EOS&gt;</code> 词元或达到某个最大长度限制。</li> </ul> <p>下图是使用 KV 缓存进行采样的示意图：</p> <figure> <picture> <source class="responsive-img-srcset" sizes="95vw" srcset="https://jax-ml.github.io/scaling-book/assets/img/cached-inference-480.webp 480w, https://jax-ml.github.io/scaling-book/assets/img/cached-inference-800.webp 800w, https://jax-ml.github.io/scaling-book/assets/img/cached-inference-1400.webp 1400w" type="image/webp"/> <img class="img-fluid" height="auto" loading="lazy" onerror="this.onerror=null; $('.responsive-img-srcset').remove();" src="https://jax-ml.github.io/scaling-book/assets/img/cached-inference.png" width="100%"/> </picture> <figcaption class="caption"><b>图：</b>使用 KV 缓存进行高效 Transformer 采样的示意图。<b style="color: red;">预填充</b>处理我们的提示，并将每个词元的键值激活值保存在缓存中。<b style="color: blue;">生成</b>接收这个缓存（以及最后一个词元的 logits），采样一个新词元，并将该新词元传递给模型，模型会关注 KV 缓存，并将新词元的键值投影保存回缓存中。在 MLP 块中，这是一个 <d-math>O(n)</d-math> 算法。</figcaption> </figure> <p>通过使用 KV 缓存进行采样，我们将生成 <d-math>n</d-math> 个词元的时间复杂度在 FFW 上降低到 <mjx-container class="MathJax CtxtMenu_Attached_0" ctxtmenu_counter="5" jax="CHTML" style="font-size: 116.9%; position: relative;" tabindex="0"><mjx-math aria-hidden="true" class="MJX-TEX"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D442 TEX-I"></mjx-c></mjx-mi><mjx-mo class="mjx-n"><mjx-c class="mjx-c28"></mjx-c></mjx-mo><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D45B TEX-I"></mjx-c></mjx-mi><mjx-mo class="mjx-n"><mjx-c class="mjx-c29"></mjx-c></mjx-mo></mjx-math><mjx-assistive-mml display="inline" unselectable="on"><math xmlns="http://www.w3.org/1998/Math/MathML"><mi>O</mi><mo stretchy="false">(</mo><mi>n</mi><mo stretchy="false">)</mo></math></mjx-assistive-mml></mjx-container>，在注意力上降低到 <mjx-container class="MathJax CtxtMenu_Attached_0" ctxtmenu_counter="6" jax="CHTML" style="font-size: 116.9%; position: relative;" tabindex="0"><mjx-math aria-hidden="true" class="MJX-TEX"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D442 TEX-I"></mjx-c></mjx-mi><mjx-mo class="mjx-n"><mjx-c class="mjx-c28"></mjx-c></mjx-mo><mjx-msup><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D45B TEX-I"></mjx-c></mjx-mi><mjx-script style="vertical-align: 0.363em;"><mjx-mn class="mjx-n" size="s"><mjx-c class="mjx-c32"></mjx-c></mjx-mn></mjx-script></mjx-msup><mjx-mo class="mjx-n"><mjx-c class="mjx-c29"></mjx-c></mjx-mo></mjx-math><mjx-assistive-mml display="inline" unselectable="on"><math xmlns="http://www.w3.org/1998/Math/MathML"><mi>O</mi><mo stretchy="false">(</mo><msup><mi>n</mi><mn>2</mn></msup><mo stretchy="false">)</mo></math></mjx-assistive-mml></mjx-container>，因为我们从不重新处理之前的词元。然而，生成一个序列仍然需要多次正向传播——当你查询 Gemini 或 ChatGPT 并看到结果以流式方式返回时，发生的就是这个过程。每个词元（通常）都是对一个巨大模型的独立（但部分缓存的）Transformer 调用。</p> <p>我们很快就会看到，<b style="color: red;">预填充</b>和<b style="color: blue;">生成</b>是两种截然不同的任务——Transformer 推理实际上是伪装成一个任务的两个任务！与训练相比，KV 缓存也是一个新颖且重要的复杂性来源。</p> <h3 id="what-do-we-actually-want-to-optimize">我们究竟想优化什么？</h3> <p>在继续之前，值得强调推理中一个全新的方面：延迟。在训练期间，我们只关心吞吐量（每秒处理的总词元数），而在推理期间，我们必须关心生成词元的速度（包括<strong>首词元时间（TTFT）</strong>和<strong>每词元延迟</strong>）。例如：</p> <ul> <li> 用于评估和数据生成的<strong>离线批量推理</strong>只关心推理的批量成本，而忽略单个样本的延迟。</li> <li> <strong>聊天界面/流式任务</strong>需要在低 TTFT 的同时，以低成本大规模运行，并且生成词元的速度要快到超过人类的阅读速度。</li> <li> <strong>边缘推理</strong>（例如，在你笔记本电脑上运行的 <code class="language-plaintext highlighter-rouge">llama.cpp</code>）只需要在尽可能低的延迟下一次服务一个用户，且可能面临严格的硬件限制。</li> </ul> <p>最大化硬件利用率仍然至关重要，有助于降低成本和 TTFT，但与训练不同，它并<em>不一定</em>在所有情况下都能转化为更好的单个用户体验。在加速器、系统和模型架构层面的许多优化，都是在延迟、吞吐量、上下文长度甚至模型质量之间进行权衡。</p> <h3 id="a-more-granular-view-of-the-transformer">更细粒度地审视 Transformer</h3> <p>到目前为止，我们主要将 Transformer 视为一堆前馈块。虽然从 FLOPs 和内存的角度来看，这通常是合理的，但这不足以正确地为推理建模。<d-footnote id="d-footnote-2">在本节中，你会注意到一件事，那就是推理远不如训练那样宽容。我们通常拥有的 FLOPs 要少得多，批处理的机会也更少，而且对延迟的敏感度要高得多。KV 缓存也极大地复杂化了推理。</d-footnote> 正如我们在<a href="transformers.html">第 4 部分</a>中看到的，Transformer 正向传播的主要组成部分是：</p> <ol> <li> <strong>一系列线性操作</strong>，包括 MLP (<d-math>W_{in}</d-math>, <d-math>W_{out}</d-math>) 和注意力 QKV 投影及输出投影 (<d-math>W_Q</d-math>, <d-math>W_K</d-math>, <d-math>W_V</d-math>, 和 <d-math>W_O</d-math>)。这些都涉及从 HBM 读取参数和一批激活值，执行一些 FLOPs，然后将结果写回 HBM。</li> <li> <strong>点积注意力</strong>。我们需要从 HBM 读取一批键值投影和一批查询激活值，进行一些内积和 softmax 操作，然后将注意力结果写回 HBM。</li> <li> <strong>其他所有操作</strong>，包括应用层归一化、激活函数、词元采样、更新 KV 缓存和位置嵌入。这些操作确实会消耗一些 FLOPs，但与上述操作相比，它们要么占主导地位，要么被融合到上述操作中。</li> </ol> <p>在接下来的几节中，我们将在预填充和生成的背景下审视这些操作，并探究什么可能成为我们性能的瓶颈。在单个加速器内，我们是受计算限制还是受内存限制？我们想强调的是，对于预填充和生成，答案将会有多大的不同。</p> <h3 id="linear-operations-what-bottlenecks-us">线性操作：瓶颈何在？</h3> <p>我们所有的线性操作在概念上都是相同的，无论它们位于 MLP 块还是注意力模块中。它们的算术强度取决于批量大小。我们在<a href="roofline.html">第 1 节</a>中做过这个数学计算，但值得重复一遍。让我们看一个 <d-math>\text{bf16[B, D]}</d-math> 批次与一个 <d-math>\text{bf16[D, F]}</d-math> 矩阵的单次矩阵乘法。这可能是大的 MLP 块（<d-math>W_\text{in}</d-math> 或 <d-math>W_\text{out}</d-math>）或较小的注意力投影之一（<d-math>W_Q</d-math>, <d-math>W_K</d-math>, <d-math>W_V</d-math>, <d-math>W_O</d-math>）。要进行这次矩阵乘法，我们需要将这两个数组从 HBM 加载到 MXU 中，进行乘法运算，然后将结果写回 HBM。和之前一样，我们有：</p><span> <mjx-container class="MathJax CtxtMenu_Attached_0" ctxtmenu_counter="7" display="true" jax="CHTML" style="font-size: 116.9%; position: relative;" tabindex="0"><mjx-math aria-hidden="true" class="MJX-TEX" display="true" style="margin-left: 0px; margin-right: 0px;"><mjx-msub><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D447 TEX-I"></mjx-c></mjx-mi><mjx-script style="vertical-align: -0.15em; margin-left: -0.12em;"><mjx-mtext class="mjx-n" size="s"><mjx-c class="mjx-c6D"></mjx-c><mjx-c class="mjx-c61"></mjx-c><mjx-c class="mjx-c74"></mjx-c><mjx-c class="mjx-c68"></mjx-c></mjx-mtext></mjx-script></mjx-msub><mjx-mo class="mjx-n" space="4"><mjx-c class="mjx-c3D"></mjx-c></mjx-mo><mjx-mfrac space="4"><mjx-frac type="d"><mjx-num><mjx-nstrut type="d"></mjx-nstrut><mjx-mtext class="mjx-n"><mjx-c class="mjx-c43"></mjx-c><mjx-c class="mjx-c6F"></mjx-c><mjx-c class="mjx-c6D"></mjx-c><mjx-c class="mjx-c70"></mjx-c><mjx-c class="mjx-c75"></mjx-c><mjx-c class="mjx-c74"></mjx-c><mjx-c class="mjx-c61"></mjx-c><mjx-c class="mjx-c74"></mjx-c><mjx-c class="mjx-c69"></mjx-c><mjx-c class="mjx-c6F"></mjx-c><mjx-c class="mjx-c6E"></mjx-c><mjx-c class="mjx-c20"></mjx-c><mjx-c class="mjx-c46"></mjx-c><mjx-c class="mjx-c4C"></mjx-c><mjx-c class="mjx-c4F"></mjx-c><mjx-c class="mjx-c50"></mjx-c><mjx-c class="mjx-c73"></mjx-c></mjx-mtext></mjx-num><mjx-dbox><mjx-dtable><mjx-line type="d"></mjx-line><mjx-row><mjx-den><mjx-dstrut type="d"></mjx-dstrut><mjx-mtext class="mjx-n"><mjx-c class="mjx-c41"></mjx-c><mjx-c class="mjx-c63"></mjx-c><mjx-c class="mjx-c63"></mjx-c><mjx-c class="mjx-c65"></mjx-c><mjx-c class="mjx-c6C"></mjx-c><mjx-c class="mjx-c65"></mjx-c><mjx-c class="mjx-c72"></mjx-c><mjx-c class="mjx-c61"></mjx-c><mjx-c class="mjx-c74"></mjx-c><mjx-c class="mjx-c6F"></mjx-c><mjx-c class="mjx-c72"></mjx-c><mjx-c class="mjx-c20"></mjx-c><mjx-c class="mjx-c46"></mjx-c><mjx-c class="mjx-c4C"></mjx-c><mjx-c class="mjx-c4F"></mjx-c><mjx-c class="mjx-c50"></mjx-c><mjx-c class="mjx-c73"></mjx-c><mjx-c class="mjx-c2F"></mjx-c><mjx-c class="mjx-c73"></mjx-c></mjx-mtext></mjx-den></mjx-row></mjx-dtable></mjx-dbox></mjx-frac></mjx-mfrac><mjx-mo class="mjx-n" space="4"><mjx-c class="mjx-c3D"></mjx-c></mjx-mo><mjx-mfrac space="4"><mjx-frac type="d"><mjx-num><mjx-nstrut type="d"></mjx-nstrut><mjx-mrow><mjx-mn class="mjx-n"><mjx-c class="mjx-c32"></mjx-c></mjx-mn><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D435 TEX-I"></mjx-c></mjx-mi><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D437 TEX-I"></mjx-c></mjx-mi><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D439 TEX-I"></mjx-c></mjx-mi></mjx-mrow></mjx-num><mjx-dbox><mjx-dtable><mjx-line type="d"></mjx-line><mjx-row><mjx-den><mjx-dstrut type="d"></mjx-dstrut><mjx-mtext class="mjx-n"><mjx-c class="mjx-c41"></mjx-c><mjx-c class="mjx-c63"></mjx-c><mjx-c class="mjx-c63"></mjx-c><mjx-c class="mjx-c65"></mjx-c><mjx-c class="mjx-c6C"></mjx-c><mjx-c class="mjx-c65"></mjx-c><mjx-c class="mjx-c72"></mjx-c><mjx-c class="mjx-c61"></mjx-c><mjx-c class="mjx-c74"></mjx-c><mjx-c class="mjx-c6F"></mjx-c><mjx-c class="mjx-c72"></mjx-c><mjx-c class="mjx-c20"></mjx-c><mjx-c class="mjx-c46"></mjx-c><mjx-c class="mjx-c4C"></mjx-c><mjx-c class="mjx-c4F"></mjx-c><mjx-c class="mjx-c50"></mjx-c><mjx-c class="mjx-c73"></mjx-c><mjx-c class="mjx-c2F"></mjx-c><mjx-c class="mjx-c73"></mjx-c></mjx-mtext></mjx-den></mjx-row></mjx-dtable></mjx-dbox></mjx-frac></mjx-mfrac></mjx-math><mjx-assistive-mml display="block" unselectable="on"><math display="block" xmlns="http://www.w3.org/1998/Math/MathML"><msub><mi>T</mi><mtext>math</mtext></msub><mo>=</mo><mfrac><mtext>Computation FLOPs</mtext><mtext>Accelerator FLOPs/s</mtext></mfrac><mo>=</mo><mfrac><mrow><mn>2</mn><mi>B</mi><mi>D</mi><mi>F</mi></mrow><mtext>Accelerator FLOPs/s</mtext></mfrac></math></mjx-assistive-mml></mjx-container> <mjx-container class="MathJax CtxtMenu_Attached_0" ctxtmenu_counter="8" display="true" jax="CHTML" style="font-size: 116.9%; position: relative;" tabindex="0"><mjx-math aria-hidden="true" class="MJX-TEX" display="true" style="margin-left: 0px; margin-right: 0px;"><mjx-msub><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D447 TEX-I"></mjx-c></mjx-mi><mjx-script style="vertical-align: -0.15em; margin-left: -0.12em;"><mjx-mtext class="mjx-n" size="s"><mjx-c class="mjx-c63"></mjx-c><mjx-c class="mjx-c6F"></mjx-c><mjx-c class="mjx-c6D"></mjx-c><mjx-c class="mjx-c6D"></mjx-c><mjx-c class="mjx-c73"></mjx-c></mjx-mtext></mjx-script></mjx-msub><mjx-mo class="mjx-n" space="4"><mjx-c class="mjx-c3D"></mjx-c></mjx-mo><mjx-mfrac space="4"><mjx-frac type="d"><mjx-num><mjx-nstrut type="d"></mjx-nstrut><mjx-mtext class="mjx-n"><mjx-c class="mjx-c43"></mjx-c><mjx-c class="mjx-c6F"></mjx-c><mjx-c class="mjx-c6D"></mjx-c><mjx-c class="mjx-c6D"></mjx-c><mjx-c class="mjx-c75"></mjx-c><mjx-c class="mjx-c6E"></mjx-c><mjx-c class="mjx-c69"></mjx-c><mjx-c class="mjx-c63"></mjx-c><mjx-c class="mjx-c61"></mjx-c><mjx-c class="mjx-c74"></mjx-c><mjx-c class="mjx-c69"></mjx-c><mjx-c class="mjx-c6F"></mjx-c><mjx-c class="mjx-c6E"></mjx-c><mjx-c class="mjx-c20"></mjx-c><mjx-c class="mjx-c42"></mjx-c><mjx-c class="mjx-c79"></mjx-c><mjx-c class="mjx-c74"></mjx-c><mjx-c class="mjx-c65"></mjx-c><mjx-c class="mjx-c73"></mjx-c></mjx-mtext></mjx-num><mjx-dbox><mjx-dtable><mjx-line type="d"></mjx-line><mjx-row><mjx-den><mjx-dstrut type="d"></mjx-dstrut><mjx-mtext class="mjx-n"><mjx-c class="mjx-c42"></mjx-c><mjx-c class="mjx-c61"></mjx-c><mjx-c class="mjx-c6E"></mjx-c><mjx-c class="mjx-c64"></mjx-c><mjx-c class="mjx-c77"></mjx-c><mjx-c class="mjx-c69"></mjx-c><mjx-c class="mjx-c64"></mjx-c><mjx-c class="mjx-c74"></mjx-c><mjx-c class="mjx-c68"></mjx-c><mjx-c class="mjx-c20"></mjx-c><mjx-c class="mjx-c42"></mjx-c><mjx-c class="mjx-c79"></mjx-c><mjx-c class="mjx-c74"></mjx-c><mjx-c class="mjx-c65"></mjx-c><mjx-c class="mjx-c73"></mjx-c><mjx-c class="mjx-c2F"></mjx-c><mjx-c class="mjx-c73"></mjx-c></mjx-mtext></mjx-den></mjx-row></mjx-dtable></mjx-dbox></mjx-frac></mjx-mfrac><mjx-mo class="mjx-n" space="4"><mjx-c class="mjx-c3D"></mjx-c></mjx-mo><mjx-mfrac space="4"><mjx-frac type="d"><mjx-num><mjx-nstrut type="d"></mjx-nstrut><mjx-mrow><mjx-mn class="mjx-n"><mjx-c class="mjx-c32"></mjx-c></mjx-mn><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D435 TEX-I"></mjx-c></mjx-mi><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D437 TEX-I"></mjx-c></mjx-mi><mjx-mo class="mjx-n" space="3"><mjx-c class="mjx-c2B"></mjx-c></mjx-mo><mjx-mn class="mjx-n" space="3"><mjx-c class="mjx-c32"></mjx-c></mjx-mn><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D439 TEX-I"></mjx-c></mjx-mi><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D437 TEX-I"></mjx-c></mjx-mi><mjx-mo class="mjx-n" space="3"><mjx-c class="mjx-c2B"></mjx-c></mjx-mo><mjx-mn class="mjx-n" space="3"><mjx-c class="mjx-c32"></mjx-c></mjx-mn><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D435 TEX-I"></mjx-c></mjx-mi><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D439 TEX-I"></mjx-c></mjx-mi></mjx-mrow></mjx-num><mjx-dbox><mjx-dtable><mjx-line type="d"></mjx-line><mjx-row><mjx-den><mjx-dstrut type="d"></mjx-dstrut><mjx-mtext class="mjx-n"><mjx-c class="mjx-c42"></mjx-c><mjx-c class="mjx-c61"></mjx-c><mjx-c class="mjx-c6E"></mjx-c><mjx-c class="mjx-c64"></mjx-c><mjx-c class="mjx-c77"></mjx-c><mjx-c class="mjx-c69"></mjx-c><mjx-c class="mjx-c64"></mjx-c><mjx-c class="mjx-c74"></mjx-c><mjx-c class="mjx-c68"></mjx-c><mjx-c class="mjx-c20"></mjx-c><mjx-c class="mjx-c42"></mjx-c><mjx-c class="mjx-c79"></mjx-c><mjx-c class="mjx-c74"></mjx-c><mjx-c class="mjx-c65"></mjx-c><mjx-c class="mjx-c73"></mjx-c><mjx-c class="mjx-c2F"></mjx-c><mjx-c class="mjx-c73"></mjx-c></mjx-mtext></mjx-den></mjx-row></mjx-dtable></mjx-dbox></mjx-frac></mjx-mfrac></mjx-math><mjx-assistive-mml display="block" unselectable="on"><math display="block" xmlns="http://www.w3.org/1998/Math/MathML"><msub><mi>T</mi><mtext>comms</mtext></msub><mo>=</mo><mfrac><mtext>Communication Bytes</mtext><mtext>Bandwidth Bytes/s</mtext></mfrac><mo>=</mo><mfrac><mrow><mn>2</mn><mi>B</mi><mi>D</mi><mo>+</mo><mn>2</mn><mi>F</mi><mi>D</mi><mo>+</mo><mn>2</mn><mi>B</mi><mi>F</mi></mrow><mtext>Bandwidth Bytes/s</mtext></mfrac></math></mjx-assistive-mml></mjx-container> </span><p>TPU 或 GPU 可以在进行计算的同时加载数据，从而重叠这些操作，因此要达到计算密集型，我们需要 <mjx-container class="MathJax CtxtMenu_Attached_0" ctxtmenu_counter="9" jax="CHTML" style="font-size: 116.9%; position: relative;" tabindex="0"><mjx-math aria-hidden="true" class="MJX-TEX"><mjx-msub><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D447 TEX-I"></mjx-c></mjx-mi><mjx-script style="vertical-align: -0.15em; margin-left: -0.12em;"><mjx-mtext class="mjx-n" size="s"><mjx-c class="mjx-c6D"></mjx-c><mjx-c class="mjx-c61"></mjx-c><mjx-c class="mjx-c74"></mjx-c><mjx-c class="mjx-c68"></mjx-c></mjx-mtext></mjx-script></mjx-msub><mjx-mo class="mjx-n" space="4"><mjx-c class="mjx-c2265"></mjx-c></mjx-mo><mjx-msub space="4"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D447 TEX-I"></mjx-c></mjx-mi><mjx-script style="vertical-align: -0.15em; margin-left: -0.12em;"><mjx-mtext class="mjx-n" size="s"><mjx-c class="mjx-c63"></mjx-c><mjx-c class="mjx-c6F"></mjx-c><mjx-c class="mjx-c6D"></mjx-c><mjx-c class="mjx-c6D"></mjx-c><mjx-c class="mjx-c73"></mjx-c></mjx-mtext></mjx-script></mjx-msub></mjx-math><mjx-assistive-mml display="inline" unselectable="on"><math xmlns="http://www.w3.org/1998/Math/MathML"><msub><mi>T</mi><mtext>math</mtext></msub><mo>≥</mo><msub><mi>T</mi><mtext>comms</mtext></msub></math></mjx-assistive-mml></mjx-container>，或者：</p><span> <mjx-container class="MathJax CtxtMenu_Attached_0" ctxtmenu_counter="10" display="true" jax="CHTML" style="font-size: 116.9%; position: relative;" tabindex="0"><mjx-math aria-hidden="true" class="MJX-TEX" display="true" style="margin-left: 0px; margin-right: 0px;"><mjx-mfrac><mjx-frac type="d"><mjx-num><mjx-nstrut type="d"></mjx-nstrut><mjx-mrow><mjx-mn class="mjx-n"><mjx-c class="mjx-c32"></mjx-c></mjx-mn><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D435 TEX-I"></mjx-c></mjx-mi><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D437 TEX-I"></mjx-c></mjx-mi><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D439 TEX-I"></mjx-c></mjx-mi></mjx-mrow></mjx-num><mjx-dbox><mjx-dtable><mjx-line type="d"></mjx-line><mjx-row><mjx-den><mjx-dstrut type="d"></mjx-dstrut><mjx-mrow><mjx-mn class="mjx-n"><mjx-c class="mjx-c32"></mjx-c></mjx-mn><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D435 TEX-I"></mjx-c></mjx-mi><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D437 TEX-I"></mjx-c></mjx-mi><mjx-mo class="mjx-n" space="3"><mjx-c class="mjx-c2B"></mjx-c></mjx-mo><mjx-mn class="mjx-n" space="3"><mjx-c class="mjx-c32"></mjx-c></mjx-mn><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D437 TEX-I"></mjx-c></mjx-mi><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D439 TEX-I"></mjx-c></mjx-mi><mjx-mo class="mjx-n" space="3"><mjx-c class="mjx-c2B"></mjx-c></mjx-mo><mjx-mn class="mjx-n" space="3"><mjx-c class="mjx-c32"></mjx-c></mjx-mn><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D435 TEX-I"></mjx-c></mjx-mi><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D439 TEX-I"></mjx-c></mjx-mi></mjx-mrow></mjx-den></mjx-row></mjx-dtable></mjx-dbox></mjx-frac></mjx-mfrac><mjx-mo class="mjx-n" space="4"><mjx-c class="mjx-c2265"></mjx-c></mjx-mo><mjx-mfrac space="4"><mjx-frac type="d"><mjx-num><mjx-nstrut type="d"></mjx-nstrut><mjx-mtext class="mjx-n"><mjx-c class="mjx-c41"></mjx-c><mjx-c class="mjx-c63"></mjx-c><mjx-c class="mjx-c63"></mjx-c><mjx-c class="mjx-c65"></mjx-c><mjx-c class="mjx-c6C"></mjx-c><mjx-c class="mjx-c65"></mjx-c><mjx-c class="mjx-c72"></mjx-c><mjx-c class="mjx-c61"></mjx-c><mjx-c class="mjx-c74"></mjx-c><mjx-c class="mjx-c6F"></mjx-c><mjx-c class="mjx-c72"></mjx-c><mjx-c class="mjx-c20"></mjx-c><mjx-c class="mjx-c46"></mjx-c><mjx-c class="mjx-c4C"></mjx-c><mjx-c class="mjx-c4F"></mjx-c><mjx-c class="mjx-c50"></mjx-c><mjx-c class="mjx-c73"></mjx-c><mjx-c class="mjx-c2F"></mjx-c><mjx-c class="mjx-c73"></mjx-c></mjx-mtext></mjx-num><mjx-dbox><mjx-dtable><mjx-line type="d"></mjx-line><mjx-row><mjx-den><mjx-dstrut type="d"></mjx-dstrut><mjx-mtext class="mjx-n"><mjx-c class="mjx-c42"></mjx-c><mjx-c class="mjx-c61"></mjx-c><mjx-c class="mjx-c6E"></mjx-c><mjx-c class="mjx-c64"></mjx-c><mjx-c class="mjx-c77"></mjx-c><mjx-c class="mjx-c69"></mjx-c><mjx-c class="mjx-c64"></mjx-c><mjx-c class="mjx-c74"></mjx-c><mjx-c class="mjx-c68"></mjx-c><mjx-c class="mjx-c20"></mjx-c><mjx-c class="mjx-c42"></mjx-c><mjx-c class="mjx-c79"></mjx-c><mjx-c class="mjx-c74"></mjx-c><mjx-c class="mjx-c65"></mjx-c><mjx-c class="mjx-c73"></mjx-c><mjx-c class="mjx-c2F"></mjx-c><mjx-c class="mjx-c73"></mjx-c></mjx-mtext></mjx-den></mjx-row></mjx-dtable></mjx-dbox></mjx-frac></mjx-mfrac><mjx-munder space="4"><mjx-row><mjx-base style="padding-left: 0.981em;"><mjx-mo class="mjx-n"><mjx-c class="mjx-c3D"></mjx-c></mjx-mo></mjx-base></mjx-row><mjx-row><mjx-under style="padding-top: 0.167em;"><mjx-mtext class="mjx-n" size="s"><mjx-c class="mjx-c54"></mjx-c><mjx-c class="mjx-c50"></mjx-c><mjx-c class="mjx-c55"></mjx-c><mjx-c class="mjx-c20"></mjx-c><mjx-c class="mjx-c76"></mjx-c><mjx-c class="mjx-c35"></mjx-c><mjx-c class="mjx-c65"></mjx-c></mjx-mtext></mjx-under></mjx-row></mjx-munder><mjx-mfrac space="4"><mjx-frac type="d"><mjx-num><mjx-nstrut type="d"></mjx-nstrut><mjx-mrow><mjx-mn class="mjx-n"><mjx-c class="mjx-c31"></mjx-c><mjx-c class="mjx-c2E"></mjx-c><mjx-c class="mjx-c39"></mjx-c><mjx-c class="mjx-c37"></mjx-c></mjx-mn><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D438 TEX-I"></mjx-c></mjx-mi><mjx-mo class="mjx-n" space="3"><mjx-c class="mjx-c2B"></mjx-c></mjx-mo><mjx-mn class="mjx-n" space="3"><mjx-c class="mjx-c31"></mjx-c><mjx-c class="mjx-c34"></mjx-c></mjx-mn></mjx-mrow></mjx-num><mjx-dbox><mjx-dtable><mjx-line type="d"></mjx-line><mjx-row><mjx-den><mjx-dstrut type="d"></mjx-dstrut><mjx-mrow><mjx-mn class="mjx-n"><mjx-c class="mjx-c38"></mjx-c><mjx-c class="mjx-c2E"></mjx-c><mjx-c class="mjx-c32"></mjx-c><mjx-c class="mjx-c30"></mjx-c></mjx-mn><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D438 TEX-I"></mjx-c></mjx-mi><mjx-mo class="mjx-n" space="3"><mjx-c class="mjx-c2B"></mjx-c></mjx-mo><mjx-mn class="mjx-n" space="3"><mjx-c class="mjx-c31"></mjx-c><mjx-c class="mjx-c31"></mjx-c></mjx-mn></mjx-mrow></mjx-den></mjx-row></mjx-dtable></mjx-dbox></mjx-frac></mjx-mfrac><mjx-mo class="mjx-n" space="4"><mjx-c class="mjx-c3D"></mjx-c></mjx-mo><mjx-mn class="mjx-n" space="4"><mjx-c class="mjx-c32"></mjx-c><mjx-c class="mjx-c34"></mjx-c><mjx-c class="mjx-c30"></mjx-c></mjx-mn></mjx-math><mjx-assistive-mml display="block" unselectable="on"><math display="block" xmlns="http://www.w3.org/1998/Math/MathML"><mfrac><mrow><mn>2</mn><mi>B</mi><mi>D</mi><mi>F</mi></mrow><mrow><mn>2</mn><mi>B</mi><mi>D</mi><mo>+</mo><mn>2</mn><mi>D</mi><mi>F</mi><mo>+</mo><mn>2</mn><mi>B</mi><mi>F</mi></mrow></mfrac><mo>≥</mo><mfrac><mtext>Accelerator FLOPs/s</mtext><mtext>Bandwidth Bytes/s</mtext></mfrac><munder><mo>=</mo><mtext>TPU v5e</mtext></munder><mfrac><mrow><mn>1.97</mn><mi>E</mi><mo>+</mo><mn>14</mn></mrow><mrow><mn>8.20</mn><mi>E</mi><mo>+</mo><mn>11</mn></mrow></mfrac><mo>=</mo><mn>240</mn></math></mjx-assistive-mml></mjx-container> </span><p>其中右侧是我们硬件的算术强度。现在让我们假设 <d-math>D</d-math> 和 <d-math>F</d-math> 与 <d-math>B</d-math> 相比非常大（通常我们的批次最多为 500，且 <d-math>D</d-math> 和 <d-math>F &gt; 10k</d-math>），我们可以通过 <d-math>\small{2BD + 2DF + 2BF \approxeq 2DF}</d-math> 这个事实来简化分母，从而得到</p><span> <mjx-container class="MathJax CtxtMenu_Attached_0" ctxtmenu_counter="11" display="true" jax="CHTML" style="font-size: 116.9%; position: relative;" tabindex="0"><mjx-math aria-hidden="true" class="MJX-TEX" display="true" style="margin-left: 0px; margin-right: 0px;"><mjx-mtable style="min-width: 24.692em;"><mjx-table><mjx-itable><mjx-mtr><mjx-mtd style="text-align: right; padding-bottom: 0.15em;"><mjx-mfrac><mjx-frac type="d"><mjx-num><mjx-nstrut type="d"></mjx-nstrut><mjx-mrow><mjx-mn class="mjx-n"><mjx-c class="mjx-c32"></mjx-c></mjx-mn><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D435 TEX-I"></mjx-c></mjx-mi><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D437 TEX-I"></mjx-c></mjx-mi><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D439 TEX-I"></mjx-c></mjx-mi></mjx-mrow></mjx-num><mjx-dbox><mjx-dtable><mjx-line type="d"></mjx-line><mjx-row><mjx-den><mjx-dstrut type="d"></mjx-dstrut><mjx-mrow><mjx-mn class="mjx-n"><mjx-c class="mjx-c32"></mjx-c></mjx-mn><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D435 TEX-I"></mjx-c></mjx-mi><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D437 TEX-I"></mjx-c></mjx-mi><mjx-mo class="mjx-n" space="3"><mjx-c class="mjx-c2B"></mjx-c></mjx-mo><mjx-mn class="mjx-n" space="3"><mjx-c class="mjx-c32"></mjx-c></mjx-mn><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D437 TEX-I"></mjx-c></mjx-mi><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D439 TEX-I"></mjx-c></mjx-mi><mjx-mo class="mjx-n" space="3"><mjx-c class="mjx-c2B"></mjx-c></mjx-mo><mjx-mn class="mjx-n" space="3"><mjx-c class="mjx-c32"></mjx-c></mjx-mn><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D435 TEX-I"></mjx-c></mjx-mi><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D439 TEX-I"></mjx-c></mjx-mi></mjx-mrow></mjx-den></mjx-row></mjx-dtable></mjx-dbox></mjx-frac></mjx-mfrac><mjx-mo class="mjx-n" space="4"><mjx-c class="mjx-c224A TEX-A"></mjx-c></mjx-mo><mjx-mfrac space="4"><mjx-frac type="d"><mjx-num><mjx-nstrut type="d"></mjx-nstrut><mjx-mrow><mjx-mn class="mjx-n"><mjx-c class="mjx-c32"></mjx-c></mjx-mn><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D435 TEX-I"></mjx-c></mjx-mi><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D437 TEX-I"></mjx-c></mjx-mi><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D439 TEX-I"></mjx-c></mjx-mi></mjx-mrow></mjx-num><mjx-dbox><mjx-dtable><mjx-line type="d"></mjx-line><mjx-row><mjx-den><mjx-dstrut type="d"></mjx-dstrut><mjx-mrow><mjx-mn class="mjx-n"><mjx-c class="mjx-c32"></mjx-c></mjx-mn><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D437 TEX-I"></mjx-c></mjx-mi><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D439 TEX-I"></mjx-c></mjx-mi></mjx-mrow></mjx-den></mjx-row></mjx-dtable></mjx-dbox></mjx-frac></mjx-mfrac><mjx-mo class="mjx-n" space="4"><mjx-c class="mjx-c2265"></mjx-c></mjx-mo><mjx-mfrac space="4"><mjx-frac type="d"><mjx-num><mjx-nstrut type="d"></mjx-nstrut><mjx-mtext class="mjx-n"><mjx-c class="mjx-c41"></mjx-c><mjx-c class="mjx-c63"></mjx-c><mjx-c class="mjx-c63"></mjx-c><mjx-c class="mjx-c65"></mjx-c><mjx-c class="mjx-c6C"></mjx-c><mjx-c class="mjx-c65"></mjx-c><mjx-c class="mjx-c72"></mjx-c><mjx-c class="mjx-c61"></mjx-c><mjx-c class="mjx-c74"></mjx-c><mjx-c class="mjx-c6F"></mjx-c><mjx-c class="mjx-c72"></mjx-c><mjx-c class="mjx-c20"></mjx-c><mjx-c class="mjx-c46"></mjx-c><mjx-c class="mjx-c4C"></mjx-c><mjx-c class="mjx-c4F"></mjx-c><mjx-c class="mjx-c50"></mjx-c><mjx-c class="mjx-c73"></mjx-c><mjx-c class="mjx-c2F"></mjx-c><mjx-c class="mjx-c73"></mjx-c></mjx-mtext></mjx-num><mjx-dbox><mjx-dtable><mjx-line type="d"></mjx-line><mjx-row><mjx-den><mjx-dstrut type="d"></mjx-dstrut><mjx-mtext class="mjx-n"><mjx-c class="mjx-c42"></mjx-c><mjx-c class="mjx-c61"></mjx-c><mjx-c class="mjx-c6E"></mjx-c><mjx-c class="mjx-c64"></mjx-c><mjx-c class="mjx-c77"></mjx-c><mjx-c class="mjx-c69"></mjx-c><mjx-c class="mjx-c64"></mjx-c><mjx-c class="mjx-c74"></mjx-c><mjx-c class="mjx-c68"></mjx-c><mjx-c class="mjx-c20"></mjx-c><mjx-c class="mjx-c42"></mjx-c><mjx-c class="mjx-c79"></mjx-c><mjx-c class="mjx-c74"></mjx-c><mjx-c class="mjx-c65"></mjx-c><mjx-c class="mjx-c73"></mjx-c><mjx-c class="mjx-c2F"></mjx-c><mjx-c class="mjx-c73"></mjx-c></mjx-mtext></mjx-den></mjx-row></mjx-dtable></mjx-dbox></mjx-frac></mjx-mfrac><mjx-tstrut></mjx-tstrut></mjx-mtd></mjx-mtr><mjx-mtr><mjx-mtd style="text-align: right; padding-top: 0.15em;"><mjx-munder><mjx-row><mjx-base style="padding-left: 0.981em;"><mjx-mo class="mjx-n"><mjx-c class="mjx-c3D"></mjx-c></mjx-mo></mjx-base></mjx-row><mjx-row><mjx-under style="padding-top: 0.167em;"><mjx-mtext class="mjx-n" size="s"><mjx-c class="mjx-c54"></mjx-c><mjx-c class="mjx-c50"></mjx-c><mjx-c class="mjx-c55"></mjx-c><mjx-c class="mjx-c20"></mjx-c><mjx-c class="mjx-c76"></mjx-c><mjx-c class="mjx-c35"></mjx-c><mjx-c class="mjx-c65"></mjx-c></mjx-mtext></mjx-under></mjx-row></mjx-munder><mjx-mfrac space="4"><mjx-frac type="d"><mjx-num><mjx-nstrut type="d"></mjx-nstrut><mjx-mrow><mjx-mn class="mjx-n"><mjx-c class="mjx-c31"></mjx-c><mjx-c class="mjx-c2E"></mjx-c><mjx-c class="mjx-c39"></mjx-c><mjx-c class="mjx-c37"></mjx-c></mjx-mn><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D438 TEX-I"></mjx-c></mjx-mi><mjx-mo class="mjx-n" space="3"><mjx-c class="mjx-c2B"></mjx-c></mjx-mo><mjx-mn class="mjx-n" space="3"><mjx-c class="mjx-c31"></mjx-c><mjx-c class="mjx-c34"></mjx-c></mjx-mn></mjx-mrow></mjx-num><mjx-dbox><mjx-dtable><mjx-line type="d"></mjx-line><mjx-row><mjx-den><mjx-dstrut type="d"></mjx-dstrut><mjx-mrow><mjx-mn class="mjx-n"><mjx-c class="mjx-c38"></mjx-c><mjx-c class="mjx-c2E"></mjx-c><mjx-c class="mjx-c32"></mjx-c><mjx-c class="mjx-c30"></mjx-c></mjx-mn><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D438 TEX-I"></mjx-c></mjx-mi><mjx-mo class="mjx-n" space="3"><mjx-c class="mjx-c2B"></mjx-c></mjx-mo><mjx-mn class="mjx-n" space="3"><mjx-c class="mjx-c31"></mjx-c><mjx-c class="mjx-c31"></mjx-c></mjx-mn></mjx-mrow></mjx-den></mjx-row></mjx-dtable></mjx-dbox></mjx-frac></mjx-mfrac><mjx-mstyle><mjx-mspace style="width: 0.278em;"></mjx-mspace></mjx-mstyle><mjx-mo class="mjx-n" space="4"><mjx-c class="mjx-c27F9"></mjx-c></mjx-mo><mjx-mstyle><mjx-mspace style="width: 0.278em;"></mjx-mspace></mjx-mstyle><mjx-mi class="mjx-i" space="4"><mjx-c class="mjx-c1D435 TEX-I"></mjx-c></mjx-mi><mjx-mo class="mjx-n" space="4"><mjx-c class="mjx-c2265"></mjx-c></mjx-mo><mjx-mn class="mjx-n" space="4"><mjx-c class="mjx-c32"></mjx-c><mjx-c class="mjx-c34"></mjx-c><mjx-c class="mjx-c30"></mjx-c></mjx-mn><mjx-mo class="mjx-n" space="4"><mjx-c class="mjx-c3D"></mjx-c></mjx-mo><mjx-msub space="4"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D435 TEX-I"></mjx-c></mjx-mi><mjx-script style="vertical-align: -0.15em;"><mjx-texatom size="s" texclass="ORD"><mjx-mtext class="mjx-n"><mjx-c class="mjx-c63"></mjx-c><mjx-c class="mjx-c72"></mjx-c><mjx-c class="mjx-c69"></mjx-c><mjx-c class="mjx-c74"></mjx-c></mjx-mtext></mjx-texatom></mjx-script></mjx-msub><mjx-tstrut></mjx-tstrut></mjx-mtd></mjx-mtr></mjx-itable></mjx-table></mjx-mtable></mjx-math><mjx-assistive-mml display="block" unselectable="on"><math display="block" xmlns="http://www.w3.org/1998/Math/MathML"><mtable columnalign="right" columnspacing="" displaystyle="true" rowspacing="3pt"><mtr><mtd><mfrac><mrow><mn>2</mn><mi>B</mi><mi>D</mi><mi>F</mi></mrow><mrow><mn>2</mn><mi>B</mi><mi>D</mi><mo>+</mo><mn>2</mn><mi>D</mi><mi>F</mi><mo>+</mo><mn>2</mn><mi>B</mi><mi>F</mi></mrow></mfrac><mo>≊</mo><mfrac><mrow><mn>2</mn><mi>B</mi><mi>D</mi><mi>F</mi></mrow><mrow><mn>2</mn><mi>D</mi><mi>F</mi></mrow></mfrac><mo>≥</mo><mfrac><mtext>Accelerator FLOPs/s</mtext><mtext>Bandwidth Bytes/s</mtext></mfrac></mtd></mtr><mtr><mtd><munder><mo>=</mo><mtext>TPU v5e</mtext></munder><mfrac><mrow><mn>1.97</mn><mi>E</mi><mo>+</mo><mn>14</mn></mrow><mrow><mn>8.20</mn><mi>E</mi><mo>+</mo><mn>11</mn></mrow></mfrac><mstyle scriptlevel="0"><mspace width="0.278em"></mspace></mstyle><mo stretchy="false">⟹</mo><mstyle scriptlevel="0"><mspace width="0.278em"></mspace></mstyle><mi>B</mi><mo>≥</mo><mn>240</mn><mo>=</mo><msub><mi>B</mi><mrow data-mjx-texclass="ORD"><mtext>crit</mtext></mrow></msub></mtd></mtr></mtable></math></mjx-assistive-mml></mjx-container> </span><p>如果我们对权重进行量化，或使用较低精度的 FLOPs 进行矩阵乘法，这个临界批量大小会发生变化。例如，如果我们将权重化为 int8 或 fp8，<d-math>B_\text{crit}</d-math> 会减少 2 倍。如果我们在 int8 或 fp8 中进行 FLOPs 计算，<d-math>B_\text{crit}</d-math> 会增加 2 倍。因此，如果我们设 <d-math>\beta = \text{bits per param} / \text{bits per activation}</d-math> 且 <d-math>\alpha_\text{hbm} = C / W_\text{hbm}</d-math>，我们的临界批量大小实际上是 <d-math>B_\text{crit} = \beta \alpha_\text{hbm}</d-math>。</p> <p class="takeaway"><strong>要点：</strong> Transformer 矩阵乘法是计算密集型的，<em>当且仅当</em>每个副本的<strong>词元</strong>批量大小大于 <d-math>B_\text{crit} = C / W_\text{hbm} \cdot (\text{bits per param} / \text{bits per activation}) = \beta \cdot \alpha_\text{hbm}</d-math>。对于 TPU v5e 上的 bf16 激活，这个值是 240 个词元。对于 H100，大约是 280 个词元。</p> <p>在训练期间，我们所有的矩阵乘法都具有高强度，因为我们在一个非常大的批次上重用相同的权重。<strong>这种高算术强度也延续到了预填充阶段，因为用户提示通常有数百甚至数千个词元长。</strong> 正如我们之前看到的，TPUv5e 的硬件算术强度是 240，所以如果一个长于 240 个词元的序列以 bf16 精度输入到运行在此硬件上的密集模型中，我们预计会是计算密集型的，一切正常。比这更短的提示理论上可以批处理在一起以实现更高的利用率，但这通常没有必要。</p> <p class="takeaway"><strong>要点：</strong> 在预填充期间，所有矩阵乘法基本上总是计算密集型的。因此，只需最大化硬件利用率或 MFU（模型 FLOPs 利用率）就足以最大化每芯片吞吐量（成本）和延迟（以 TTFT 的形式）。除非提示非常短，否则在每个提示级别进行批处理只会增加延迟，而对预填充吞吐量的提升很小。</p> <p>然而，在生成期间，对于每个请求，我们一次只能进行一个词元的正向传播，因为步骤之间存在顺序依赖！因此，我们只能（容易地）通过将多个请求批处理在一起，在批次维度上并行化，来实现良好的利用率。我们稍后会更多地讨论这一点，但实际上，在不影响延迟的情况下将许多并发请求批处理在一起是很困难的。因此，<strong>用生成来饱和硬件的 FLOPs 要困难得多。</strong></p> <p class="takeaway"><strong>要点：</strong> 在生成期间，总词元批量大小必须大于 <d-math>B_{\text{crit}}</d-math>，才能在线性/前馈操作上达到计算密集型（对于 TPU v5e 上的 bf16 参数，该值为 240）。因为生成是串行地、逐词元进行的，这要求我们将多个请求批处理在一起，这很困难！</p> <p><em>值得注意的是这个数字有多大！</em> 生成批量大小为 240 意味着 240 个并发请求同时生成，对于密集模型来说，需要 240 个独立的 KV 缓存。这意味着在实践中很难实现，除非在某些批量推理场景中。相比之下，在预填充期间处理超过 240 个词元是相当常规的，尽管随着稀疏性的增加需要一些注意。</p> <p><strong>请注意，这个确切的数字会因量化类型和硬件而异。</strong> 加速器通常可以在较低精度下提供更多的算力。例如，如果我们有 int8 参数但在 bf16 中进行计算，临界批量大小会降至 120。使用 int8 激活和 int8 参数，它又会跳回到 240，因为 TPUv5e 可以提供 400 TOPs/s 的 int8 x int8 算力。</p> <h3 id="what-about-attention">注意力机制呢？</h3> <p>当我们审视点积注意力操作时，事情变得更加复杂，特别是我们必须考虑 KV 缓存。让我们只看一个具有纯多头注意力的注意力头。在一次 Flash Attention 融合中，我们<d-footnote id="d-footnote-3">我们在这里做了相当多的简化，忽略了应用 softmax、掩码等操作中的非矩阵乘法 FLOPs。它们应该与计算或 HBM 读取重叠，但在某些 TPU 代上实现起来可能不简单。这些细节不会改变主要信息，即 KV 缓存通常是受内存限制的。</d-footnote>：</p> <ol> <li>从 HBM 读取形状为 <d-math>Q</d-math> 的 <d-math>\text{bf16[B, T, D]}</d-math> 激活。</li> <li>从 HBM 读取 <d-math>KV</d-math> 缓存，它是一对 <d-math>\text{bf16[B, S, D]}</d-math> 张量。</li> <li>在 <mjx-container class="MathJax CtxtMenu_Attached_0" ctxtmenu_counter="12" jax="CHTML" style="font-size: 116.9%; position: relative;" tabindex="0"><mjx-math aria-hidden="true" class="MJX-TEX"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D444 TEX-I"></mjx-c></mjx-mi><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D43E TEX-I"></mjx-c></mjx-mi></mjx-math><mjx-assistive-mml display="inline" unselectable="on"><math xmlns="http://www.w3.org/1998/Math/MathML"><mi>Q</mi><mi>K</mi></math></mjx-assistive-mml></mjx-container> 矩阵乘法中执行 <d-math>2BSTD</d-math> FLOPs。使用 Flash Attention，我们不需要将 <d-math>\text{bf16[B, S, T]}</d-math> 注意力矩阵写回 HBM。</li> <li>在注意力 <mjx-container class="MathJax CtxtMenu_Attached_0" ctxtmenu_counter="13" jax="CHTML" style="font-size: 116.9%; position: relative;" tabindex="0"><mjx-math aria-hidden="true" class="MJX-TEX"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D434 TEX-I"></mjx-c></mjx-mi><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D449 TEX-I"></mjx-c></mjx-mi></mjx-math><mjx-assistive-mml display="inline" unselectable="on"><math xmlns="http://www.w3.org/1998/Math/MathML"><mi>A</mi><mi>V</mi></math></mjx-assistive-mml></mjx-container> 矩阵乘法中执行 <d-math>2BSTD</d-math>。</li> <li>将得到的 <d-math>\text{bf16[B, T, D]}</d-math> 张量写回 HBM。</li> </ol> <p>综上所述，我们得到：</p><span> <mjx-container class="MathJax CtxtMenu_Attached_0" ctxtmenu_counter="14" display="true" jax="CHTML" style="font-size: 116.9%; position: relative;" tabindex="0"><mjx-math aria-hidden="true" class="MJX-TEX" display="true" style="margin-left: 0px; margin-right: 0px;"><mjx-mtext class="mjx-n"><mjx-c class="mjx-c4D"></mjx-c><mjx-c class="mjx-c75"></mjx-c><mjx-c class="mjx-c6C"></mjx-c><mjx-c class="mjx-c74"></mjx-c><mjx-c class="mjx-c69"></mjx-c><mjx-c class="mjx-c68"></mjx-c><mjx-c class="mjx-c65"></mjx-c><mjx-c class="mjx-c61"></mjx-c><mjx-c class="mjx-c64"></mjx-c><mjx-c class="mjx-c65"></mjx-c><mjx-c class="mjx-c64"></mjx-c><mjx-c class="mjx-c20"></mjx-c><mjx-c class="mjx-c41"></mjx-c><mjx-c class="mjx-c74"></mjx-c><mjx-c class="mjx-c74"></mjx-c><mjx-c class="mjx-c65"></mjx-c><mjx-c class="mjx-c6E"></mjx-c><mjx-c class="mjx-c74"></mjx-c><mjx-c class="mjx-c69"></mjx-c><mjx-c class="mjx-c6F"></mjx-c><mjx-c class="mjx-c6E"></mjx-c><mjx-c class="mjx-c20"></mjx-c><mjx-c class="mjx-c41"></mjx-c><mjx-c class="mjx-c72"></mjx-c><mjx-c class="mjx-c69"></mjx-c><mjx-c class="mjx-c74"></mjx-c><mjx-c class="mjx-c68"></mjx-c><mjx-c class="mjx-c6D"></mjx-c><mjx-c class="mjx-c65"></mjx-c><mjx-c class="mjx-c74"></mjx-c><mjx-c class="mjx-c69"></mjx-c><mjx-c class="mjx-c63"></mjx-c><mjx-c class="mjx-c20"></mjx-c><mjx-c class="mjx-c49"></mjx-c><mjx-c class="mjx-c6E"></mjx-c><mjx-c class="mjx-c74"></mjx-c><mjx-c class="mjx-c65"></mjx-c><mjx-c class="mjx-c6E"></mjx-c><mjx-c class="mjx-c73"></mjx-c><mjx-c class="mjx-c69"></mjx-c><mjx-c class="mjx-c74"></mjx-c><mjx-c class="mjx-c79"></mjx-c></mjx-mtext><mjx-mo class="mjx-n" space="4"><mjx-c class="mjx-c3D"></mjx-c></mjx-mo><mjx-mfrac space="4"><mjx-frac type="d"><mjx-num><mjx-nstrut type="d"></mjx-nstrut><mjx-mrow><mjx-mn class="mjx-n"><mjx-c class="mjx-c34"></mjx-c></mjx-mn><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D435 TEX-I"></mjx-c></mjx-mi><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D446 TEX-I"></mjx-c></mjx-mi><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D447 TEX-I"></mjx-c></mjx-mi><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D437 TEX-I"></mjx-c></mjx-mi></mjx-mrow></mjx-num><mjx-dbox><mjx-dtable><mjx-line type="d"></mjx-line><mjx-row><mjx-den><mjx-dstrut type="d"></mjx-dstrut><mjx-mrow><mjx-mn class="mjx-n"><mjx-c class="mjx-c34"></mjx-c></mjx-mn><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D435 TEX-I"></mjx-c></mjx-mi><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D446 TEX-I"></mjx-c></mjx-mi><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D437 TEX-I"></mjx-c></mjx-mi><mjx-mo class="mjx-n" space="3"><mjx-c class="mjx-c2B"></mjx-c></mjx-mo><mjx-mn class="mjx-n" space="3"><mjx-c class="mjx-c34"></mjx-c></mjx-mn><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D435 TEX-I"></mjx-c></mjx-mi><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D447 TEX-I"></mjx-c></mjx-mi><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D437 TEX-I"></mjx-c></mjx-mi></mjx-mrow></mjx-den></mjx-row></mjx-dtable></mjx-dbox></mjx-frac></mjx-mfrac><mjx-mo class="mjx-n" space="4"><mjx-c class="mjx-c3D"></mjx-c></mjx-mo><mjx-mfrac space="4"><mjx-frac type="d"><mjx-num><mjx-nstrut type="d"></mjx-nstrut><mjx-mrow><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D446 TEX-I"></mjx-c></mjx-mi><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D447 TEX-I"></mjx-c></mjx-mi></mjx-mrow></mjx-num><mjx-dbox><mjx-dtable><mjx-line type="d"></mjx-line><mjx-row><mjx-den><mjx-dstrut type="d"></mjx-dstrut><mjx-mrow><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D446 TEX-I"></mjx-c></mjx-mi><mjx-mo class="mjx-n" space="3"><mjx-c class="mjx-c2B"></mjx-c></mjx-mo><mjx-mi class="mjx-i" space="3"><mjx-c class="mjx-c1D447 TEX-I"></mjx-c></mjx-mi></mjx-mrow></mjx-den></mjx-row></mjx-dtable></mjx-dbox></mjx-frac></mjx-mfrac></mjx-math><mjx-assistive-mml display="block" unselectable="on"><math display="block" xmlns="http://www.w3.org/1998/Math/MathML"><mtext>Multiheaded Attention Arithmetic Intensity</mtext><mo>=</mo><mfrac><mrow><mn>4</mn><mi>B</mi><mi>S</mi><mi>T</mi><mi>D</mi></mrow><mrow><mn>4</mn><mi>B</mi><mi>S</mi><mi>D</mi><mo>+</mo><mn>4</mn><mi>B</mi><mi>T</mi><mi>D</mi></mrow></mfrac><mo>=</mo><mfrac><mrow><mi>S</mi><mi>T</mi></mrow><mrow><mi>S</mi><mo>+</mo><mi>T</mi></mrow></mfrac></math></mjx-assistive-mml></mjx-container> </span><p>对于预填充，<d-math>S=T</d-math> 因为我们正在做自注意力，所以这简化为 <d-math>T^2 / 2T = T / 2</d-math>。这很好，因为这意味着<strong>预填充期间注意力的算术强度是 <d-math>\Theta(T)</d-math></strong>。这意味着注意力很容易达到计算密集型。只要我们的序列长度足够大，就没问题！</p> <p>但是由于生成的序列维度很小，并且 <d-math>B</d-math> 和 <d-math>D</d-math> 维度相互抵消，我们可以做如下近似：</p><span> <mjx-container class="MathJax CtxtMenu_Attached_0" ctxtmenu_counter="15" display="true" jax="CHTML" style="font-size: 116.9%; position: relative;" tabindex="0"><mjx-math aria-hidden="true" class="MJX-TEX" display="true" style="margin-left: 0px; margin-right: 0px;"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D446 TEX-I"></mjx-c></mjx-mi><mjx-mo class="mjx-n" space="4"><mjx-c class="mjx-c226B"></mjx-c></mjx-mo><mjx-mi class="mjx-i" space="4"><mjx-c class="mjx-c1D447 TEX-I"></mjx-c></mjx-mi><mjx-mo class="mjx-n" space="4"><mjx-c class="mjx-c3D"></mjx-c></mjx-mo><mjx-mn class="mjx-n" space="4"><mjx-c class="mjx-c31"></mjx-c></mjx-mn><mjx-mstyle><mjx-mspace style="width: 0.278em;"></mjx-mspace></mjx-mstyle><mjx-mo class="mjx-n" space="4"><mjx-c class="mjx-c27F9"></mjx-c></mjx-mo><mjx-mstyle><mjx-mspace style="width: 0.278em;"></mjx-mspace></mjx-mstyle><mjx-mfrac space="4"><mjx-frac type="d"><mjx-num><mjx-nstrut type="d"></mjx-nstrut><mjx-mrow><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D446 TEX-I"></mjx-c></mjx-mi><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D447 TEX-I"></mjx-c></mjx-mi></mjx-mrow></mjx-num><mjx-dbox><mjx-dtable><mjx-line type="d"></mjx-line><mjx-row><mjx-den><mjx-dstrut type="d"></mjx-dstrut><mjx-mrow><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D446 TEX-I"></mjx-c></mjx-mi><mjx-mo class="mjx-n" space="3"><mjx-c class="mjx-c2B"></mjx-c></mjx-mo><mjx-mi class="mjx-i" space="3"><mjx-c class="mjx-c1D447 TEX-I"></mjx-c></mjx-mi></mjx-mrow></mjx-den></mjx-row></mjx-dtable></mjx-dbox></mjx-frac></mjx-mfrac><mjx-mo class="mjx-n" space="4"><mjx-c class="mjx-c2248"></mjx-c></mjx-mo><mjx-mn class="mjx-n" space="4"><mjx-c class="mjx-c31"></mjx-c></mjx-mn></mjx-math><mjx-assistive-mml display="block" unselectable="on"><math display="block" xmlns="http://www.w3.org/1998/Math/MathML"><mi>S</mi><mo>≫</mo><mi>T</mi><mo>=</mo><mn>1</mn><mstyle scriptlevel="0"><mspace width="0.278em"></mspace></mstyle><mo stretchy="false">⟹</mo><mstyle scriptlevel="0"><mspace width="0.278em"></mspace></mstyle><mfrac><mrow><mi>S</mi><mi>T</mi></mrow><mrow><mi>S</mi><mo>+</mo><mi>T</mi></mrow></mfrac><mo>≈</mo><mn>1</mn></math></mjx-assistive-mml></mjx-container> </span><p>这很糟糕，因为它意味着我们无法做任何事情来提高生成期间注意力的算术强度。我们在加载一个巨大的 KV 缓存的同时，只做了极少量的 FLOPs。<strong>所以我们在注意力计算期间基本上总是受内存带宽限制的！</strong></p> <p class="takeaway"><strong>要点：</strong>在预填充期间，对于任何合理的序列长度（大约 <d-math>\gt 480</d-math> 个词元），注意力通常是计算密集型的；而在生成期间，我们的算术强度很低且为常数，所以我们总是受内存带宽限制。</p> <p><em>从概念上讲，这是为什么？</em> 主要原因是，我们在模型的线性部分是计算密集型的，因为参数（内存带宽密集型组件）被许多批次项重用。然而，每个批次项都有自己的 KV 缓存，所以更大的批量大小意味着更多的 KV 缓存。除非架构被大幅调整，否则我们在这里几乎<em>总是</em>受内存限制。</p> <p>这也意味着，一旦参数内存变得与 KV 缓存内存相当，通过增加批量大小来提高吞吐量将获得递减的回报。回报递减的程度取决于单个序列的参数与 KV 缓存字节的比率，即大约 <d-math>2DF / SHK</d-math>。由于 <d-math>HK\approx D</d-math>，这大致取决于 <d-math>F</d-math> 与序列长度 <d-math>S</d-math> 的比率。这也取决于使 KV 缓存变小的架构修改（我们稍后会详细说明）。</p> <h3 id="theoretical-estimates-for-llm-latency-and-throughput">LLM 延迟和吞吐量的理论估算</h3> <p>通过这个数学计算，我们可以得到优化时应该追求的步长时间的相当好的界限。<strong>（注意：如果说我们希望读者从本章中学到一件事，那就是接下来的内容）。</strong> 对于生成期间的小批量大小（这很常见），我们可以通过假设我们在注意力和 MLP 块中都受内存带宽限制，来得到每步延迟的下界：</p><span> <mjx-container class="MathJax CtxtMenu_Attached_0" ctxtmenu_counter="16" display="true" jax="CHTML" style="font-size: 116.9%; position: relative;" tabindex="0"><mjx-math aria-hidden="true" class="MJX-TEX" display="true" style="margin-left: 0px; margin-right: 0px;"><mjx-mtext class="mjx-n"><mjx-c class="mjx-c54"></mjx-c><mjx-c class="mjx-c68"></mjx-c><mjx-c class="mjx-c65"></mjx-c><mjx-c class="mjx-c6F"></mjx-c><mjx-c class="mjx-c72"></mjx-c><mjx-c class="mjx-c65"></mjx-c><mjx-c class="mjx-c74"></mjx-c><mjx-c class="mjx-c69"></mjx-c><mjx-c class="mjx-c63"></mjx-c><mjx-c class="mjx-c61"></mjx-c><mjx-c class="mjx-c6C"></mjx-c><mjx-c class="mjx-c20"></mjx-c><mjx-c class="mjx-c4D"></mjx-c><mjx-c class="mjx-c69"></mjx-c><mjx-c class="mjx-c6E"></mjx-c><mjx-c class="mjx-c20"></mjx-c><mjx-c class="mjx-c53"></mjx-c><mjx-c class="mjx-c74"></mjx-c><mjx-c class="mjx-c65"></mjx-c><mjx-c class="mjx-c70"></mjx-c><mjx-c class="mjx-c20"></mjx-c><mjx-c class="mjx-c54"></mjx-c><mjx-c class="mjx-c69"></mjx-c><mjx-c class="mjx-c6D"></mjx-c><mjx-c class="mjx-c65"></mjx-c></mjx-mtext><mjx-mo class="mjx-n" space="4"><mjx-c class="mjx-c3D"></mjx-c></mjx-mo><mjx-mfrac space="4"><mjx-frac type="d"><mjx-num><mjx-nstrut type="d"></mjx-nstrut><mjx-mrow><mjx-mtext class="mjx-n"><mjx-c class="mjx-c42"></mjx-c><mjx-c class="mjx-c61"></mjx-c><mjx-c class="mjx-c74"></mjx-c><mjx-c class="mjx-c63"></mjx-c><mjx-c class="mjx-c68"></mjx-c><mjx-c class="mjx-c20"></mjx-c><mjx-c class="mjx-c53"></mjx-c><mjx-c class="mjx-c69"></mjx-c><mjx-c class="mjx-c7A"></mjx-c><mjx-c class="mjx-c65"></mjx-c></mjx-mtext><mjx-mo class="mjx-n" space="3"><mjx-c class="mjx-cD7"></mjx-c></mjx-mo><mjx-mtext class="mjx-n" space="3"><mjx-c class="mjx-c4B"></mjx-c><mjx-c class="mjx-c56"></mjx-c><mjx-c class="mjx-c20"></mjx-c><mjx-c class="mjx-c43"></mjx-c><mjx-c class="mjx-c61"></mjx-c><mjx-c class="mjx-c63"></mjx-c><mjx-c class="mjx-c68"></mjx-c><mjx-c class="mjx-c65"></mjx-c><mjx-c class="mjx-c20"></mjx-c><mjx-c class="mjx-c53"></mjx-c><mjx-c class="mjx-c69"></mjx-c><mjx-c class="mjx-c7A"></mjx-c><mjx-c class="mjx-c65"></mjx-c></mjx-mtext><mjx-mo class="mjx-n" space="3"><mjx-c class="mjx-c2B"></mjx-c></mjx-mo><mjx-mtext class="mjx-n" space="3"><mjx-c class="mjx-c50"></mjx-c><mjx-c class="mjx-c61"></mjx-c><mjx-c class="mjx-c72"></mjx-c><mjx-c class="mjx-c61"></mjx-c><mjx-c class="mjx-c6D"></mjx-c><mjx-c class="mjx-c65"></mjx-c><mjx-c class="mjx-c74"></mjx-c><mjx-c class="mjx-c65"></mjx-c><mjx-c class="mjx-c72"></mjx-c><mjx-c class="mjx-c20"></mjx-c><mjx-c class="mjx-c53"></mjx-c><mjx-c class="mjx-c69"></mjx-c><mjx-c class="mjx-c7A"></mjx-c><mjx-c class="mjx-c65"></mjx-c></mjx-mtext></mjx-mrow></mjx-num><mjx-dbox><mjx-dtable><mjx-line type="d"></mjx-line><mjx-row><mjx-den><mjx-dstrut type="d"></mjx-dstrut><mjx-mtext class="mjx-n"><mjx-c class="mjx-c54"></mjx-c><mjx-c class="mjx-c6F"></mjx-c><mjx-c class="mjx-c74"></mjx-c><mjx-c class="mjx-c61"></mjx-c><mjx-c class="mjx-c6C"></mjx-c><mjx-c class="mjx-c20"></mjx-c><mjx-c class="mjx-c4D"></mjx-c><mjx-c class="mjx-c65"></mjx-c><mjx-c class="mjx-c6D"></mjx-c><mjx-c class="mjx-c6F"></mjx-c><mjx-c class="mjx-c72"></mjx-c><mjx-c class="mjx-c79"></mjx-c><mjx-c class="mjx-c20"></mjx-c><mjx-c class="mjx-c42"></mjx-c><mjx-c class="mjx-c61"></mjx-c><mjx-c class="mjx-c6E"></mjx-c><mjx-c class="mjx-c64"></mjx-c><mjx-c class="mjx-c77"></mjx-c><mjx-c class="mjx-c69"></mjx-c><mjx-c class="mjx-c64"></mjx-c><mjx-c class="mjx-c74"></mjx-c><mjx-c class="mjx-c68"></mjx-c></mjx-mtext></mjx-den></mjx-row></mjx-dtable></mjx-dbox></mjx-frac></mjx-mfrac></mjx-math><mjx-assistive-mml display="block" unselectable="on"><math display="block" xmlns="http://www.w3.org/1998/Math/MathML"><mtext>Theoretical Min Step Time</mtext><mo>=</mo><mfrac><mrow><mtext>Batch Size</mtext><mo>×</mo><mtext>KV Cache Size</mtext><mo>+</mo><mtext>Parameter Size</mtext></mrow><mtext>Total Memory Bandwidth</mtext></mfrac></math></mjx-assistive-mml></mjx-container> </span><p>同样，对于吞吐量：</p><span> <mjx-container class="MathJax CtxtMenu_Attached_0" ctxtmenu_counter="17" display="true" jax="CHTML" style="font-size: 116.9%; position: relative;" tabindex="0"><mjx-math aria-hidden="true" class="MJX-TEX" display="true" style="margin-left: 0px; margin-right: 0px;"><mjx-mtext class="mjx-n"><mjx-c class="mjx-c54"></mjx-c><mjx-c class="mjx-c68"></mjx-c><mjx-c class="mjx-c65"></mjx-c><mjx-c class="mjx-c6F"></mjx-c><mjx-c class="mjx-c72"></mjx-c><mjx-c class="mjx-c65"></mjx-c><mjx-c class="mjx-c74"></mjx-c><mjx-c class="mjx-c69"></mjx-c><mjx-c class="mjx-c63"></mjx-c><mjx-c class="mjx-c61"></mjx-c><mjx-c class="mjx-c6C"></mjx-c><mjx-c class="mjx-c20"></mjx-c><mjx-c class="mjx-c4D"></mjx-c><mjx-c class="mjx-c61"></mjx-c><mjx-c class="mjx-c78"></mjx-c><mjx-c class="mjx-c20"></mjx-c><mjx-c class="mjx-c54"></mjx-c><mjx-c class="mjx-c6F"></mjx-c><mjx-c class="mjx-c6B"></mjx-c><mjx-c class="mjx-c65"></mjx-c><mjx-c class="mjx-c6E"></mjx-c><mjx-c class="mjx-c73"></mjx-c><mjx-c class="mjx-c2F"></mjx-c><mjx-c class="mjx-c73"></mjx-c></mjx-mtext><mjx-mo class="mjx-n" space="4"><mjx-c class="mjx-c3D"></mjx-c></mjx-mo><mjx-mfrac space="4"><mjx-frac type="d"><mjx-num><mjx-nstrut type="d"></mjx-nstrut><mjx-mrow><mjx-mtext class="mjx-n"><mjx-c class="mjx-c42"></mjx-c><mjx-c class="mjx-c61"></mjx-c><mjx-c class="mjx-c74"></mjx-c><mjx-c class="mjx-c63"></mjx-c><mjx-c class="mjx-c68"></mjx-c><mjx-c class="mjx-c20"></mjx-c><mjx-c class="mjx-c53"></mjx-c><mjx-c class="mjx-c69"></mjx-c><mjx-c class="mjx-c7A"></mjx-c><mjx-c class="mjx-c65"></mjx-c></mjx-mtext><mjx-mo class="mjx-n" space="3"><mjx-c class="mjx-cD7"></mjx-c></mjx-mo><mjx-mtext class="mjx-n" space="3"><mjx-c class="mjx-c54"></mjx-c><mjx-c class="mjx-c6F"></mjx-c><mjx-c class="mjx-c74"></mjx-c><mjx-c class="mjx-c61"></mjx-c><mjx-c class="mjx-c6C"></mjx-c><mjx-c class="mjx-c20"></mjx-c><mjx-c class="mjx-c4D"></mjx-c><mjx-c class="mjx-c65"></mjx-c><mjx-c class="mjx-c6D"></mjx-c><mjx-c class="mjx-c6F"></mjx-c><mjx-c class="mjx-c72"></mjx-c><mjx-c class="mjx-c79"></mjx-c><mjx-c class="mjx-c20"></mjx-c><mjx-c class="mjx-c42"></mjx-c><mjx-c class="mjx-c61"></mjx-c><mjx-c class="mjx-c6E"></mjx-c><mjx-c class="mjx-c64"></mjx-c><mjx-c class="mjx-c77"></mjx-c><mjx-c class="mjx-c69"></mjx-c><mjx-c class="mjx-c64"></mjx-c><mjx-c class="mjx-c74"></mjx-c><mjx-c class="mjx-c68"></mjx-c></mjx-mtext></mjx-mrow></mjx-num><mjx-dbox><mjx-dtable><mjx-line type="d"></mjx-line><mjx-row><mjx-den><mjx-dstrut type="d"></mjx-dstrut><mjx-mrow><mjx-mtext class="mjx-n"><mjx-c class="mjx-c42"></mjx-c><mjx-c class="mjx-c61"></mjx-c><mjx-c class="mjx-c74"></mjx-c><mjx-c class="mjx-c63"></mjx-c><mjx-c class="mjx-c68"></mjx-c><mjx-c class="mjx-c20"></mjx-c><mjx-c class="mjx-c53"></mjx-c><mjx-c class="mjx-c69"></mjx-c><mjx-c class="mjx-c7A"></mjx-c><mjx-c class="mjx-c65"></mjx-c></mjx-mtext><mjx-mo class="mjx-n" space="3"><mjx-c class="mjx-cD7"></mjx-c></mjx-mo><mjx-mtext class="mjx-n" space="3"><mjx-c class="mjx-c4B"></mjx-c><mjx-c class="mjx-c56"></mjx-c><mjx-c class="mjx-c20"></mjx-c><mjx-c class="mjx-c43"></mjx-c><mjx-c class="mjx-c61"></mjx-c><mjx-c class="mjx-c63"></mjx-c><mjx-c class="mjx-c68"></mjx-c><mjx-c class="mjx-c65"></mjx-c><mjx-c class="mjx-c20"></mjx-c><mjx-c class="mjx-c53"></mjx-c><mjx-c class="mjx-c69"></mjx-c><mjx-c class="mjx-c7A"></mjx-c><mjx-c class="mjx-c65"></mjx-c></mjx-mtext><mjx-mo class="mjx-n" space="3"><mjx-c class="mjx-c2B"></mjx-c></mjx-mo><mjx-mtext class="mjx-n" space="3"><mjx-c class="mjx-c50"></mjx-c><mjx-c class="mjx-c61"></mjx-c><mjx-c class="mjx-c72"></mjx-c><mjx-c class="mjx-c61"></mjx-c><mjx-c class="mjx-c6D"></mjx-c><mjx-c class="mjx-c65"></mjx-c><mjx-c class="mjx-c74"></mjx-c><mjx-c class="mjx-c65"></mjx-c><mjx-c class="mjx-c72"></mjx-c><mjx-c class="mjx-c20"></mjx-c><mjx-c class="mjx-c53"></mjx-c><mjx-c class="mjx-c69"></mjx-c><mjx-c class="mjx-c7A"></mjx-c><mjx-c class="mjx-c65"></mjx-c></mjx-mtext></mjx-mrow></mjx-den></mjx-row></mjx-dtable></mjx-dbox></mjx-frac></mjx-mfrac></mjx-math><mjx-assistive-mml display="block" unselectable="on"><math display="block" xmlns="http://www.w3.org/1998/Math/MathML"><mtext>Theoretical Max Tokens/s</mtext><mo>=</mo><mfrac><mrow><mtext>Batch Size</mtext><mo>×</mo><mtext>Total Memory Bandwidth</mtext></mrow><mrow><mtext>Batch Size</mtext><mo>×</mo><mtext>KV Cache Size</mtext><mo>+</mo><mtext>Parameter Size</mtext></mrow></mfrac></math></mjx-assistive-mml></mjx-container> </span><p>最终，随着批量大小的增长，FLOPs 开始主导参数加载，因此在实践中我们有更通用的方程：</p><span> <mjx-container class="MathJax CtxtMenu_Attached_0" ctxtmenu_counter="18" display="true" jax="CHTML" style="font-size: 116.9%; min-width: 34.272em; position: relative;" tabindex="0" width="full"><mjx-math aria-hidden="true" class="MJX-TEX" display="true" width="full"><mjx-mtable side="right" style="min-width: 34.272em;" width="full"><mjx-table style="width: auto; min-width: 30.116em; margin: 0px 2.078em;"><mjx-itable width="full"><mjx-mlabeledtr><mjx-mtd style="text-align: right;"><mjx-mstyle size="ss"><mjx-mtext class="mjx-n"><mjx-c class="mjx-c54"></mjx-c><mjx-c class="mjx-c68"></mjx-c><mjx-c class="mjx-c65"></mjx-c><mjx-c class="mjx-c6F"></mjx-c><mjx-c class="mjx-c72"></mjx-c><mjx-c class="mjx-c65"></mjx-c><mjx-c class="mjx-c74"></mjx-c><mjx-c class="mjx-c69"></mjx-c><mjx-c class="mjx-c63"></mjx-c><mjx-c class="mjx-c61"></mjx-c><mjx-c class="mjx-c6C"></mjx-c><mjx-c class="mjx-c20"></mjx-c><mjx-c class="mjx-c53"></mjx-c><mjx-c class="mjx-c74"></mjx-c><mjx-c class="mjx-c65"></mjx-c><mjx-c class="mjx-c70"></mjx-c><mjx-c class="mjx-c20"></mjx-c><mjx-c class="mjx-c54"></mjx-c><mjx-c class="mjx-c69"></mjx-c><mjx-c class="mjx-c6D"></mjx-c><mjx-c class="mjx-c65"></mjx-c><mjx-c class="mjx-c20"></mjx-c><mjx-c class="mjx-c28"></mjx-c><mjx-c class="mjx-c47"></mjx-c><mjx-c class="mjx-c65"></mjx-c><mjx-c class="mjx-c6E"></mjx-c><mjx-c class="mjx-c65"></mjx-c><mjx-c class="mjx-c72"></mjx-c><mjx-c class="mjx-c61"></mjx-c><mjx-c class="mjx-c6C"></mjx-c><mjx-c class="mjx-c29"></mjx-c></mjx-mtext><mjx-mo class="mjx-n" space="4"><mjx-c class="mjx-c3D"></mjx-c></mjx-mo><mjx-munder space="4"><mjx-row><mjx-base><mjx-texatom texclass="OP"><mjx-munder><mjx-row><mjx-base><mjx-mfrac><mjx-frac type="d"><mjx-num><mjx-nstrut type="d"></mjx-nstrut><mjx-mrow><mjx-mtext class="mjx-n"><mjx-c class="mjx-c42"></mjx-c><mjx-c class="mjx-c61"></mjx-c><mjx-c class="mjx-c74"></mjx-c><mjx-c class="mjx-c63"></mjx-c><mjx-c class="mjx-c68"></mjx-c><mjx-c class="mjx-c20"></mjx-c><mjx-c class="mjx-c53"></mjx-c><mjx-c class="mjx-c69"></mjx-c><mjx-c class="mjx-c7A"></mjx-c><mjx-c class="mjx-c65"></mjx-c></mjx-mtext><mjx-mo class="mjx-n" space="3"><mjx-c class="mjx-cD7"></mjx-c></mjx-mo><mjx-mtext class="mjx-n" space="3"><mjx-c class="mjx-c4B"></mjx-c><mjx-c class="mjx-c56"></mjx-c><mjx-c class="mjx-c20"></mjx-c><mjx-c class="mjx-c43"></mjx-c><mjx-c class="mjx-c61"></mjx-c><mjx-c class="mjx-c63"></mjx-c><mjx-c class="mjx-c68"></mjx-c><mjx-c class="mjx-c65"></mjx-c><mjx-c class="mjx-c20"></mjx-c><mjx-c class="mjx-c53"></mjx-c><mjx-c class="mjx-c69"></mjx-c><mjx-c class="mjx-c7A"></mjx-c><mjx-c class="mjx-c65"></mjx-c></mjx-mtext></mjx-mrow></mjx-num><mjx-dbox><mjx-dtable><mjx-line type="d"></mjx-line><mjx-row><mjx-den><mjx-dstrut type="d"></mjx-dstrut><mjx-mstyle><mjx-mtext class="mjx-n"><mjx-c class="mjx-c54"></mjx-c><mjx-c class="mjx-c6F"></mjx-c><mjx-c class="mjx-c74"></mjx-c><mjx-c class="mjx-c61"></mjx-c><mjx-c class="mjx-c6C"></mjx-c><mjx-c class="mjx-c20"></mjx-c><mjx-c class="mjx-c4D"></mjx-c><mjx-c class="mjx-c65"></mjx-c><mjx-c class="mjx-c6D"></mjx-c><mjx-c class="mjx-c6F"></mjx-c><mjx-c class="mjx-c72"></mjx-c><mjx-c class="mjx-c79"></mjx-c><mjx-c class="mjx-c20"></mjx-c><mjx-c class="mjx-c42"></mjx-c><mjx-c class="mjx-c61"></mjx-c><mjx-c class="mjx-c6E"></mjx-c><mjx-c class="mjx-c64"></mjx-c><mjx-c class="mjx-c77"></mjx-c><mjx-c class="mjx-c69"></mjx-c><mjx-c class="mjx-c64"></mjx-c><mjx-c class="mjx-c74"></mjx-c><mjx-c class="mjx-c68"></mjx-c></mjx-mtext></mjx-mstyle></mjx-den></mjx-row></mjx-dtable></mjx-dbox></mjx-frac></mjx-mfrac></mjx-base></mjx-row><mjx-row><mjx-under style="padding-top: 0.105em;"><mjx-mo class="mjx-n"><mjx-stretchy-h class="mjx-c23DF" style="width: 12.647em;"><mjx-beg><mjx-c></mjx-c></mjx-beg><mjx-ext><mjx-c></mjx-c></mjx-ext><mjx-mid><mjx-c></mjx-c></mjx-mid><mjx-ext><mjx-c></mjx-c></mjx-ext><mjx-end><mjx-c></mjx-c></mjx-end></mjx-stretchy-h></mjx-mo></mjx-under></mjx-row></mjx-munder></mjx-texatom></mjx-base></mjx-row><mjx-row><mjx-under style="padding-top: 0.062em; padding-left: 0.604em;"><mjx-texatom size="s" texclass="ORD"><mjx-mtext class="mjx-n"><mjx-c class="mjx-c41"></mjx-c><mjx-c class="mjx-c74"></mjx-c><mjx-c class="mjx-c74"></mjx-c><mjx-c class="mjx-c65"></mjx-c><mjx-c class="mjx-c6E"></mjx-c><mjx-c class="mjx-c74"></mjx-c><mjx-c class="mjx-c69"></mjx-c><mjx-c class="mjx-c6F"></mjx-c><mjx-c class="mjx-c6E"></mjx-c><mjx-c class="mjx-c20"></mjx-c><mjx-c class="mjx-c28"></mjx-c><mjx-c class="mjx-c61"></mjx-c><mjx-c class="mjx-c6C"></mjx-c><mjx-c class="mjx-c77"></mjx-c><mjx-c class="mjx-c61"></mjx-c><mjx-c class="mjx-c79"></mjx-c><mjx-c class="mjx-c73"></mjx-c><mjx-c class="mjx-c20"></mjx-c><mjx-c class="mjx-c62"></mjx-c><mjx-c class="mjx-c61"></mjx-c><mjx-c class="mjx-c6E"></mjx-c><mjx-c class="mjx-c64"></mjx-c><mjx-c class="mjx-c77"></mjx-c><mjx-c class="mjx-c69"></mjx-c><mjx-c class="mjx-c64"></mjx-c><mjx-c class="mjx-c74"></mjx-c><mjx-c class="mjx-c68"></mjx-c><mjx-c class="mjx-c2D"></mjx-c><mjx-c class="mjx-c62"></mjx-c><mjx-c class="mjx-c6F"></mjx-c><mjx-c class="mjx-c75"></mjx-c><mjx-c class="mjx-c6E"></mjx-c><mjx-c class="mjx-c64"></mjx-c><mjx-c class="mjx-c29"></mjx-c></mjx-mtext></mjx-texatom></mjx-under></mjx-row></mjx-munder><mjx-mo class="mjx-n" space="2"><mjx-c class="mjx-c2B"></mjx-c></mjx-mo><mjx-munder><mjx-row><mjx-base><mjx-texatom texclass="OP"><mjx-munder><mjx-row><mjx-base><mjx-mrow><mjx-mo class="mjx-n"><mjx-c class="mjx-c6D"></mjx-c><mjx-c class="mjx-c61"></mjx-c><mjx-c class="mjx-c78"></mjx-c></mjx-mo><mjx-mrow space="2"><mjx-mo class="mjx-s3"><mjx-c class="mjx-c28 TEX-S3"></mjx-c></mjx-mo><mjx-mfrac><mjx-frac type="d"><mjx-num><mjx-nstrut type="d"></mjx-nstrut><mjx-mrow><mjx-mn class="mjx-n"><mjx-c class="mjx-c32"></mjx-c></mjx-mn><mjx-mo class="mjx-n" space="3"><mjx-c class="mjx-cD7"></mjx-c></mjx-mo><mjx-mtext class="mjx-n" space="3"><mjx-c class="mjx-c42"></mjx-c><mjx-c class="mjx-c61"></mjx-c><mjx-c class="mjx-c74"></mjx-c><mjx-c class="mjx-c63"></mjx-c><mjx-c class="mjx-c68"></mjx-c><mjx-c class="mjx-c20"></mjx-c><mjx-c class="mjx-c53"></mjx-c><mjx-c class="mjx-c69"></mjx-c><mjx-c class="mjx-c7A"></mjx-c><mjx-c class="mjx-c65"></mjx-c></mjx-mtext><mjx-mo class="mjx-n" space="3"><mjx-c class="mjx-cD7"></mjx-c></mjx-mo><mjx-mtext class="mjx-n" space="3"><mjx-c class="mjx-c50"></mjx-c><mjx-c class="mjx-c61"></mjx-c><mjx-c class="mjx-c72"></mjx-c><mjx-c class="mjx-c61"></mjx-c><mjx-c class="mjx-c6D"></mjx-c><mjx-c class="mjx-c65"></mjx-c><mjx-c class="mjx-c74"></mjx-c><mjx-c class="mjx-c65"></mjx-c><mjx-c class="mjx-c72"></mjx-c><mjx-c class="mjx-c20"></mjx-c><mjx-c class="mjx-c43"></mjx-c><mjx-c class="mjx-c6F"></mjx-c><mjx-c class="mjx-c75"></mjx-c><mjx-c class="mjx-c6E"></mjx-c><mjx-c class="mjx-c74"></mjx-c></mjx-mtext></mjx-mrow></mjx-num><mjx-dbox><mjx-dtable><mjx-line type="d"></mjx-line><mjx-row><mjx-den><mjx-dstrut type="d"></mjx-dstrut><mjx-mtext class="mjx-n"><mjx-c class="mjx-c54"></mjx-c><mjx-c class="mjx-c6F"></mjx-c><mjx-c class="mjx-c74"></mjx-c><mjx-c class="mjx-c61"></mjx-c><mjx-c class="mjx-c6C"></mjx-c><mjx-c class="mjx-c20"></mjx-c><mjx-c class="mjx-c46"></mjx-c><mjx-c class="mjx-c4C"></mjx-c><mjx-c class="mjx-c4F"></mjx-c><mjx-c class="mjx-c50"></mjx-c><mjx-c class="mjx-c73"></mjx-c><mjx-c class="mjx-c2F"></mjx-c><mjx-c class="mjx-c73"></mjx-c></mjx-mtext></mjx-den></mjx-row></mjx-dtable></mjx-dbox></mjx-frac></mjx-mfrac><mjx-mo class="mjx-n"><mjx-c class="mjx-c2C"></mjx-c></mjx-mo><mjx-mfrac space="2"><mjx-frac type="d"><mjx-num><mjx-nstrut type="d"></mjx-nstrut><mjx-mtext class="mjx-n"><mjx-c class="mjx-c50"></mjx-c><mjx-c class="mjx-c61"></mjx-c><mjx-c class="mjx-c72"></mjx-c><mjx-c class="mjx-c61"></mjx-c><mjx-c class="mjx-c6D"></mjx-c><mjx-c class="mjx-c65"></mjx-c><mjx-c class="mjx-c74"></mjx-c><mjx-c class="mjx-c65"></mjx-c><mjx-c class="mjx-c72"></mjx-c><mjx-c class="mjx-c20"></mjx-c><mjx-c class="mjx-c53"></mjx-c><mjx-c class="mjx-c69"></mjx-c><mjx-c class="mjx-c7A"></mjx-c><mjx-c class="mjx-c65"></mjx-c></mjx-mtext></mjx-num><mjx-dbox><mjx-dtable><mjx-line type="d"></mjx-line><mjx-row><mjx-den><mjx-dstrut type="d"></mjx-dstrut><mjx-mtext class="mjx-n"><mjx-c class="mjx-c54"></mjx-c><mjx-c class="mjx-c6F"></mjx-c><mjx-c class="mjx-c74"></mjx-c><mjx-c class="mjx-c61"></mjx-c><mjx-c class="mjx-c6C"></mjx-c><mjx-c class="mjx-c20"></mjx-c><mjx-c class="mjx-c4D"></mjx-c><mjx-c class="mjx-c65"></mjx-c><mjx-c class="mjx-c6D"></mjx-c><mjx-c class="mjx-c6F"></mjx-c><mjx-c class="mjx-c72"></mjx-c><mjx-c class="mjx-c79"></mjx-c><mjx-c class="mjx-c20"></mjx-c><mjx-c class="mjx-c42"></mjx-c><mjx-c class="mjx-c61"></mjx-c><mjx-c class="mjx-c6E"></mjx-c><mjx-c class="mjx-c64"></mjx-c><mjx-c class="mjx-c77"></mjx-c><mjx-c class="mjx-c69"></mjx-c><mjx-c class="mjx-c64"></mjx-c><mjx-c class="mjx-c74"></mjx-c><mjx-c class="mjx-c68"></mjx-c></mjx-mtext></mjx-den></mjx-row></mjx-dtable></mjx-dbox></mjx-frac></mjx-mfrac><mjx-mo class="mjx-s3"><mjx-c class="mjx-c29 TEX-S3"></mjx-c></mjx-mo></mjx-mrow></mjx-mrow></mjx-base></mjx-row><mjx-row><mjx-under style="padding-top: 0.105em;"><mjx-mo class="mjx-n"><mjx-stretchy-h class="mjx-c23DF" style="width: 31.21em;"><mjx-beg><mjx-c></mjx-c></mjx-beg><mjx-ext><mjx-c></mjx-c></mjx-ext><mjx-mid><mjx-c></mjx-c></mjx-mid><mjx-ext><mjx-c></mjx-c></mjx-ext><mjx-end><mjx-c></mjx-c></mjx-end></mjx-stretchy-h></mjx-mo></mjx-under></mjx-row></mjx-munder></mjx-texatom></mjx-base></mjx-row><mjx-row><mjx-under style="padding-top: 0.062em; padding-left: 10.998em;"><mjx-texatom size="s" texclass="ORD"><mjx-mstyle><mjx-mtext class="mjx-n"><mjx-c class="mjx-c4D"></mjx-c><mjx-c class="mjx-c4C"></mjx-c><mjx-c class="mjx-c50"></mjx-c><mjx-c class="mjx-c20"></mjx-c><mjx-c class="mjx-c28"></mjx-c><mjx-c class="mjx-c63"></mjx-c><mjx-c class="mjx-c61"></mjx-c><mjx-c class="mjx-c6E"></mjx-c><mjx-c class="mjx-c20"></mjx-c><mjx-c class="mjx-c62"></mjx-c><mjx-c class="mjx-c65"></mjx-c><mjx-c class="mjx-c20"></mjx-c><mjx-c class="mjx-c63"></mjx-c><mjx-c class="mjx-c6F"></mjx-c><mjx-c class="mjx-c6D"></mjx-c><mjx-c class="mjx-c70"></mjx-c><mjx-c class="mjx-c75"></mjx-c><mjx-c class="mjx-c74"></mjx-c><mjx-c class="mjx-c65"></mjx-c><mjx-c class="mjx-c2D"></mjx-c><mjx-c class="mjx-c62"></mjx-c><mjx-c class="mjx-c6F"></mjx-c><mjx-c class="mjx-c75"></mjx-c><mjx-c class="mjx-c6E"></mjx-c><mjx-c class="mjx-c64"></mjx-c><mjx-c class="mjx-c29"></mjx-c></mjx-mtext></mjx-mstyle></mjx-texatom></mjx-under></mjx-row></mjx-munder></mjx-mstyle><mjx-tstrut></mjx-tstrut></mjx-mtd></mjx-mlabeledtr></mjx-itable></mjx-table><mjx-labels style="width: 34.272em;"><mjx-itable align="right" style="right: 0px;"><mjx-mtr style="height: 2.027em;"><mjx-mtd id="mjx-eqn:1"><mjx-mtext class="mjx-n"><mjx-c class="mjx-c28"></mjx-c><mjx-c class="mjx-c31"></mjx-c><mjx-c class="mjx-c29"></mjx-c></mjx-mtext><mjx-tstrut style="height: 2.027em; vertical-align: -1.277em;"></mjx-tstrut></mjx-mtd></mjx-mtr></mjx-itable></mjx-labels></mjx-mtable></mjx-math><mjx-assistive-mml display="block" unselectable="on"><math display="block" xmlns="http://www.w3.org/1998/Math/MathML"><mtable columnalign="right" columnspacing="" displaystyle="true" rowspacing="3pt"><mlabeledtr><mtd><mtext>(1)</mtext></mtd><mtd><mstyle mathsize="0.5em"><mtext>Theoretical Step Time (General)</mtext><mo>=</mo><munder><mrow data-mjx-texclass="OP"><munder><mfrac><mrow><mtext>Batch Size</mtext><mo>×</mo><mtext>KV Cache Size</mtext></mrow><mstyle><mtext>Total Memory Bandwidth</mtext></mstyle></mfrac><mo>⏟</mo></munder></mrow><mrow data-mjx-texclass="ORD"><mtext>Attention (always bandwidth-bound)</mtext></mrow></munder><mo>+</mo><munder><mrow data-mjx-texclass="OP"><munder><mrow><mo data-mjx-texclass="OP" movablelimits="true">max</mo><mrow data-mjx-texclass="INNER"><mo data-mjx-texclass="OPEN">(</mo><mfrac><mrow><mn>2</mn><mo>×</mo><mtext>Batch Size</mtext><mo>×</mo><mtext>Parameter Count</mtext></mrow><mtext>Total FLOPs/s</mtext></mfrac><mo>,</mo><mfrac><mtext>Parameter Size</mtext><mtext>Total Memory Bandwidth</mtext></mfrac><mo data-mjx-texclass="CLOSE">)</mo></mrow></mrow><mo>⏟</mo></munder></mrow><mrow data-mjx-texclass="ORD"><mstyle><mtext>MLP (can be compute-bound)</mtext></mstyle></mrow></munder></mstyle></mtd></mlabeledtr></mtable></math></mjx-assistive-mml></mjx-container> </span><p>其中注意力部分（左）从不是计算密集型的，因此不需要 FLOPs 屋顶线。这些对于进行粗略计算相当有用，例如</p> <p><b style="color: #57cf57;">小测验：</b> 假设我们想在一个 4x4 的 TPU v5e 切片上，使用 int8 参数和 bf16 FLOPs，对一个 30B 参数的密集模型进行一个生成步骤，批量大小为 4 个词元，上下文长度为 8192，每个词元的 KV 缓存为 100 kB。这个操作的延迟的合理下界是多少？如果我们想采样一批 256 个词元呢？</p> <details><summary>点击此处查看答案。</summary> <p><strong>答案：</strong> 在 int8 中，我们的参数将使用 30e9 字节，根据给定的规格，我们的 KV 缓存每个将使用 <code class="language-plaintext highlighter-rouge">100e3 * 8192 = 819MB</code>。我们有 16 个芯片，每个芯片的带宽为 <code class="language-plaintext highlighter-rouge">8.1e11</code> 字节/秒，bf16 FLOPs/秒为 <code class="language-plaintext highlighter-rouge">1.97e14</code>。根据上述方程，由于我们的批量大小很小，我们预计步长时间至少为 <code class="language-plaintext highlighter-rouge">(4 * 819e6 + 30e9) / (16 * 8.1e11) = 2.5 ms</code>。对于 256 个词元，我们的 MLP 块将远超计算密集型区域，所以步长时间大约为 <code class="language-plaintext highlighter-rouge">(256 * 819e6) / (16 * 8.1e11) + (2 * 256 * 30e9) / (16 * 1.97e14) = 21ms</code>。</p> </details> <p>正如你所见，这里在吞吐量和延迟之间存在明显的权衡。小批量速度快，但硬件利用率不高。大批量速度慢，但效率高。以下是为一些旧的 PaLM 模型计算的延迟-吞吐量帕累托前沿（来自 <a href="https://arxiv.org/pdf/2211.05102" rel="external nofollow noopener" target="_blank">ESTI 论文</a><d-cite key="esti"></d-cite>）：</p> <figure> <picture> <source class="responsive-img-srcset" sizes="95vw" srcset="https://jax-ml.github.io/scaling-book/assets/img/latency-cost-480.webp 480w, https://jax-ml.github.io/scaling-book/assets/img/latency-cost-800.webp 800w, https://jax-ml.github.io/scaling-book/assets/img/latency-cost-1400.webp 1400w" type="image/webp"/> <img class="img-fluid" height="auto" loading="lazy" onerror="this.onerror=null; $('.responsive-img-srcset').remove();" src="https://jax-ml.github.io/scaling-book/assets/img/latency-cost.png" width="100%"/> </picture> <figcaption class="caption"><b>图：</b>几个 PaLM 模型的成本（即吞吐量）与延迟的帕累托前沿。注意芯片数量（C）和批量大小（B）如何让你在帕累托前沿上移动，除了绿点（PaLM 540B 的 C:32 B:16），那里的可用内存阻止了设置支持一个好的批量大小，并导致吞吐量受损。注意吞吐量通常在批量大小 240 之后趋于平缓。int8 权重提供了更好的延迟-吞吐量帕累托最优，但最大吞吐量没有更好。</figcaption> </figure> <p>我们不仅通过批量大小作为调节旋钮来权衡延迟和吞吐量，如果我们发现自己受 HBM 限制，我们也可能更喜欢更大的拓扑结构而不是更小的，以便容纳更大的批次。 <a href="applied-inference.html">下一节</a>将更详细地探讨这一点。</p> <p class="takeaway"><strong>要点：</strong> 如果你关心生成吞吐量，请使用尽可能大的每芯片批量大小。任何高于 TPU 算术强度（<d-math>B_\text{crit}</d-math>，通常为 120 或 240）的每芯片批量大小都将最大化吞吐量。你可能需要增加你的拓扑结构来实现这一点。较小的批量大小将允许你以牺牲吞吐量为代价来改善延迟。</p> <details><summary>从硬件的角度来看，这有一些需要注意的地方。点击这里查看一些细节。</summary> <p>这一切都相当理论化。在实践中，我们通常不会看到一个尖锐的屋顶线，原因有几个：</p> <ul> <li>我们关于 HBM 读取将与 FLOPs 完全重叠的假设是不现实的，因为我们的编译器（XLA）并非完美无缺。</li> <li>对于分片模型，XLA 也常常无法有效地将我们模型分片矩阵乘法的 ICI 通信与 FLOPs 本身重叠，所以我们经常在线性操作上开始遭受延迟损失，超过 <mjx-container class="MathJax CtxtMenu_Attached_0" ctxtmenu_counter="19" jax="CHTML" style="font-size: 116.9%; position: relative;" tabindex="0"><mjx-math aria-hidden="true" class="MJX-TEX"><mjx-mtext class="mjx-n"><mjx-c class="mjx-c42"></mjx-c><mjx-c class="mjx-c53"></mjx-c></mjx-mtext><mjx-mo class="mjx-n" space="4"><mjx-c class="mjx-c3D"></mjx-c></mjx-mo><mjx-mn class="mjx-n" space="4"><mjx-c class="mjx-c33"></mjx-c><mjx-c class="mjx-c32"></mjx-c></mjx-mn></mjx-math><mjx-assistive-mml display="inline" unselectable="on"><math xmlns="http://www.w3.org/1998/Math/MathML"><mtext>BS</mtext><mo>=</mo><mn>32</mn></math></mjx-assistive-mml></mjx-container>。</li> <li>大于理论屋顶线的批量大小仍然会看到一些吞吐量的改善，因为重叠不完美，但这只是一个很好的启发式方法。</li> </ul> </details> <h3 id="what-about-memory">内存方面呢？</h3> <p>我们花了一些时间研究带宽和 FLOPs，但没有研究内存。由于我们新的数据结构——KV 缓存，推理时的内存情况看起来大不相同。在本节中，我们将选择一个真实模型（LLaMA 2-13B）来展示情况有多么不同：</p> <table class="table-hover" data-toggle="table"> <thead> <tr> <th>超参数</th> <th>值</th> </tr> </thead> <tbody> <tr> <td>L (num_layers)</td> <td>40</td> </tr> <tr> <td>D (d_model)</td> <td>5,120</td> </tr> <tr> <td>F (ffw_dimension)</td> <td>13,824</td> </tr> <tr> <td>N (num_heads)</td> <td>40</td> </tr> <tr> <td>K (num_kv_heads)</td> <td>40</td> </tr> <tr> <td>H (qkv_dim)</td> <td>128</td> </tr> <tr> <td>V (num_embeddings)</td> <td>32,000</td> </tr> </tbody> </table> <p>在推理期间什么在占用内存？嗯，很明显，是我们的参数。计算这些，我们有：</p> <table class="table-hover" data-toggle="table"> <thead> <tr> <th>参数</th> <th>公式</th> <th>大小 (字节)</th> </tr> </thead> <tbody> <tr> <td>FFW 参数</td> <td>d_model<sup>2</sup> x ffw_multiplier x 3 (用于 gelu + 输出投影) x n_layers</td> <td>5,120 x 5,120 x 2.7 x 3 x 40 = <strong>8.5e9</strong> </td> </tr> <tr> <td>词汇表参数</td> <td>2 (输入和输出嵌入) x n_embeddings x d_model</td> <td>2 x 32,000 x 5,120 = <strong>0.3e9</strong> </td> </tr> <tr> <td>注意力参数</td> <td>[2 (<em>q 和输出</em>) x d_model x n_heads x d_qkv + 2 (<em>用于 k 和 v</em>) x d_model x n_kv_heads x d_qkv] x n_layers</td> <td>(2 x 5,120 x 40 x 128 + 2 x 5,120 x 40 x 128) x 40 = <strong>4.2e9</strong> </td> </tr> </tbody> </table> <p>将这些参数加起来，我们得到 8.5e9 + 4.2e9 + 0.3e9 = <strong>13e9 总参数</strong>，正如预期的那样。正如我们在前几节中看到的，在训练期间，我们可能会将参数存储在 bfloat16 中，并将优化器状态存储在 float32 中。这可能会使用大约 100GB 的内存。与我们的梯度检查点相比，这相形见绌，后者可能使用数 TB。</p> <p><strong>推理有何不同？</strong> 在推理期间，我们存储一份参数，比如以 bfloat16 格式。这会占用 26GB——实际上，通过量化，我们通常可以做得更好。没有优化器状态或梯度需要跟踪。因为我们不进行检查点（为反向传播保留激活），我们的激活占用空间对于预填充<d-footnote id="d-footnote-4">特别要感谢 Flash Attention，它避免了将我们的注意力矩阵实例化</d-footnote>和生成来说都是微不足道的。如果我们预填充 8k 个词元，单个激活仅使用大约 <code class="language-plaintext highlighter-rouge">8,192 x 5,120 x 2 字节 = 80MB</code> 的内存。更长的预填充可以分解为许多更小的正向传播，因此对于更长的上下文也不是问题。生成使用的词元甚至更少，所以激活可以忽略不计。</p> <p><strong>主要区别在于 KV 缓存</strong>。这些是所有过去词元的键和值投影，其大小仅受最大允许序列长度的限制。对于 <mjx-container class="MathJax CtxtMenu_Attached_0" ctxtmenu_counter="20" jax="CHTML" style="font-size: 116.9%; position: relative;" tabindex="0"><mjx-math aria-hidden="true" class="MJX-TEX"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D447 TEX-I"></mjx-c></mjx-mi></mjx-math><mjx-assistive-mml display="inline" unselectable="on"><math xmlns="http://www.w3.org/1998/Math/MathML"><mi>T</mi></math></mjx-assistive-mml></mjx-container> 个词元的总大小是</p><span> <mjx-container class="MathJax CtxtMenu_Attached_0" ctxtmenu_counter="21" display="true" jax="CHTML" style="font-size: 116.9%; position: relative;" tabindex="0"><mjx-math aria-hidden="true" class="MJX-TEX" display="true" style="margin-left: 0px; margin-right: 0px;"><mjx-mtext class="mjx-n"><mjx-c class="mjx-c4B"></mjx-c><mjx-c class="mjx-c56"></mjx-c><mjx-c class="mjx-c20"></mjx-c><mjx-c class="mjx-c63"></mjx-c><mjx-c class="mjx-c61"></mjx-c><mjx-c class="mjx-c63"></mjx-c><mjx-c class="mjx-c68"></mjx-c><mjx-c class="mjx-c65"></mjx-c><mjx-c class="mjx-c20"></mjx-c><mjx-c class="mjx-c73"></mjx-c><mjx-c class="mjx-c69"></mjx-c><mjx-c class="mjx-c7A"></mjx-c><mjx-c class="mjx-c65"></mjx-c></mjx-mtext><mjx-mo class="mjx-n" space="4"><mjx-c class="mjx-c3D"></mjx-c></mjx-mo><mjx-mn class="mjx-n" space="4"><mjx-c class="mjx-c32"></mjx-c></mjx-mn><mjx-mo class="mjx-n" space="3"><mjx-c class="mjx-c22C5"></mjx-c></mjx-mo><mjx-mtext class="mjx-n" space="3"><mjx-c class="mjx-c62"></mjx-c><mjx-c class="mjx-c79"></mjx-c><mjx-c class="mjx-c74"></mjx-c><mjx-c class="mjx-c65"></mjx-c><mjx-c class="mjx-c73"></mjx-c><mjx-c class="mjx-c20"></mjx-c><mjx-c class="mjx-c70"></mjx-c><mjx-c class="mjx-c65"></mjx-c><mjx-c class="mjx-c72"></mjx-c><mjx-c class="mjx-c20"></mjx-c><mjx-c class="mjx-c66"></mjx-c><mjx-c class="mjx-c6C"></mjx-c><mjx-c class="mjx-c6F"></mjx-c><mjx-c class="mjx-c61"></mjx-c><mjx-c class="mjx-c74"></mjx-c></mjx-mtext><mjx-mo class="mjx-n" space="3"><mjx-c class="mjx-c22C5"></mjx-c></mjx-mo><mjx-mi class="mjx-i" space="3"><mjx-c class="mjx-c1D43B TEX-I"></mjx-c></mjx-mi><mjx-mo class="mjx-n" space="3"><mjx-c class="mjx-c22C5"></mjx-c></mjx-mo><mjx-mi class="mjx-i" space="3"><mjx-c class="mjx-c1D43E TEX-I"></mjx-c></mjx-mi><mjx-mo class="mjx-n" space="3"><mjx-c class="mjx-c22C5"></mjx-c></mjx-mo><mjx-mi class="mjx-i" space="3"><mjx-c class="mjx-c1D43F TEX-I"></mjx-c></mjx-mi><mjx-mo class="mjx-n" space="3"><mjx-c class="mjx-c22C5"></mjx-c></mjx-mo><mjx-mi class="mjx-i" space="3"><mjx-c class="mjx-c1D447 TEX-I"></mjx-c></mjx-mi></mjx-math><mjx-assistive-mml display="block" unselectable="on"><math display="block" xmlns="http://www.w3.org/1998/Math/MathML"><mtext>KV cache size</mtext><mo>=</mo><mn>2</mn><mo>⋅</mo><mtext>bytes per float</mtext><mo>⋅</mo><mi>H</mi><mo>⋅</mo><mi>K</mi><mo>⋅</mo><mi>L</mi><mo>⋅</mo><mi>T</mi></math></mjx-assistive-mml></mjx-container> </span><p>其中 <mjx-container class="MathJax CtxtMenu_Attached_0" ctxtmenu_counter="22" jax="CHTML" style="font-size: 116.9%; position: relative;" tabindex="0"><mjx-math aria-hidden="true" class="MJX-TEX"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D43B TEX-I"></mjx-c></mjx-mi></mjx-math><mjx-assistive-mml display="inline" unselectable="on"><math xmlns="http://www.w3.org/1998/Math/MathML"><mi>H</mi></math></mjx-assistive-mml></mjx-container> 是每个头的维度，<mjx-container class="MathJax CtxtMenu_Attached_0" ctxtmenu_counter="23" jax="CHTML" style="font-size: 116.9%; position: relative;" tabindex="0"><mjx-math aria-hidden="true" class="MJX-TEX"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D43E TEX-I"></mjx-c></mjx-mi></mjx-math><mjx-assistive-mml display="inline" unselectable="on"><math xmlns="http://www.w3.org/1998/Math/MathML"><mi>K</mi></math></mjx-assistive-mml></mjx-container> 是 KV 头的数量，<mjx-container class="MathJax CtxtMenu_Attached_0" ctxtmenu_counter="24" jax="CHTML" style="font-size: 116.9%; position: relative;" tabindex="0"><mjx-math aria-hidden="true" class="MJX-TEX"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D43F TEX-I"></mjx-c></mjx-mi></mjx-math><mjx-assistive-mml display="inline" unselectable="on"><math xmlns="http://www.w3.org/1998/Math/MathML"><mi>L</mi></math></mjx-assistive-mml></mjx-container> 是层数，2 来自于同时存储键和值。</p> <p><strong>即使批量大小和上下文长度适中，这个值也可能迅速变得非常大</strong>。对于 LLaMA-13B，一个 8192 序列在 bf16 下的 KV 缓存是</p><span> <mjx-container class="MathJax CtxtMenu_Attached_0" ctxtmenu_counter="25" display="true" jax="CHTML" style="font-size: 116.9%; position: relative;" tabindex="0"><mjx-math aria-hidden="true" class="MJX-TEX" display="true" style="margin-left: 0px; margin-right: 0px;"><mjx-mn class="mjx-n"><mjx-c class="mjx-c38"></mjx-c><mjx-c class="mjx-c31"></mjx-c><mjx-c class="mjx-c39"></mjx-c><mjx-c class="mjx-c32"></mjx-c></mjx-mn><mjx-mtext class="mjx-n"><mjx-c class="mjx-cA0"></mjx-c></mjx-mtext><mjx-mo class="mjx-n"><mjx-c class="mjx-c28"></mjx-c></mjx-mo><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D447 TEX-I"></mjx-c></mjx-mi><mjx-mo class="mjx-n"><mjx-c class="mjx-c29"></mjx-c></mjx-mo><mjx-mo class="mjx-n" space="3"><mjx-c class="mjx-cD7"></mjx-c></mjx-mo><mjx-mn class="mjx-n" space="3"><mjx-c class="mjx-c34"></mjx-c><mjx-c class="mjx-c30"></mjx-c></mjx-mn><mjx-mtext class="mjx-n"><mjx-c class="mjx-cA0"></mjx-c></mjx-mtext><mjx-mo class="mjx-n"><mjx-c class="mjx-c28"></mjx-c></mjx-mo><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D43E TEX-I"></mjx-c></mjx-mi><mjx-mo class="mjx-n"><mjx-c class="mjx-c29"></mjx-c></mjx-mo><mjx-mo class="mjx-n" space="3"><mjx-c class="mjx-cD7"></mjx-c></mjx-mo><mjx-mn class="mjx-n" space="3"><mjx-c class="mjx-c31"></mjx-c><mjx-c class="mjx-c32"></mjx-c><mjx-c class="mjx-c38"></mjx-c></mjx-mn><mjx-mtext class="mjx-n"><mjx-c class="mjx-cA0"></mjx-c></mjx-mtext><mjx-mo class="mjx-n"><mjx-c class="mjx-c28"></mjx-c></mjx-mo><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D43B TEX-I"></mjx-c></mjx-mi><mjx-mo class="mjx-n"><mjx-c class="mjx-c29"></mjx-c></mjx-mo><mjx-mo class="mjx-n" space="3"><mjx-c class="mjx-cD7"></mjx-c></mjx-mo><mjx-mn class="mjx-n" space="3"><mjx-c class="mjx-c34"></mjx-c><mjx-c class="mjx-c30"></mjx-c></mjx-mn><mjx-mtext class="mjx-n"><mjx-c class="mjx-cA0"></mjx-c></mjx-mtext><mjx-mo class="mjx-n"><mjx-c class="mjx-c28"></mjx-c></mjx-mo><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D43F TEX-I"></mjx-c></mjx-mi><mjx-mo class="mjx-n"><mjx-c class="mjx-c29"></mjx-c></mjx-mo><mjx-mo class="mjx-n" space="3"><mjx-c class="mjx-cD7"></mjx-c></mjx-mo><mjx-mn class="mjx-n" space="3"><mjx-c class="mjx-c32"></mjx-c></mjx-mn><mjx-mtext class="mjx-n"><mjx-c class="mjx-cA0"></mjx-c></mjx-mtext><mjx-mo class="mjx-n"><mjx-c class="mjx-c28"></mjx-c></mjx-mo><mjx-mtext class="mjx-n"><mjx-c class="mjx-c62"></mjx-c><mjx-c class="mjx-c79"></mjx-c><mjx-c class="mjx-c74"></mjx-c><mjx-c class="mjx-c65"></mjx-c><mjx-c class="mjx-c73"></mjx-c></mjx-mtext><mjx-mo class="mjx-n"><mjx-c class="mjx-c29"></mjx-c></mjx-mo><mjx-mo class="mjx-n" space="3"><mjx-c class="mjx-cD7"></mjx-c></mjx-mo><mjx-mn class="mjx-n" space="3"><mjx-c class="mjx-c32"></mjx-c></mjx-mn><mjx-mo class="mjx-n" space="4"><mjx-c class="mjx-c3D"></mjx-c></mjx-mo><mjx-mn class="mjx-n" space="4"><mjx-c class="mjx-c36"></mjx-c><mjx-c class="mjx-c2E"></mjx-c><mjx-c class="mjx-c37"></mjx-c></mjx-mn><mjx-mtext class="mjx-n"><mjx-c class="mjx-c47"></mjx-c><mjx-c class="mjx-c42"></mjx-c></mjx-mtext></mjx-math><mjx-assistive-mml display="block" unselectable="on"><math display="block" xmlns="http://www.w3.org/1998/Math/MathML"><mn>8192</mn><mtext> </mtext><mo stretchy="false">(</mo><mi>T</mi><mo stretchy="false">)</mo><mo>×</mo><mn>40</mn><mtext> </mtext><mo stretchy="false">(</mo><mi>K</mi><mo stretchy="false">)</mo><mo>×</mo><mn>128</mn><mtext> </mtext><mo stretchy="false">(</mo><mi>H</mi><mo stretchy="false">)</mo><mo>×</mo><mn>40</mn><mtext> </mtext><mo stretchy="false">(</mo><mi>L</mi><mo stretchy="false">)</mo><mo>×</mo><mn>2</mn><mtext> </mtext><mo stretchy="false">(</mo><mtext>bytes</mtext><mo stretchy="false">)</mo><mo>×</mo><mn>2</mn><mo>=</mo><mn>6.7</mn><mtext>GB</mtext></math></mjx-assistive-mml></mjx-container> </span><p><strong>仅仅 4 个这样的缓存就超过了我们参数的内存使用量！</strong> 需要明确的是，LLaMA 2 并未针对较长上下文的 KV 缓存大小进行优化（情况并非总是这么糟，因为通常 <d-math>K</d-math> 要小得多，如 LLaMA-3 中），但这仍然具有说明性。我们在内存或延迟估算中不能忽略这些。</p> <h3 id="modeling-throughput-and-latency-for-llama-2-13b">为 LLaMA 2-13B 的吞吐量和延迟建模</h3> <p>让我们看看，如果我们尝试在 8 个 TPU v5e 上，以不同的批量大小完美高效地执行生成，直到达到之前为最大理论吞吐量推导出的临界批量大小（240），会发生什么。</p> <table class="table-hover" data-toggle="table"> <thead> <tr> <th style="text-align: left">批量大小</th> <th style="text-align: right">1</th> <th style="text-align: right">8</th> <th style="text-align: right">16</th> <th style="text-align: right">32</th> <th style="text-align: right">64</th> <th style="text-align: right">240</th> </tr> </thead> <tbody> <tr> <td style="text-align: left">KV 缓存内存 (GiB)</td> <td style="text-align: right">6.7</td> <td style="text-align: right">53.6</td> <td style="text-align: right">107.2</td> <td style="text-align: right">214.4</td> <td style="text-align: right">428.8</td> <td style="text-align: right">1608</td> </tr> <tr> <td style="text-align: left">总内存 (GiB)</td> <td style="text-align: right">32.7</td> <td style="text-align: right">79.6</td> <td style="text-align: right">133.2</td> <td style="text-align: right">240.4</td> <td style="text-align: right">454.8</td> <td style="text-align: right">1634</td> </tr> <tr> <td style="text-align: left">理论步长时间 (ms)</td> <td style="text-align: right">4.98</td> <td style="text-align: right">12.13</td> <td style="text-align: right">20.30</td> <td style="text-align: right">36.65</td> <td style="text-align: right">69.33</td> <td style="text-align: right">249.09</td> </tr> <tr> <td style="text-align: left">理论吞吐量 (词元/秒)</td> <td style="text-align: right">200.61</td> <td style="text-align: right">659.30</td> <td style="text-align: right">787.99</td> <td style="text-align: right">873.21</td> <td style="text-align: right">923.13</td> <td style="text-align: right">963.53</td> </tr> </tbody> </table> <p>8 个 TPU v5e 给了我们 128GiB 的 HBM，6.5TiB/s 的 HBM 带宽（每个 0.82TiB/s）和 1600TF/s 的计算能力。</p> <p>对于这个模型，增加批量大小确实能带来更好的吞吐量，但我们很快就会遇到收益递减的问题。当批量大小超过 16 时，我们就会出现内存不足（OOM），并且需要数量级更多的内存才能接近 240。更大的拓扑结构可以改善延迟，但我们在每个芯片的吞吐量上遇到了瓶颈。</p> <p>假设我们保持总参数数量不变，但神奇地将 KV 缓存缩小 5 倍（比如说，使用 1:5 的 <a href="#tricks-for-improving-generation-throughput-and-latency">GMQA</a>，这意味着我们有 8 个 KV 头共享给 40 个 Q 头——详见下一节）。</p> <table class="table-hover" data-toggle="table"> <thead> <tr> <th style="text-align: left">批量大小</th> <th style="text-align: right">1</th> <th style="text-align: right">8</th> <th style="text-align: right">16</th> <th style="text-align: right">32</th> <th style="text-align: right">64</th> <th style="text-align: right">240</th> </tr> </thead> <tbody> <tr> <td style="text-align: left">KV 缓存内存 (GiB)</td> <td style="text-align: right">1.34</td> <td style="text-align: right">10.72</td> <td style="text-align: right">21.44</td> <td style="text-align: right">42.88</td> <td style="text-align: right">85.76</td> <td style="text-align: right">321.6</td> </tr> <tr> <td style="text-align: left">总内存 (GiB)</td> <td style="text-align: right">27.34</td> <td style="text-align: right">36.72</td> <td style="text-align: right">47.44</td> <td style="text-align: right">68.88</td> <td style="text-align: right">111.76</td> <td style="text-align: right">347.6</td> </tr> <tr> <td style="text-align: left">理论步长时间 (ms)</td> <td style="text-align: right">4.17</td> <td style="text-align: right">5.60</td> <td style="text-align: right">7.23</td> <td style="text-align: right">10.50</td> <td style="text-align: right">17.04</td> <td style="text-align: right">52.99</td> </tr> <tr> <td style="text-align: left">理论吞吐量 (词元/秒)</td> <td style="text-align: right">239.94</td> <td style="text-align: right">1,429.19</td> <td style="text-align: right">2,212.48</td> <td style="text-align: right">3,047.62</td> <td style="text-align: right">3,756.62</td> <td style="text-align: right">4,529.34</td> </tr> </tbody> </table> <p>使用更小的 KV 缓存，我们仍然会遇到收益递减的问题，但理论上每个芯片的吞吐量会持续扩展到批量大小为 240。我们可以容纳更大的批次，达到 64，并且在所有批量大小下，延迟也始终更好。延迟、最大吞吐量和最大批量大小都得到了显著改善！事实上，后来的 LLaMA 版本就使用了这个确切的优化——LLaMA-3 8B 有 32 个查询头和 8 个 KV 头（<a href="https://huggingface.co/MaziyarPanahi/Llama-3-13B-Instruct-v0.1/blob/dfdeb40bdb2c149dfa399ea2be0d56eb120f0831/config.json" rel="external nofollow noopener" target="_blank">来源</a>）。</p> <p class="takeaway"><strong>要点：</strong> 除了参数，KV 缓存的大小对模型的最终推理性能有很大影响。我们需要通过架构决策和运行时优化的结合来控制它。</p> <h2 id="tricks-for-improving-generation-throughput-and-latency">提升生成吞吐量和延迟的技巧</h2> <p>自最初的 <a href="https://arxiv.org/abs/1706.03762" rel="external nofollow noopener" target="_blank">Attention is All You Need 论文</a>以来，已经发展出许多技术来提高模型的效率，通常特别针对 KV 缓存。总的来说，一个更小的 KV 缓存使得在不损害延迟的情况下更容易增加生成步骤的批量大小和上下文长度，并且让围绕 Transformer 的系统（如请求缓存）工作起来更容易。忽略对质量的影响，我们可能会看到：</p> <p><strong>分组多查询注意力（又名 GMQA, GQA）：</strong> 我们可以减少 KV 头的数量，并在注意力机制中与许多 Q 头共享它们。在极端情况下，可以在所有 Q 头之间共享一个 KV 头。这比纯 MHA 将 KV 缓存减少了 Q:KV 的比率倍，并且已经观察到模型的性能对这种变化相对不敏感。</p> <figure> <picture> <source class="responsive-img-srcset" sizes="95vw" srcset="https://jax-ml.github.io/scaling-book/assets/img/gmqa-480.webp 480w, https://jax-ml.github.io/scaling-book/assets/img/gmqa-800.webp 800w, https://jax-ml.github.io/scaling-book/assets/img/gmqa-1400.webp 1400w" type="image/webp"/> <img class="img-fluid" height="auto" loading="lazy" onerror="this.onerror=null; $('.responsive-img-srcset').remove();" src="https://jax-ml.github.io/scaling-book/assets/img/gmqa.png" width="100%"/> </picture> </figure> <p>这也有效地增加了注意力计算的算术强度（参见<a href="transformers.html">第 4 节</a>中的问题 4）。</p> <p><strong>混合一些局部注意力层：</strong> 局部注意力将上下文限制在一个小到中等大小的最大长度内。在训练和预填充时，这涉及到将注意力矩阵掩码为一个对角条带而不是一个三角形。这有效地限制了局部层的 KV 缓存的最大长度。通过在模型中混合一些局部层和一些全局层，当上下文长度超过局部窗口时，KV 缓存的大小会大大减小。</p> <p><strong>跨层共享 KV：</strong> 模型可以学习以某种模式在不同层之间共享相同的 KV 缓存。虽然这确实减小了 KV 缓存的大小，并在增加批量大小、缓存、离线存储等方面提供了好处，但共享的 KV 缓存可能需要多次从 HBM 读取，<em>因此不一定能改善步长时间。</em></p> <figure> <picture> <source class="responsive-img-srcset" sizes="95vw" srcset="https://jax-ml.github.io/scaling-book/assets/img/kv-sharing-480.webp 480w, https://jax-ml.github.io/scaling-book/assets/img/kv-sharing-800.webp 800w, https://jax-ml.github.io/scaling-book/assets/img/kv-sharing-1400.webp 1400w" type="image/webp"/> <img class="img-fluid" height="auto" loading="lazy" onerror="this.onerror=null; $('.responsive-img-srcset').remove();" src="https://jax-ml.github.io/scaling-book/assets/img/kv-sharing.png" width="100%"/> </picture> <figcaption class="caption"> <b>左图：</b>多层纯全局注意力。<b>右图：</b>一个全局/局部交错模式并与相邻层共享的示例。来源：<a href="https://research.character.ai/optimizing-inference/?ref=blog.character.ai" rel="external nofollow noopener" target="_blank">Character.ai 博客</a>。</figcaption> </figure> <p><strong>量化：</strong> 推理通常对参数和 KV 的精度不太敏感。通过量化参数和 KV 缓存（例如，量化到 int8、int4、<code class="language-plaintext highlighter-rouge">fp8</code> 等），我们可以在两者上节省内存带宽，减少达到计算屋顶线所需的批量大小，并节省内存以运行更大的批量。量化还有一个额外的好处，即使模型没有在训练时使用量化，也通常可以在训练后应用。</p> <p><strong>使用非规则 HBM 读取和 Paged Attention：</strong> 在上面的计算中，我们为每个 KV 缓存分配了 8k 的上下文，但通常没有必要从内存中读取整个 KV 缓存——请求的长度分布范围很广，并不总是使用模型的最大上下文，所以我们通常可以实现只读取 KV 缓存非填充部分的内核（例如 Flash Attention 变体）。</p> <p>Paged Attention<d-cite key="paged"></d-cite> 是对此的改进，它将 KV 缓存存储在类似操作系统的页表中，并且基本上完全避免了对 KV 缓存的填充。这增加了很多复杂性，但意味着每个批次只使用它需要的内存量。这是一个运行时优化，所以它同样与架构无关。</p> <figure> <picture> <source class="responsive-img-srcset" sizes="95vw" srcset="https://jax-ml.github.io/scaling-book/assets/img/paged-attention-480.webp 480w, https://jax-ml.github.io/scaling-book/assets/img/paged-attention-800.webp 800w, https://jax-ml.github.io/scaling-book/assets/img/paged-attention-1400.webp 1400w" type="image/webp"/> <img class="img-fluid img-small" height="auto" loading="lazy" onerror="this.onerror=null; $('.responsive-img-srcset').remove();" src="https://jax-ml.github.io/scaling-book/assets/img/paged-attention.png" width="100%"/> </picture> <figcaption class="caption"><b>图：</b>在生成过程中，一个词元（forth）关注多个 KV 缓存块/页。通过对 KV 缓存进行分页，我们避免了加载或存储超出我们需要的内存。引自 <a href="https://arxiv.org/pdf/2309.06180" rel="external nofollow noopener" target="_blank">PagedAttention 论文</a>。</figcaption> </figure> <p class="takeaway"><strong>宏观视角：</strong> 总而言之，这些 KV 缓存优化可以将 KV 缓存大小与标准的 MHA Transformer 相比减少一个数量级以上。这可能导致 Transformer 的总成本提高一个数量级。</p> <h2 id="distributing-inference-over-multiple-accelerators">在多个加速器上分布推理</h2> <p>到目前为止，我们都只是泛泛地谈论如何扩展到单个芯片之外。继<a href="training.html">第 5 节</a>之后，让我们探讨一下可用的不同策略及其权衡。和往常一样，我们将分别考察预填充和生成。</p> <h3 id="prefill">预填充</h3> <p>从屋顶线的角度来看，<strong>预填充与训练几乎相同</strong>，并且几乎所有相同的技术和权衡都适用——模型（Megatron）并行性、序列分片（对于足够长的上下文）、流水线，甚至 FSDP 都是可行的！你只需要保留 KV，以便稍后进行生成。与训练一样，增加芯片数量可以让我们获得更多的 FLOPs/s（可能降低 TTFT），但会增加通信开销（可能降低每个芯片的吞吐量）。</p> <p><strong>分片预填充的一般规则：</strong> 这里有一套关于预填充的一般规则。我们将假设我们只对单个序列进行预填充（没有批次维度）：</p> <ol> <li> <em>模型分片：</em> 我们通常首先进行一定程度的模型并行性，直到我们受 ICI 限制。正如我们在<a href="training.html">第 5 节</a>中看到的，对于 1 个轴，这大约是 <d-math>F / 2200</d-math>（通常是 4-8 路分片）。</li> <li> <em>序列并行性：</em> 除此之外，我们进行序列并行性（类似于数据并行性，但在序列维度上进行分片）。虽然序列并行性在注意力中引入了一些额外的通信，但在较长的上下文中，这通常相当小。与训练一样，我们可以重叠通信和计算（分别使用集体矩阵乘法用于 Megatron 和环形注意力）。</li> </ol> <p class="takeaway"><strong>要点：</strong> 在预填充期间，几乎任何在训练期间可行的分片策略都可以正常工作。先进行模型并行性直到达到 ICI 边界，然后进行序列并行性。</p> <h3 id="generation">生成</h3> <p>生成比预填充要复杂得多。一方面，很难获得大的批量大小，因为我们需要将许多请求批处理在一起。延迟目标更低。这些因素共同意味着我们通常更受内存限制，对通信开销更敏感，这限制了我们的分片策略：</p> <ol> <li> <p><strong>FSDP 是不可能的：</strong> 由于我们在从 HBM 加载参数和 KV 缓存到 MXU 的过程中受内存限制，我们不想通过比 HBM 慢几个数量级的 ICI 来移动它们。<em>我们希望移动激活而不是权重。</em> 这意味着类似 FSDP 的方法通常对于生成是完全不可行的。<d-footnote id="d-footnote-5">训练后不小心保留它是导致数量级性能下降的一个简单而常见的方式</d-footnote></p> </li> <li> <p><strong>没有理由进行数据并行性：</strong> 纯数据并行性没有帮助，因为它复制了我们的参数，并且无助于我们更快地加载参数。你最好启动多个模型的副本。<d-footnote id="d-footnote-6">我们的意思是，以较小的批量大小启动多个带有模型副本的服务器。模型级别的数据并行性严格来说更差。</d-footnote></p> </li> <li> <p><strong>没有序列 = 没有序列分片。</strong> 祝你好运进行序列分片。</p> </li> </ol> <p><em>这主要给我们留下了用于密集模型生成的模型分片变体</em>。与预填充一样，我们能做的最简单的事情就是简单的模型并行性（激活完全复制，MLP 的权重在隐藏维度上完全分片），直到 4-8 路时我们受 ICI 限制。然而，由于我们经常受内存带宽限制，我们实际上可以超越这个限制来提高延迟！</p> <p><strong>关于生成 ICI 边界的说明：</strong> 在训练期间，我们希望是计算密集型的，所以我们的屋顶线关注的是 ICI 通信时间何时超过 FLOPs 时间。然而，在生成期间，如果我们受参数加载的内存带宽限制，我们可以将模型分片增加到超过这个点，并以最小的吞吐量成本提高延迟。更多的模型分片为我们提供了更多的 HBM 来加载我们的权重，而我们的 FLOPs 并不重要。<d-footnote id="d-footnote-7">意思是 FLOPs 时间不是我们的瓶颈，所以我们需要担心的是 ICI 时间超过参数加载时间。</d-footnote> 让我们看看在模型并行性成为瓶颈之前，我们可以做多少。</p><span> <mjx-container class="MathJax CtxtMenu_Attached_0" ctxtmenu_counter="26" display="true" jax="CHTML" style="font-size: 116.9%; position: relative;" tabindex="0"><mjx-math aria-hidden="true" class="MJX-TEX" display="true" style="margin-left: 0px; margin-right: 0px;"><mjx-mtable style="min-width: 20.158em;"><mjx-table><mjx-itable><mjx-mtr><mjx-mtd style="text-align: right; padding-right: 0px;"><mjx-msub><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D447 TEX-I"></mjx-c></mjx-mi><mjx-script style="vertical-align: -0.15em; margin-left: -0.12em;"><mjx-mtext class="mjx-n" size="s"><mjx-c class="mjx-c48"></mjx-c><mjx-c class="mjx-c42"></mjx-c><mjx-c class="mjx-c4D"></mjx-c><mjx-c class="mjx-c20"></mjx-c><mjx-c class="mjx-c63"></mjx-c><mjx-c class="mjx-c6F"></mjx-c><mjx-c class="mjx-c6D"></mjx-c><mjx-c class="mjx-c6D"></mjx-c><mjx-c class="mjx-c73"></mjx-c></mjx-mtext></mjx-script></mjx-msub><mjx-mo class="mjx-n" space="4"><mjx-c class="mjx-c3D"></mjx-c></mjx-mo><mjx-mfrac space="4"><mjx-frac type="d"><mjx-num><mjx-nstrut type="d"></mjx-nstrut><mjx-mrow><mjx-mn class="mjx-n"><mjx-c class="mjx-c32"></mjx-c></mjx-mn><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D437 TEX-I"></mjx-c></mjx-mi><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D439 TEX-I"></mjx-c></mjx-mi></mjx-mrow></mjx-num><mjx-dbox><mjx-dtable><mjx-line type="d"></mjx-line><mjx-row><mjx-den><mjx-dstrut type="d"></mjx-dstrut><mjx-mrow><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D44C TEX-I"></mjx-c></mjx-mi><mjx-mo class="mjx-n" space="3"><mjx-c class="mjx-c22C5"></mjx-c></mjx-mo><mjx-msub space="3"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D44A TEX-I"></mjx-c></mjx-mi><mjx-script style="vertical-align: -0.15em; margin-left: -0.104em;"><mjx-mtext class="mjx-n" size="s"><mjx-c class="mjx-c68"></mjx-c><mjx-c class="mjx-c62"></mjx-c><mjx-c class="mjx-c6D"></mjx-c></mjx-mtext></mjx-script></mjx-msub></mjx-mrow></mjx-den></mjx-row></mjx-dtable></mjx-dbox></mjx-frac></mjx-mfrac><mjx-tstrut></mjx-tstrut></mjx-mtd><mjx-mtd style="text-align: left; padding-left: 0px; padding-right: 1em;"><mjx-tstrut></mjx-tstrut></mjx-mtd><mjx-mtd style="text-align: right; padding-left: 1em;"><mjx-msub><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D447 TEX-I"></mjx-c></mjx-mi><mjx-script style="vertical-align: -0.15em; margin-left: -0.12em;"><mjx-mtext class="mjx-n" size="s"><mjx-c class="mjx-c49"></mjx-c><mjx-c class="mjx-c43"></mjx-c><mjx-c class="mjx-c49"></mjx-c><mjx-c class="mjx-c20"></mjx-c><mjx-c class="mjx-c63"></mjx-c><mjx-c class="mjx-c6F"></mjx-c><mjx-c class="mjx-c6D"></mjx-c><mjx-c class="mjx-c6D"></mjx-c><mjx-c class="mjx-c73"></mjx-c></mjx-mtext></mjx-script></mjx-msub><mjx-mo class="mjx-n" space="4"><mjx-c class="mjx-c3D"></mjx-c></mjx-mo><mjx-mfrac space="4"><mjx-frac type="d"><mjx-num><mjx-nstrut type="d"></mjx-nstrut><mjx-mrow><mjx-mn class="mjx-n"><mjx-c class="mjx-c32"></mjx-c></mjx-mn><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D435 TEX-I"></mjx-c></mjx-mi><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D437 TEX-I"></mjx-c></mjx-mi></mjx-mrow></mjx-num><mjx-dbox><mjx-dtable><mjx-line type="d"></mjx-line><mjx-row><mjx-den><mjx-dstrut type="d"></mjx-dstrut><mjx-msub><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D44A TEX-I"></mjx-c></mjx-mi><mjx-script style="vertical-align: -0.15em; margin-left: -0.104em;"><mjx-mtext class="mjx-n" size="s"><mjx-c class="mjx-c69"></mjx-c><mjx-c class="mjx-c63"></mjx-c><mjx-c class="mjx-c69"></mjx-c></mjx-mtext></mjx-script></mjx-msub></mjx-den></mjx-row></mjx-dtable></mjx-dbox></mjx-frac></mjx-mfrac><mjx-tstrut></mjx-tstrut></mjx-mtd></mjx-mtr></mjx-itable></mjx-table></mjx-mtable></mjx-math><mjx-assistive-mml display="block" unselectable="on"><math display="block" xmlns="http://www.w3.org/1998/Math/MathML"><mtable columnalign="right left right" columnspacing="0em 2em" displaystyle="true" rowspacing="3pt"><mtr><mtd><msub><mi>T</mi><mtext>HBM comms</mtext></msub><mo>=</mo><mfrac><mrow><mn>2</mn><mi>D</mi><mi>F</mi></mrow><mrow><mi>Y</mi><mo>⋅</mo><msub><mi>W</mi><mtext>hbm</mtext></msub></mrow></mfrac></mtd><mtd></mtd><mtd><msub><mi>T</mi><mtext>ICI comms</mtext></msub><mo>=</mo><mfrac><mrow><mn>2</mn><mi>B</mi><mi>D</mi></mrow><msub><mi>W</mi><mtext>ici</mtext></msub></mfrac></mtd></mtr></mtable></math></mjx-assistive-mml></mjx-container> <mjx-container class="MathJax CtxtMenu_Attached_0" ctxtmenu_counter="27" display="true" jax="CHTML" style="font-size: 116.9%; position: relative;" tabindex="0"><mjx-math aria-hidden="true" class="MJX-TEX" display="true" style="margin-left: 0px; margin-right: 0px;"><mjx-msub><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D447 TEX-I"></mjx-c></mjx-mi><mjx-script style="vertical-align: -0.15em; margin-left: -0.12em;"><mjx-mtext class="mjx-n" size="s"><mjx-c class="mjx-c49"></mjx-c><mjx-c class="mjx-c43"></mjx-c><mjx-c class="mjx-c49"></mjx-c><mjx-c class="mjx-c20"></mjx-c><mjx-c class="mjx-c63"></mjx-c><mjx-c class="mjx-c6F"></mjx-c><mjx-c class="mjx-c6D"></mjx-c><mjx-c class="mjx-c6D"></mjx-c><mjx-c class="mjx-c73"></mjx-c></mjx-mtext></mjx-script></mjx-msub><mjx-mo class="mjx-n" space="4"><mjx-c class="mjx-c3E"></mjx-c></mjx-mo><mjx-msub space="4"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D447 TEX-I"></mjx-c></mjx-mi><mjx-script style="vertical-align: -0.15em; margin-left: -0.12em;"><mjx-mtext class="mjx-n" size="s"><mjx-c class="mjx-c48"></mjx-c><mjx-c class="mjx-c42"></mjx-c><mjx-c class="mjx-c4D"></mjx-c><mjx-c class="mjx-c20"></mjx-c><mjx-c class="mjx-c63"></mjx-c><mjx-c class="mjx-c6F"></mjx-c><mjx-c class="mjx-c6D"></mjx-c><mjx-c class="mjx-c6D"></mjx-c><mjx-c class="mjx-c73"></mjx-c></mjx-mtext></mjx-script></mjx-msub><mjx-mo class="mjx-n" space="4"><mjx-c class="mjx-c2192"></mjx-c></mjx-mo><mjx-mfrac space="4"><mjx-frac type="d"><mjx-num><mjx-nstrut type="d"></mjx-nstrut><mjx-msub><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D44A TEX-I"></mjx-c></mjx-mi><mjx-script style="vertical-align: -0.15em; margin-left: -0.104em;"><mjx-mtext class="mjx-n" size="s"><mjx-c class="mjx-c68"></mjx-c><mjx-c class="mjx-c62"></mjx-c><mjx-c class="mjx-c6D"></mjx-c></mjx-mtext></mjx-script></mjx-msub></mjx-num><mjx-dbox><mjx-dtable><mjx-line type="d"></mjx-line><mjx-row><mjx-den><mjx-dstrut type="d"></mjx-dstrut><mjx-msub><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D44A TEX-I"></mjx-c></mjx-mi><mjx-script style="vertical-align: -0.15em; margin-left: -0.104em;"><mjx-mtext class="mjx-n" size="s"><mjx-c class="mjx-c69"></mjx-c><mjx-c class="mjx-c63"></mjx-c><mjx-c class="mjx-c69"></mjx-c></mjx-mtext></mjx-script></mjx-msub></mjx-den></mjx-row></mjx-dtable></mjx-dbox></mjx-frac></mjx-mfrac><mjx-mo class="mjx-n" space="4"><mjx-c class="mjx-c3E"></mjx-c></mjx-mo><mjx-mfrac space="4"><mjx-frac type="d"><mjx-num><mjx-nstrut type="d"></mjx-nstrut><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D439 TEX-I"></mjx-c></mjx-mi></mjx-num><mjx-dbox><mjx-dtable><mjx-line type="d"></mjx-line><mjx-row><mjx-den><mjx-dstrut type="d"></mjx-dstrut><mjx-mrow><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D44C TEX-I"></mjx-c></mjx-mi><mjx-mo class="mjx-n" space="3"><mjx-c class="mjx-c22C5"></mjx-c></mjx-mo><mjx-mi class="mjx-i" space="3"><mjx-c class="mjx-c1D435 TEX-I"></mjx-c></mjx-mi></mjx-mrow></mjx-den></mjx-row></mjx-dtable></mjx-dbox></mjx-frac></mjx-mfrac><mjx-mo class="mjx-n" space="4"><mjx-c class="mjx-c2192"></mjx-c></mjx-mo><mjx-mi class="mjx-i" space="4"><mjx-c class="mjx-c1D44C TEX-I"></mjx-c></mjx-mi><mjx-mo class="mjx-n" space="4"><mjx-c class="mjx-c3E"></mjx-c></mjx-mo><mjx-mi class="mjx-i" space="4"><mjx-c class="mjx-c1D439 TEX-I"></mjx-c></mjx-mi><mjx-texatom texclass="ORD"><mjx-mo class="mjx-n"><mjx-c class="mjx-c2F"></mjx-c></mjx-mo></mjx-texatom><mjx-mo class="mjx-n"><mjx-c class="mjx-c28"></mjx-c></mjx-mo><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D435 TEX-I"></mjx-c></mjx-mi><mjx-mo class="mjx-n" space="3"><mjx-c class="mjx-c22C5"></mjx-c></mjx-mo><mjx-mi class="mjx-i" space="3"><mjx-c class="mjx-c1D6FD TEX-I"></mjx-c></mjx-mi><mjx-mo class="mjx-n"><mjx-c class="mjx-c29"></mjx-c></mjx-mo></mjx-math><mjx-assistive-mml display="block" unselectable="on"><math display="block" xmlns="http://www.w3.org/1998/Math/MathML"><msub><mi>T</mi><mtext>ICI comms</mtext></msub><mo>&gt;</mo><msub><mi>T</mi><mtext>HBM comms</mtext></msub><mo stretchy="false">→</mo><mfrac><msub><mi>W</mi><mtext>hbm</mtext></msub><msub><mi>W</mi><mtext>ici</mtext></msub></mfrac><mo>&gt;</mo><mfrac><mi>F</mi><mrow><mi>Y</mi><mo>⋅</mo><mi>B</mi></mrow></mfrac><mo stretchy="false">→</mo><mi>Y</mi><mo>&gt;</mo><mi>F</mi><mrow data-mjx-texclass="ORD"><mo>/</mo></mrow><mo stretchy="false">(</mo><mi>B</mi><mo>⋅</mo><mi>β</mi><mo stretchy="false">)</mo></math></mjx-assistive-mml></mjx-container> </span><p>其中 <d-math>\beta = W_\text{hbm} / W_\text{ici}</d-math>。对于 TPU v5e 和 TPU v6e，这个数字通常在 8 左右。这意味着，例如，如果 <d-math>F</d-math> 是 16,384，<d-math>B</d-math> 是 32，理论上我们可以进行高达 <code class="language-plaintext highlighter-rouge">16384 / (32 * 8) = 64</code> 路的模型并行性，而不会对吞吐量产生有意义的影响。这假设我们可以将我们的 KV 缓存完全分片 64 路，这很困难：我们将在下面讨论这个问题。</p> <p>对于注意力层，我们还以 Megatron 的方式在头上对注意力 <mjx-container class="MathJax CtxtMenu_Attached_0" ctxtmenu_counter="28" jax="CHTML" style="font-size: 116.9%; position: relative;" tabindex="0"><mjx-math aria-hidden="true" class="MJX-TEX"><mjx-msub><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D44A TEX-I"></mjx-c></mjx-mi><mjx-script style="vertical-align: -0.15em; margin-left: -0.104em;"><mjx-mi class="mjx-i" size="s"><mjx-c class="mjx-c1D444 TEX-I"></mjx-c></mjx-mi></mjx-script></mjx-msub></mjx-math><mjx-assistive-mml display="inline" unselectable="on"><math xmlns="http://www.w3.org/1998/Math/MathML"><msub><mi>W</mi><mi>Q</mi></msub></math></mjx-assistive-mml></mjx-container> 和 <mjx-container class="MathJax CtxtMenu_Attached_0" ctxtmenu_counter="29" jax="CHTML" style="font-size: 116.9%; position: relative;" tabindex="0"><mjx-math aria-hidden="true" class="MJX-TEX"><mjx-msub><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D44A TEX-I"></mjx-c></mjx-mi><mjx-script style="vertical-align: -0.15em; margin-left: -0.104em;"><mjx-mi class="mjx-i" size="s"><mjx-c class="mjx-c1D442 TEX-I"></mjx-c></mjx-mi></mjx-script></mjx-msub></mjx-math><mjx-assistive-mml display="inline" unselectable="on"><math xmlns="http://www.w3.org/1998/Math/MathML"><msub><mi>W</mi><mi>O</mi></msub></math></mjx-assistive-mml></mjx-container> 进行模型分片。KV 权重相当小，复制它们通常比分片超过 <d-math>K</d-math> 路分片更便宜。</p> <p class="takeaway"><strong>要点：</strong> 在生成期间，我们唯一的选择是模型并行性的变体。我们的目标是移动激活而不是更大的 KV 缓存或参数。当我们的批量大小很大时，我们进行模型并行性直到达到 FLOPs-ICI 边界（<d-math>F / \alpha</d-math>）。当我们的批量大小较小时，我们可以通过更多的模型分片来改善延迟（以适度的吞吐量成本）。当我们想要模型分片的数量超过我们拥有的 KV 头数时，我们也可以沿着批次维度对我们的 KV 进行分片。</p> <h3 id="sharding-the-kv-cache">分片 KV 缓存</h3> <p><strong>我们还有一个需要分片的额外数据结构——KV 缓存。</strong> 同样，我们几乎总是倾向于避免复制缓存，因为它是注意力延迟的主要来源。为此，我们首先沿着头维度对 KV 进行 Megatron 分片。这仅限于 <d-math>K</d-math> 路分片，所以对于头数较少的模型，我们尽可能地分片头维度，然后沿着批次维度分片，即 <d-math>\text{KV}[2, B_Z, S, K_Y, H]</d-math>。这意味着 KV 缓存是完全分布式的。</p> <figure> <picture> <source class="responsive-img-srcset" sizes="95vw" srcset="https://jax-ml.github.io/scaling-book/assets/img/esta-figure-480.webp 480w, https://jax-ml.github.io/scaling-book/assets/img/esta-figure-800.webp 800w, https://jax-ml.github.io/scaling-book/assets/img/esta-figure-1400.webp 1400w" type="image/webp"/> <img class="img-fluid" height="auto" loading="lazy" onerror="this.onerror=null; $('.responsive-img-srcset').remove();" src="https://jax-ml.github.io/scaling-book/assets/img/esta-figure.png" width="100%"/> </picture> <figcaption class="caption"><b>图：</b>注意力机制的比较，(a) 具有纯模型分片的多头注意力和 (b) 具有 KV 缓存批次分片的多查询注意力。注意我们如何需要两个额外的 AllToAlls 来将激活从模型分片转移到批次分片，以便它们可以作用于 KV 缓存。</figcaption> </figure> <p>这样做的代价是每个注意力层需要两次 AllToAlls 操作——一次是将 Q 激活转移到批次分片，以便我们可以用批次分片计算注意力；另一次是将批次分片的注意力输出转回纯模型分片。</p> <details><summary>这是完整的算法！</summary> <p>在这里，我们将写出在 <d-math>Y</d-math> 和 <d-math>Z</d-math> 上都进行模型并行性的完整注意力算法。我为同时使用 <d-math>K</d-math> 表示键张量和 KV 头维度而道歉。设 <d-math>M=N/K</d-math>。</p> <div class="algorithm"> <ol> <li>X[B, D] = … (现有激活，来自前一层，未分片)</li> <li>K[B<sub>Z</sub>, S, K<sub>Y</sub>, H], V[B<sub>Z</sub>, S, K, H] = … (现有 KV 缓存，批次分片)</li> <li>Q[B, N<sub>YZ</sub>, H] = X[B, D] * W<sub>Q</sub>[D, N<sub>YZ</sub>, H]</li> <li>Q[B<sub>Z</sub>, N<sub>Y</sub>, H] = <strong>AllToAll</strong><sub>Z-&gt;B</sub>(Q[B, N<sub>YZ</sub>, H])</li> <li>Q[B<sub>Z</sub>, K<sub>Y</sub>, M, H] = <strong>Reshape</strong>(Q[B<sub>Z</sub>, N<sub>Y</sub>, H])</li> <li>O[B<sub>Z</sub>, S, K<sub>Y</sub>, M] = Q[B<sub>Z</sub>, K<sub>Y</sub>, M, H] *<sub>H</sub> K[B<sub>Z</sub>, S, K<sub>Y</sub>, H]</li> <li>O[B<sub>Z</sub>, S, K, M] = <strong>Softmax</strong><sub>S</sub>(O[B<sub>Z</sub>, S, K<sub>Y</sub>])</li> <li>O[B<sub>Z</sub>, K<sub>Y</sub>, M, H] = O[B<sub>Z</sub>, S, K, M] *<sub>S</sub> V[B<sub>Z</sub>, S, K<sub>Y</sub>, H]</li> <li>O[B, K<sub>Y</sub>, M<sub>Z</sub>, H] = <strong>AllToAll</strong><sub>Z-&gt;M</sub>(O[B<sub>Z</sub>, K<sub>Y</sub>, M, H])</li> <li>O[B, N<sub>YZ</sub>, H] = <strong>Reshape</strong>(O[B, K<sub>Y</sub>, M<sub>Z</sub>, H])</li> <li>X[B, D] {U<sub>YZ</sub>} = W<sub>O</sub>[N<sub>YZ</sub>, H, D] *<sub>N,H</sub> O[B, N<sub>YZ</sub>, H]</li> <li>X[B, D] = <strong>AllReduce</strong>(X[B, D] { U<sub>YZ</sub>})</li> </ol> <p>这相当复杂，但你可以大致了解它的工作原理。新的通信开销适中，因为它们作用于我们的小激活，作为回报，我们节省了大量的内存带宽来加载 KV（它们是静止的）。</p> </div> </details> <ul> <li> <strong>序列分片：</strong> 如果批量大小太小，或者上下文很长，我们可以对 KV 缓存进行序列分片。同样，我们在这里为跨分片累积注意力付出了集体通信的代价。首先我们需要 AllGather Q 激活，然后以类似于 Flash Attention 的方式累积 KV。</li> </ul> <h2 id="designing-an-effective-inference-engine">设计高效的推理引擎</h2> <p>到目前为止，我们已经研究了如何独立地高效优化和分片单个预填充和生成操作。为了实际有效地使用它们，我们需要设计一个推理引擎，它可以在我们选择的延迟/吞吐量帕累托前沿的点上为这两个操作提供数据。</p> <p>最简单的方法是简单地运行一批预填充，然后运行一批生成：</p> <figure> <picture> <source class="responsive-img-srcset" sizes="95vw" srcset="https://jax-ml.github.io/scaling-book/assets/img/batched-prefill-480.webp 480w, https://jax-ml.github.io/scaling-book/assets/img/batched-prefill-800.webp 800w, https://jax-ml.github.io/scaling-book/assets/img/batched-prefill-1400.webp 1400w" type="image/webp"/> <img class="img-fluid" height="auto" loading="lazy" onerror="this.onerror=null; $('.responsive-img-srcset').remove();" src="https://jax-ml.github.io/scaling-book/assets/img/batched-prefill.png" width="100%"/> </picture> <figcaption class="caption"><b>图：</b>在最简单的设置中，请求被聚合，服务器在运行一批预填充和为所有序列调用生成函数直到完成之间交替进行。</figcaption> </figure> <p>这很容易实现，是大多数代码库中的第一个推理设置，但它有多个缺点：</p> <ol> <li> <strong>延迟很糟糕。</strong> 我们将预填充和生成的批量大小耦合在一起。在大的预填充批量下，首词元时间（TTFT）非常糟糕——你需要完成所有预填充后，用户才能看到任何词元。在小的批量下，生成吞吐量很糟糕。</li> <li> <strong>我们让较短的生成被较长的生成阻塞。</strong> 许多序列会比其他序列先完成，在生成期间留下空的批次槽位，进一步损害生成吞吐量。随着批量大小和生成长度的增加，这个问题会加剧。</li> <li> <strong>预填充被填充。</strong> 预填充被填充到最长的序列，我们浪费了大量的计算。对此有解决方案，但历史上 XLA 使得跳过这些 FLOPs 相当困难。同样，批量大小和预填充序列长度越大，情况越糟。</li> <li> <strong>我们被迫在预填充和生成之间共享一个分片策略。</strong> 预填充和生成都在同一个切片上运行，这意味着我们对两者使用相同的拓扑和分片（除非你保留两份权重副本），这通常对性能无益，例如，生成需要更多的模型分片。</li> </ol> <p>因此，这种方法只推荐用于边缘应用（通常只关心服务单个用户并使用 FLOPs/字节较少的硬件）和 Transformer 代码库生命周期早期的快速迭代（由于其简单性）。</p> <p>一种稍微好一点的方法是在批量大小为 1 时执行预填充（此时它是计算密集型的，但延迟合理），但在生成期间将多个请求批处理在一起：</p> <figure> <picture> <source class="responsive-img-srcset" sizes="95vw" srcset="https://jax-ml.github.io/scaling-book/assets/img/interleaving-480.webp 480w, https://jax-ml.github.io/scaling-book/assets/img/interleaving-800.webp 800w, https://jax-ml.github.io/scaling-book/assets/img/interleaving-1400.webp 1400w" type="image/webp"/> <img class="img-fluid" height="auto" loading="lazy" onerror="this.onerror=null; $('.responsive-img-srcset').remove();" src="https://jax-ml.github.io/scaling-book/assets/img/interleaving.png" width="100%"/> </picture> </figure> <p>这将避免因批处理预填充而浪费的 TTFT，同时保持较高的生成吞吐量。我们称之为<strong>交错</strong>配置，因为我们“交错”了预填充和生成步骤。这对于批量生成应用（如评估）非常强大，其中吞吐量是主要目标。协调器可以配置为在任何生成槽位空闲时优先进行预填充，即使对于非常大的生成批量大小也能确保高利用率。我们还可以避免将预填充填充到最大长度，因为它没有与另一个请求批处理。</p> <p>主要缺点是，当服务器正在执行预填充时，所有其他请求的生成都会暂停，因为所有计算资源都将被预填充消耗。用户 A 的响应正在解码，将被用户 B 的预填充阻塞。这意味着即使 TTFT 得到了改善，词元生成平均也会出现抖动和缓慢，这对许多应用来说不是一个好的用户体验——其他用户的预填充处于请求总延迟的关键路径上。</p> <p>为了解决这个问题，我们将解码和预填充分开。虽然 Transformer 推理可以在一个服务器上完成，但从延迟的角度来看，将这两个不同的任务在两组 TPU/GPU 上执行通常更好。预填充服务器生成 KV 缓存，这些缓存通过网络发送到生成服务器，生成服务器将多个缓存批处理在一起并为它们中的每一个生成词元。我们称之为<strong>“解耦”</strong>服务。</p> <figure> <picture> <source class="responsive-img-srcset" sizes="95vw" srcset="https://jax-ml.github.io/scaling-book/assets/img/disaggregation-480.webp 480w, https://jax-ml.github.io/scaling-book/assets/img/disaggregation-800.webp 800w, https://jax-ml.github.io/scaling-book/assets/img/disaggregation-1400.webp 1400w" type="image/webp"/> <img class="img-fluid" height="auto" loading="lazy" onerror="this.onerror=null; $('.responsive-img-srcset').remove();" src="https://jax-ml.github.io/scaling-book/assets/img/disaggregation.png" width="100%"/> </picture> </figure> <p>这提供了几个优势：</p> <ol> <li> <p><strong>大规模下的低延迟</strong>：用户的请求永远不会被另一个用户的请求阻塞，除非预填充容量不足。请求应该立即被预填充，然后发送到生成服务器，然后立即插入生成缓冲区。如果我们预计会有许多并发请求进来，我们可以独立于生成服务器的数量来扩展预填充服务器的数量，这样用户就不会在预填充队列中等待太长时间。</p> </li> <li> <p><strong>专业化：</strong> 很多时候，预填充和生成的延迟最优参数分片策略/硬件拓扑是相当不同的（例如，更多的模型并行性对生成有用，但对预填充没用）。将这两个操作限制在同一个分片策略下会损害两者的性能，而拥有两套权重会占用内存。此外，通过将预填充移到自己的服务器上，它就不需要持有任何 KV 缓存，除了它当前正在处理的那个。这意味着我们有更多的内存可用于历史缓存（见下一节）或优化预填充延迟。</p> </li> </ol> <p>一个缺点是 KV 缓存现在需要在网络上传输。这通常是可以接受的，但再次为减小 KV 缓存大小提供了动力。</p> <p class="takeaway"><strong>要点：</strong> 对于延迟敏感、高吞吐量的服务，我们通常必须将预填充和生成分离到不同的服务器上，预填充以批次 1 运行，而生成则将许多并发请求批处理在一起。</p> <h3 id="continuous-batching">连续批处理</h3> <p>上面的问题 (2) 激发了<strong>连续批处理</strong>的概念。我们优化并编译：</p> <ul> <li>一些具有可变上下文长度的预填充函数，并将其插入到某个 KV 缓冲区中，该缓冲区具有最大批量大小和上下文长度/页数。</li> <li>一个生成函数，它接收 KV 缓存，并为所有当前活动的请求执行生成步骤。</li> </ul> <p>然后，我们将这些函数与一个协调器结合起来，该协调器对传入的请求进行排队，根据可用的生成槽位调用预填充和生成，处理历史缓存（见下一节），并以流式方式输出词元。</p> <figure> <picture> <source class="responsive-img-srcset" sizes="95vw" srcset="https://jax-ml.github.io/scaling-book/assets/img/continuous-batching-480.webp 480w, https://jax-ml.github.io/scaling-book/assets/img/continuous-batching-800.webp 800w, https://jax-ml.github.io/scaling-book/assets/img/continuous-batching-1400.webp 1400w" type="image/webp"/> <img class="img-fluid" height="auto" loading="lazy" onerror="this.onerror=null; $('.responsive-img-srcset').remove();" src="https://jax-ml.github.io/scaling-book/assets/img/continuous-batching.gif" width="100%"/> </picture> </figure> <h3 id="prefix-caching">前缀缓存</h3> <p>由于预填充成本高且受计算限制（给我们留下的空间较少），减少其成本的最佳方法之一就是少做一些。因为 LLM 是自回归的，查询 [“我”, “喜欢”, “狗”] 和 [“我”, “喜欢”, “猫”] 产生的 KV 缓存在前两个词元上是相同的。这意味着，原则上，如果我们先计算“我喜欢狗”的缓存，然后再计算“我喜欢猫”的缓存，我们只需要做 1/3 的计算。我们可以通过重用缓存来节省大部分工作。这在一些特定情况下尤其强大：</p> <ol> <li> <strong>聊天机器人</strong>：大多数聊天机器人对话都涉及一种严格追加自身的来回对话。这意味着如果我们能保存每次对话轮次的 KV 缓存，我们就可以跳过除最新词元外的所有计算。</li> <li> <strong>少样本提示</strong>：如果我们有任何形式的少样本提示，这可以被保存并免费重用。系统指令通常也具有这种形式。</li> </ol> <p>这样做之所以困难，唯一的限制是内存。正如我们所见，KV 缓存很大（通常是几 GB），要使缓存有用，我们需要将它们保留到后续查询到达。通常，预填充服务器上任何未使用的 HBM 都可以用于本地缓存系统。此外，加速器通常在其 CPU 主机上有很多内存（例如，一个 8xTPUv5e 服务器有 128GiB 的 HBM，但大约有 450GiB 的主机 DRAM）。这种内存比 HBM 慢得多——通常慢到无法进行生成步骤——但对于缓存读取来说足够快。在实践中：</p> <ul> <li>因为 KV 缓存是处理初始请求的 TPU 集合的本地缓存，我们需要某种形式的亲和性路由来确保后续查询到达同一个副本。这可能会导致负载均衡问题。</li> <li>一个更小的 KV 缓存（再次）是有帮助的——它使我们能够在相同数量的空间中保存更多的 KV 缓存，并减少读取时间。</li> <li>KV 缓存及其查找可以很自然地存储在树或前缀树中。可以基于 LRU（最近最少使用）原则进行驱逐。</li> </ul> <figure> <picture> <source class="responsive-img-srcset" sizes="95vw" srcset="https://jax-ml.github.io/scaling-book/assets/img/prefix-caching-trie-480.webp 480w, https://jax-ml.github.io/scaling-book/assets/img/prefix-caching-trie-800.webp 800w, https://jax-ml.github.io/scaling-book/assets/img/prefix-caching-trie-1400.webp 1400w" type="image/webp"/> <img class="img-fluid" height="auto" loading="lazy" onerror="this.onerror=null; $('.responsive-img-srcset').remove();" src="https://jax-ml.github.io/scaling-book/assets/img/prefix-caching-trie.png" width="100%"/> </picture> <figcaption class="caption"><b>图：</b>以 LRU 前缀树实现的 KV 前缀缓存。我们可以通过共享前缀来避免重复的 KV 内存。来源：<a href="https://research.character.ai/optimizing-inference/?ref=blog.character.ai" rel="external nofollow noopener" target="_blank">Character.ai 博客</a>。</figcaption> </figure> <h3 id="let-s-look-at-an-implementation-jetstream">来看一个实现：JetStream</h3> <p>谷歌开源了一个实现这种逻辑的库，名为 <a href="https://github.com/google/JetStream" rel="external nofollow noopener" target="_blank">JetStream</a>。该服务器有一组“预填充引擎”和“生成引擎”，通常位于不同的 TPU 切片上，由一个控制器进行协调。预填充发生在“<a href="https://github.com/AI-Hypercomputer/JetStream/blob/c0f83127c16d7861cacc560303a28404c6cbb24c/jetstream/core/orchestrator.py#L499" rel="external nofollow noopener" target="_blank">预填充线程</a>”中，而生成发生在“<a href="https://github.com/AI-Hypercomputer/JetStream/blob/c0f83127c16d7861cacc560303a28404c6cbb24c/jetstream/core/orchestrator.py#L629" rel="external nofollow noopener" target="_blank">生成线程</a>”中。我们还有一个“<a href="https://github.com/AI-Hypercomputer/JetStream/blob/c0f83127c16d7861cacc560303a28404c6cbb24c/jetstream/core/orchestrator.py#L592" rel="external nofollow noopener" target="_blank">传输线程</a>”，负责协调将 KV 缓存从预填充切片复制到生成切片。</p> <p>Engine 接口（<a href="https://github.com/google/JetStream/blob/445f1aa8e857d0a09d72618e365daf80723bdf4c/jetstream/engine/engine_api.py#L138" rel="external nofollow noopener" target="_blank">在此实现</a>）是任何 LLM 必须提供的通用接口。关键方法是：</p> <ul> <li> <strong>prefill:</strong> 接收一组输入词元并生成一个 KV 缓存。</li> <li> <strong>insert:</strong> 接收一个 KV 缓存并将其插入到生成正在处理的 KV 缓存批次中。</li> <li> <strong>generate:</strong> 接收一批 KV 缓存并为每个批次条目生成一个词元，将单个词元的 KV 缓存附加到每个词元的解码状态中。</li> </ul> <p>我们还有一个可用的 PyTorch 版本的 JetStream <a href="https://github.com/google/jetstream-pytorch" rel="external nofollow noopener" target="_blank">在此</a>。</p> <h2 id="worked-problems">习题</h2> <p>在本节中，我将基于 LLaMA-2 13B 发明一个新模型。以下是详细信息：</p> <table class="table-hover" data-toggle="table"> <thead> <tr> <th style="text-align: left">超参数</th> <th style="text-align: left">值</th> </tr> </thead> <tbody> <tr> <td style="text-align: left">L (num_layers)</td> <td style="text-align: left">64</td> </tr> <tr> <td style="text-align: left">D (d_model)</td> <td style="text-align: left">4,096</td> </tr> <tr> <td style="text-align: left">F (ffw_dimension)</td> <td style="text-align: left">16,384</td> </tr> <tr> <td style="text-align: left">N (num_heads)</td> <td style="text-align: left">32</td> </tr> <tr> <td style="text-align: left">K (num_kv_heads)</td> <td style="text-align: left">8</td> </tr> <tr> <td style="text-align: left">H (qkv_dim)</td> <td style="text-align: left">256</td> </tr> <tr> <td style="text-align: left">V (num_embeddings)</td> <td style="text-align: left">32,128</td> </tr> </tbody> </table> <p><strong>问题 1：</strong> 上述模型有多少参数？其 KV 缓存每个词元在 int8 下有多大？<em>你可以假设我们共享输入和输出投影矩阵。</em></p> <details><summary>点击此处查看答案。</summary> <p><strong>参数数量：</strong></p> <ul> <li>MLP 参数数量: <d-math>L * D * F * 3</d-math></li> <li>注意力参数数量: <d-math>L * 2 * D * H * (N + K)</d-math></li> <li>词汇表参数: <d-math>D * V</d-math> (因为我们共享这些矩阵)</li> </ul> <p>因此，我们的总参数数量是 <d-math>L * D * (3F + 2H * (N + K)) + D * V</d-math>。代入上面的数字，我们有 <code class="language-plaintext highlighter-rouge">64 * 4096 * (3*16384 + 2 * 256 * (32 + 8)) + 4096 * 32128 = 18.4e9</code>。因此，这个模型大约有 184 亿个参数。</p> <p>KV 缓存是 <d-math>L * K * H</d-math> 每个词元，即 <code class="language-plaintext highlighter-rouge">64 * 8 * 256 = 131kB</code> 每个词元。</p> </details> <p><strong>问题 2：</strong> 假设我们想在一个 TPUv5e 4x4 切片上服务这个模型，并且可以完全在此拓扑上分片我们的 KV 缓存。假设我们对所有东西都使用 int8，并且希望支持 128k 序列，那么我们能容纳的最大批量大小是多少？如果我们将 KV 头的数量减少到 1 呢？</p> <details><summary>点击此处查看答案。</summary> <p>我们的 KV 缓存每个词元在 int8 下的大小为 <d-math>L * K * H</d-math>，即 <code class="language-plaintext highlighter-rouge">64 * 8 * 256 = 131kB</code>。对于 128k 序列，这意味着每个批次条目为 <code class="language-plaintext highlighter-rouge">131e3 * 128e3 = 16.8GB</code>。由于每个 TPU 有 16GB 的 HBM，包括我们的参数，我们能容纳的最大批量大小是 <code class="language-plaintext highlighter-rouge">(16 * 16e9 - 18.4e9) / 16.8e9 = 14</code>。如果我们有 <d-math>K=1</d-math>，我们将拥有这个值的 8 倍，即大约 112。</p> </details> <p><strong>问题 3：</strong> 假设所有参数在 TPU v5e 4x4 切片上完全分片，将它们从 HBM 加载到 MXU 需要多长时间？假设是 int8 参数。<em>这是每步延迟的一个很好的下界。</em></p> <details><summary>点击此处查看答案。</summary> <p>我们总共有 18.4B 个参数，在 int8 中是 18.4e9 字节。每个芯片的 HBM 带宽为 8.1e11，所以大约需要 <code class="language-plaintext highlighter-rouge">18e9 / (8.1e11 * 16) = 1.3ms</code>，假设我们可以完全利用我们的 HBM 带宽。</p> </details> <p><strong>问题 4：</strong> 假设我们想在一个 TPUv5e 4x4 切片上使用 int8 FLOPs 和参数/激活来服务这个模型。我们将如何为预填充和解码进行分片？<em>提示：也许先回答这些问题：</em></p> <ol> <li>4x4 上的 ICI 是什么样的？</li> <li>张量并行性的屋顶线界限是什么？</li> <li>我们如何分片 KV 缓存？</li> </ol> <p>对于这种分片，生成的粗略每步延迟是多少？</p> <p><strong>问题 5：</strong> 让我们假装上述模型实际上是一个 MoE。一个 MoE 模型实际上是一个具有 E 个 FFW 块副本的密集模型。每个词元通过 k 个 FFW 块，并将这 <code class="language-plaintext highlighter-rouge">k</code> 个的输出平均以产生最终输出。让我们使用 <code class="language-plaintext highlighter-rouge">E=16</code> 和 <code class="language-plaintext highlighter-rouge">k=2</code> 以及上述设置。</p> <ol> <li>它有多少总参数和激活参数？<em>激活参数指任何给定词元使用的参数。</em> </li> <li>在 TPU v5e 上达到 FLOPs 密集型需要多大的批量大小？</li> <li>它的 KV 缓存每个词元有多大？</li> <li>一个 T 个词元的正向传播涉及多少 FLOPs？</li> </ol> <details><summary>点击此处查看答案。</summary> <p>(1) 作为一个 MoE，每个 MLP 块现在有 <d-math>3 * E * D * F</d-math> 个参数，比密集变体增加了 <d-math>E</d-math> 倍。因此，它现在有 <d-math>L * D * (3EF + 2H * (N + K)) + D * V</d-math> 或 <code class="language-plaintext highlighter-rouge">64 * 4096 * (3*16*16384 + 2 * 256 * (32 + 8)) + 4096 * 32128 = 212e9</code> 个总参数，增加了约 12 倍。对于激活参数，我们有 <d-math>k</d-math> 而不是 <d-math>E</d-math> 个激活参数，总共为 <code class="language-plaintext highlighter-rouge">64 * 4096 * (3*2*16384 + 2 * 256 * (32 + 8)) + 4096 * 32128 = 31.2e9</code>，比密集变体增加了不到 2 倍。</p> <p>(2) 因为我们的参数增加了 <d-math>E</d-math> 倍，而 FLOPs 只增加了 <d-math>k</d-math> 倍，我们的 HBM 屋顶线增加了 <d-math>E/k</d-math> 倍。这意味着在 TPU v5e 上，我们需要大约 <code class="language-plaintext highlighter-rouge">240 * (16 / 2) = 1920</code> 个词元。</p> <p>(3) KV 缓存大小保持不变，因为 MoE 的特性不改变任何关于注意力机制的东西。</p> <p>(4) 这仍然是 <d-math>2ND</d-math>，其中 <d-math>D</d-math> 是激活参数计数。因此这是 <d-math>2 * \text{32.2e9} * T</d-math>。</p> </details> <p><strong>问题 6：</strong> 对于 MoE，我们可以进行“专家分片”，即我们将我们的专家分布在网格的一个轴上。在我们的标准表示法中，我们的第一个 FFW 权重形状为 <code class="language-plaintext highlighter-rouge">[E, D, F]</code>，我们将其分片为 [E<sub>Z</sub>, D<sub>X</sub>, F<sub>Y</sub>]，其中 <code class="language-plaintext highlighter-rouge">X</code> 仅在训练期间用作我们的 FSDP 维度。假设我们想在 TPU v5e 上进行推理：</p> <ol> <li>在 TPU v5e 8x16 切片上，Y=8, Z=16 时，上述模型的 HBM 权重加载时间是多少？每个 TPU 有多少可用的 HBM？</li> <li>我们能将我们的模型容纳在的最小切片是多大？</li> </ol> <p><strong>问题 7 [2D 模型分片]：</strong> 在这里，我们将详细计算 <a href="https://arxiv.org/pdf/2211.05102" rel="external nofollow noopener" target="_blank">ESTI 论文</a>中所谓的 2D 权重固定分片。我们在附录 B 中简要描述了这一点，但请先尝试做这个问题，看看你是否能推导出数学。2D 权重固定分片的基本思想是沿着 <d-math>D</d-math> 和 <d-math>F</d-math> 两个轴对我们的权重进行分片，使得每个块大致是方形的。这减少了通信负载，并允许我们扩展得更远一些。</p> <p>这是 2D 权重固定的算法：</p> <div class="algorithm"> <ol> <li>In[B, D<sub>X</sub>] = <strong>AllGather</strong><sub>YZ</sub>(In[B, D<sub>XYZ</sub>])</li> <li>Tmp[B, F<sub>YZ</sub>] {U.X} = In[B, D<sub>X</sub>] *<sub>D</sub> W<sub>in</sub>[D<sub>X</sub>, F<sub>YZ</sub>]</li> <li>Tmp[B, F<sub>YZ</sub>] = <strong>AllReduce</strong><sub>X</sub>(Tmp[B, F<sub>YZ</sub>] {U.X})</li> <li>Out[B, D<sub>X</sub>] {U.YZ} = Tmp[B, F<sub>YZ</sub>] *<sub>F</sub> W2[F<sub>YZ</sub>, D<sub>X</sub>]</li> <li>Out[B, D<sub>XYZ</sub>] = <strong>ReduceScatter</strong><sub>YZ</sub>(Out[B, D<sub>X</sub>] {U.YZ})</li> </ol> </div> <p>你的目标是计算这个算法的 <d-math>T_\text{math}</d-math> 和 <d-math>T_\text{comms}</d-math>，并找出它何时会优于传统的 3D 模型分片？</p> <details><summary>点击此处查看答案！</summary> <p>让我们计算 <d-math>T_\text{math}</d-math> 和 <d-math>T_\text{comms}</d-math>。我们所有的 FLOPs 都是完全分片的，所以和之前一样，我们有 <d-math>T_\text{math} = 4BDF / (N \cdot C)</d-math>，但我们的通信现在是</p> <mjx-container class="MathJax CtxtMenu_Attached_0" ctxtmenu_counter="30" display="true" jax="CHTML" style="font-size: 116.9%; position: relative;" tabindex="0"><mjx-math aria-hidden="true" class="MJX-TEX" display="true" style="margin-left: 0px; margin-right: 0px;"><mjx-mtable style="min-width: 31.207em;"><mjx-table><mjx-itable><mjx-mtr><mjx-mtd style="text-align: right;"><mjx-msub><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D447 TEX-I"></mjx-c></mjx-mi><mjx-script style="vertical-align: -0.15em; margin-left: -0.12em;"><mjx-mtext class="mjx-n" size="s"><mjx-c class="mjx-c32"></mjx-c><mjx-c class="mjx-c44"></mjx-c><mjx-c class="mjx-c20"></mjx-c><mjx-c class="mjx-c63"></mjx-c><mjx-c class="mjx-c6F"></mjx-c><mjx-c class="mjx-c6D"></mjx-c><mjx-c class="mjx-c6D"></mjx-c><mjx-c class="mjx-c73"></mjx-c></mjx-mtext></mjx-script></mjx-msub><mjx-mo class="mjx-n" space="4"><mjx-c class="mjx-c3D"></mjx-c></mjx-mo><mjx-mfrac space="4"><mjx-frac type="d"><mjx-num><mjx-nstrut type="d"></mjx-nstrut><mjx-mrow><mjx-mn class="mjx-n"><mjx-c class="mjx-c32"></mjx-c></mjx-mn><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D435 TEX-I"></mjx-c></mjx-mi><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D437 TEX-I"></mjx-c></mjx-mi></mjx-mrow></mjx-num><mjx-dbox><mjx-dtable><mjx-line type="d"></mjx-line><mjx-row><mjx-den><mjx-dstrut type="d"></mjx-dstrut><mjx-mrow><mjx-mn class="mjx-n"><mjx-c class="mjx-c32"></mjx-c></mjx-mn><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D44B TEX-I"></mjx-c></mjx-mi><mjx-mo class="mjx-n" space="3"><mjx-c class="mjx-c22C5"></mjx-c></mjx-mo><mjx-msub space="3"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D44A TEX-I"></mjx-c></mjx-mi><mjx-script style="vertical-align: -0.15em; margin-left: -0.104em;"><mjx-mtext class="mjx-n" size="s"><mjx-c class="mjx-c69"></mjx-c><mjx-c class="mjx-c63"></mjx-c><mjx-c class="mjx-c69"></mjx-c></mjx-mtext></mjx-script></mjx-msub></mjx-mrow></mjx-den></mjx-row></mjx-dtable></mjx-dbox></mjx-frac></mjx-mfrac><mjx-mo class="mjx-n" space="3"><mjx-c class="mjx-c2B"></mjx-c></mjx-mo><mjx-mfrac space="3"><mjx-frac type="d"><mjx-num><mjx-nstrut type="d"></mjx-nstrut><mjx-mrow><mjx-mn class="mjx-n"><mjx-c class="mjx-c34"></mjx-c></mjx-mn><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D435 TEX-I"></mjx-c></mjx-mi><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D439 TEX-I"></mjx-c></mjx-mi></mjx-mrow></mjx-num><mjx-dbox><mjx-dtable><mjx-line type="d"></mjx-line><mjx-row><mjx-den><mjx-dstrut type="d"></mjx-dstrut><mjx-mrow><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D44C TEX-I"></mjx-c></mjx-mi><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D44D TEX-I"></mjx-c></mjx-mi><mjx-mo class="mjx-n" space="3"><mjx-c class="mjx-c22C5"></mjx-c></mjx-mo><mjx-msub space="3"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D44A TEX-I"></mjx-c></mjx-mi><mjx-script style="vertical-align: -0.15em; margin-left: -0.104em;"><mjx-mtext class="mjx-n" size="s"><mjx-c class="mjx-c69"></mjx-c><mjx-c class="mjx-c63"></mjx-c><mjx-c class="mjx-c69"></mjx-c></mjx-mtext></mjx-script></mjx-msub></mjx-mrow></mjx-den></mjx-row></mjx-dtable></mjx-dbox></mjx-frac></mjx-mfrac><mjx-mo class="mjx-n" space="3"><mjx-c class="mjx-c2B"></mjx-c></mjx-mo><mjx-mfrac space="3"><mjx-frac type="d"><mjx-num><mjx-nstrut type="d"></mjx-nstrut><mjx-mrow><mjx-mn class="mjx-n"><mjx-c class="mjx-c32"></mjx-c></mjx-mn><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D435 TEX-I"></mjx-c></mjx-mi><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D437 TEX-I"></mjx-c></mjx-mi></mjx-mrow></mjx-num><mjx-dbox><mjx-dtable><mjx-line type="d"></mjx-line><mjx-row><mjx-den><mjx-dstrut type="d"></mjx-dstrut><mjx-mrow><mjx-mn class="mjx-n"><mjx-c class="mjx-c32"></mjx-c></mjx-mn><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D44B TEX-I"></mjx-c></mjx-mi><mjx-mo class="mjx-n" space="3"><mjx-c class="mjx-c22C5"></mjx-c></mjx-mo><mjx-msub space="3"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D44A TEX-I"></mjx-c></mjx-mi><mjx-script style="vertical-align: -0.15em; margin-left: -0.104em;"><mjx-mtext class="mjx-n" size="s"><mjx-c class="mjx-c69"></mjx-c><mjx-c class="mjx-c63"></mjx-c><mjx-c class="mjx-c69"></mjx-c></mjx-mtext></mjx-script></mjx-msub></mjx-mrow></mjx-den></mjx-row></mjx-dtable></mjx-dbox></mjx-frac></mjx-mfrac><mjx-mo class="mjx-n" space="4"><mjx-c class="mjx-c3D"></mjx-c></mjx-mo><mjx-mfrac space="4"><mjx-frac type="d"><mjx-num><mjx-nstrut type="d"></mjx-nstrut><mjx-mrow><mjx-mn class="mjx-n"><mjx-c class="mjx-c32"></mjx-c></mjx-mn><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D435 TEX-I"></mjx-c></mjx-mi><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D437 TEX-I"></mjx-c></mjx-mi></mjx-mrow></mjx-num><mjx-dbox><mjx-dtable><mjx-line type="d"></mjx-line><mjx-row><mjx-den><mjx-dstrut type="d"></mjx-dstrut><mjx-mrow><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D44B TEX-I"></mjx-c></mjx-mi><mjx-mo class="mjx-n" space="3"><mjx-c class="mjx-c22C5"></mjx-c></mjx-mo><mjx-msub space="3"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D44A TEX-I"></mjx-c></mjx-mi><mjx-script style="vertical-align: -0.15em; margin-left: -0.104em;"><mjx-mtext class="mjx-n" size="s"><mjx-c class="mjx-c69"></mjx-c><mjx-c class="mjx-c63"></mjx-c><mjx-c class="mjx-c69"></mjx-c></mjx-mtext></mjx-script></mjx-msub></mjx-mrow></mjx-den></mjx-row></mjx-dtable></mjx-dbox></mjx-frac></mjx-mfrac><mjx-mo class="mjx-n" space="3"><mjx-c class="mjx-c2B"></mjx-c></mjx-mo><mjx-mfrac space="3"><mjx-frac type="d"><mjx-num><mjx-nstrut type="d"></mjx-nstrut><mjx-mrow><mjx-mn class="mjx-n"><mjx-c class="mjx-c34"></mjx-c></mjx-mn><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D435 TEX-I"></mjx-c></mjx-mi><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D439 TEX-I"></mjx-c></mjx-mi></mjx-mrow></mjx-num><mjx-dbox><mjx-dtable><mjx-line type="d"></mjx-line><mjx-row><mjx-den><mjx-dstrut type="d"></mjx-dstrut><mjx-mrow><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D44C TEX-I"></mjx-c></mjx-mi><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D44D TEX-I"></mjx-c></mjx-mi><mjx-mo class="mjx-n" space="3"><mjx-c class="mjx-c22C5"></mjx-c></mjx-mo><mjx-msub space="3"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D44A TEX-I"></mjx-c></mjx-mi><mjx-script style="vertical-align: -0.15em; margin-left: -0.104em;"><mjx-mtext class="mjx-n" size="s"><mjx-c class="mjx-c69"></mjx-c><mjx-c class="mjx-c63"></mjx-c><mjx-c class="mjx-c69"></mjx-c></mjx-mtext></mjx-script></mjx-msub></mjx-mrow></mjx-den></mjx-row></mjx-dtable></mjx-dbox></mjx-frac></mjx-mfrac><mjx-tstrut></mjx-tstrut></mjx-mtd></mjx-mtr></mjx-itable></mjx-table></mjx-mtable></mjx-math><mjx-assistive-mml display="block" unselectable="on"><math display="block" xmlns="http://www.w3.org/1998/Math/MathML"><mtable columnalign="right" columnspacing="" displaystyle="true" rowspacing="3pt"><mtr><mtd><msub><mi>T</mi><mtext>2D comms</mtext></msub><mo>=</mo><mfrac><mrow><mn>2</mn><mi>B</mi><mi>D</mi></mrow><mrow><mn>2</mn><mi>X</mi><mo>⋅</mo><msub><mi>W</mi><mtext>ici</mtext></msub></mrow></mfrac><mo>+</mo><mfrac><mrow><mn>4</mn><mi>B</mi><mi>F</mi></mrow><mrow><mi>Y</mi><mi>Z</mi><mo>⋅</mo><msub><mi>W</mi><mtext>ici</mtext></msub></mrow></mfrac><mo>+</mo><mfrac><mrow><mn>2</mn><mi>B</mi><mi>D</mi></mrow><mrow><mn>2</mn><mi>X</mi><mo>⋅</mo><msub><mi>W</mi><mtext>ici</mtext></msub></mrow></mfrac><mo>=</mo><mfrac><mrow><mn>2</mn><mi>B</mi><mi>D</mi></mrow><mrow><mi>X</mi><mo>⋅</mo><msub><mi>W</mi><mtext>ici</mtext></msub></mrow></mfrac><mo>+</mo><mfrac><mrow><mn>4</mn><mi>B</mi><mi>F</mi></mrow><mrow><mi>Y</mi><mi>Z</mi><mo>⋅</mo><msub><mi>W</mi><mtext>ici</mtext></msub></mrow></mfrac></mtd></mtr></mtable></math></mjx-assistive-mml></mjx-container> <p>我们注意到 AllReduce 的成本是原来的两倍，并且我们根据每个操作执行的轴数来缩放我们的通信。假设我们可以自由选择拓扑结构，并假设 <d-math>F=4D</d-math>（如 LLaMA-2 中），我们声称（通过一些基本微积分）<d-math>X</d-math>、<d-math>Y</d-math> 和 <d-math>Z</d-math> 的最优值是 <d-math>X = \sqrt{N / 8}</d-math>、<d-math>YZ = \sqrt{8N}</d-math>，所以总通信量是</p> <mjx-container class="MathJax CtxtMenu_Attached_0" ctxtmenu_counter="31" display="true" jax="CHTML" style="font-size: 116.9%; position: relative;" tabindex="0"><mjx-math aria-hidden="true" class="MJX-TEX" display="true" style="margin-left: 0px; margin-right: 0px;"><mjx-msub><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D447 TEX-I"></mjx-c></mjx-mi><mjx-script style="vertical-align: -0.15em; margin-left: -0.12em;"><mjx-mtext class="mjx-n" size="s"><mjx-c class="mjx-c32"></mjx-c><mjx-c class="mjx-c44"></mjx-c><mjx-c class="mjx-c20"></mjx-c><mjx-c class="mjx-c63"></mjx-c><mjx-c class="mjx-c6F"></mjx-c><mjx-c class="mjx-c6D"></mjx-c><mjx-c class="mjx-c6D"></mjx-c><mjx-c class="mjx-c73"></mjx-c></mjx-mtext></mjx-script></mjx-msub><mjx-mo class="mjx-n" space="4"><mjx-c class="mjx-c3D"></mjx-c></mjx-mo><mjx-mfrac space="4"><mjx-frac type="d"><mjx-num><mjx-nstrut type="d"></mjx-nstrut><mjx-mrow><mjx-mn class="mjx-n"><mjx-c class="mjx-c32"></mjx-c></mjx-mn><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D435 TEX-I"></mjx-c></mjx-mi></mjx-mrow></mjx-num><mjx-dbox><mjx-dtable><mjx-line type="d"></mjx-line><mjx-row><mjx-den><mjx-dstrut type="d"></mjx-dstrut><mjx-msub><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D44A TEX-I"></mjx-c></mjx-mi><mjx-script style="vertical-align: -0.15em; margin-left: -0.104em;"><mjx-mtext class="mjx-n" size="s"><mjx-c class="mjx-c69"></mjx-c><mjx-c class="mjx-c63"></mjx-c><mjx-c class="mjx-c69"></mjx-c></mjx-mtext></mjx-script></mjx-msub></mjx-den></mjx-row></mjx-dtable></mjx-dbox></mjx-frac></mjx-mfrac><mjx-mrow><mjx-mo class="mjx-s3"><mjx-c class="mjx-c28 TEX-S3"></mjx-c></mjx-mo><mjx-mfrac><mjx-frac type="d"><mjx-num><mjx-nstrut type="d"></mjx-nstrut><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D437 TEX-I"></mjx-c></mjx-mi></mjx-num><mjx-dbox><mjx-dtable><mjx-line type="d"></mjx-line><mjx-row><mjx-den><mjx-dstrut type="d"></mjx-dstrut><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D44B TEX-I"></mjx-c></mjx-mi></mjx-den></mjx-row></mjx-dtable></mjx-dbox></mjx-frac></mjx-mfrac><mjx-mo class="mjx-n" space="3"><mjx-c class="mjx-c2B"></mjx-c></mjx-mo><mjx-mfrac space="3"><mjx-frac type="d"><mjx-num><mjx-nstrut type="d"></mjx-nstrut><mjx-mrow><mjx-mn class="mjx-n"><mjx-c class="mjx-c38"></mjx-c></mjx-mn><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D437 TEX-I"></mjx-c></mjx-mi></mjx-mrow></mjx-num><mjx-dbox><mjx-dtable><mjx-line type="d"></mjx-line><mjx-row><mjx-den><mjx-dstrut type="d"></mjx-dstrut><mjx-mrow><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D44C TEX-I"></mjx-c></mjx-mi><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D44D TEX-I"></mjx-c></mjx-mi></mjx-mrow></mjx-den></mjx-row></mjx-dtable></mjx-dbox></mjx-frac></mjx-mfrac><mjx-mo class="mjx-s3"><mjx-c class="mjx-c29 TEX-S3"></mjx-c></mjx-mo></mjx-mrow><mjx-mo class="mjx-n" space="4"><mjx-c class="mjx-c3D"></mjx-c></mjx-mo><mjx-mfrac space="4"><mjx-frac type="d"><mjx-num><mjx-nstrut type="d"></mjx-nstrut><mjx-mrow><mjx-msqrt><mjx-sqrt><mjx-surd><mjx-mo class="mjx-n"><mjx-c class="mjx-c221A"></mjx-c></mjx-mo></mjx-surd><mjx-box style="padding-top: 0.163em;"><mjx-mn class="mjx-n"><mjx-c class="mjx-c31"></mjx-c><mjx-c class="mjx-c32"></mjx-c><mjx-c class="mjx-c38"></mjx-c></mjx-mn></mjx-box></mjx-sqrt></mjx-msqrt><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D435 TEX-I"></mjx-c></mjx-mi><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D437 TEX-I"></mjx-c></mjx-mi></mjx-mrow></mjx-num><mjx-dbox><mjx-dtable><mjx-line type="d"></mjx-line><mjx-row><mjx-den><mjx-dstrut type="d"></mjx-dstrut><mjx-mrow><mjx-msqrt><mjx-sqrt><mjx-surd><mjx-mo class="mjx-n"><mjx-c class="mjx-c221A"></mjx-c></mjx-mo></mjx-surd><mjx-box style="padding-top: 0.166em;"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D441 TEX-I"></mjx-c></mjx-mi></mjx-box></mjx-sqrt></mjx-msqrt><mjx-mo class="mjx-n" space="3"><mjx-c class="mjx-c22C5"></mjx-c></mjx-mo><mjx-msub space="3"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D44A TEX-I"></mjx-c></mjx-mi><mjx-script style="vertical-align: -0.15em; margin-left: -0.104em;"><mjx-mtext class="mjx-n" size="s"><mjx-c class="mjx-c69"></mjx-c><mjx-c class="mjx-c63"></mjx-c><mjx-c class="mjx-c69"></mjx-c></mjx-mtext></mjx-script></mjx-msub></mjx-mrow></mjx-den></mjx-row></mjx-dtable></mjx-dbox></mjx-frac></mjx-mfrac><mjx-mo class="mjx-n" space="4"><mjx-c class="mjx-c2248"></mjx-c></mjx-mo><mjx-mfrac space="4"><mjx-frac type="d"><mjx-num><mjx-nstrut type="d"></mjx-nstrut><mjx-mrow><mjx-mn class="mjx-n"><mjx-c class="mjx-c31"></mjx-c><mjx-c class="mjx-c31"></mjx-c><mjx-c class="mjx-c2E"></mjx-c><mjx-c class="mjx-c33"></mjx-c></mjx-mn><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D435 TEX-I"></mjx-c></mjx-mi><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D437 TEX-I"></mjx-c></mjx-mi></mjx-mrow></mjx-num><mjx-dbox><mjx-dtable><mjx-line type="d"></mjx-line><mjx-row><mjx-den><mjx-dstrut type="d"></mjx-dstrut><mjx-mrow><mjx-msqrt><mjx-sqrt><mjx-surd><mjx-mo class="mjx-n"><mjx-c class="mjx-c221A"></mjx-c></mjx-mo></mjx-surd><mjx-box style="padding-top: 0.166em;"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D441 TEX-I"></mjx-c></mjx-mi></mjx-box></mjx-sqrt></mjx-msqrt><mjx-mo class="mjx-n" space="3"><mjx-c class="mjx-c22C5"></mjx-c></mjx-mo><mjx-msub space="3"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D44A TEX-I"></mjx-c></mjx-mi><mjx-script style="vertical-align: -0.15em; margin-left: -0.104em;"><mjx-mtext class="mjx-n" size="s"><mjx-c class="mjx-c69"></mjx-c><mjx-c class="mjx-c63"></mjx-c><mjx-c class="mjx-c69"></mjx-c></mjx-mtext></mjx-script></mjx-msub></mjx-mrow></mjx-den></mjx-row></mjx-dtable></mjx-dbox></mjx-frac></mjx-mfrac></mjx-math><mjx-assistive-mml display="block" unselectable="on"><math display="block" xmlns="http://www.w3.org/1998/Math/MathML"><msub><mi>T</mi><mtext>2D comms</mtext></msub><mo>=</mo><mfrac><mrow><mn>2</mn><mi>B</mi></mrow><msub><mi>W</mi><mtext>ici</mtext></msub></mfrac><mrow data-mjx-texclass="INNER"><mo data-mjx-texclass="OPEN">(</mo><mfrac><mi>D</mi><mi>X</mi></mfrac><mo>+</mo><mfrac><mrow><mn>8</mn><mi>D</mi></mrow><mrow><mi>Y</mi><mi>Z</mi></mrow></mfrac><mo data-mjx-texclass="CLOSE">)</mo></mrow><mo>=</mo><mfrac><mrow><msqrt><mn>128</mn></msqrt><mi>B</mi><mi>D</mi></mrow><mrow><msqrt><mi>N</mi></msqrt><mo>⋅</mo><msub><mi>W</mi><mtext>ici</mtext></msub></mrow></mfrac><mo>≈</mo><mfrac><mrow><mn>11.3</mn><mi>B</mi><mi>D</mi></mrow><mrow><msqrt><mi>N</mi></msqrt><mo>⋅</mo><msub><mi>W</mi><mtext>ici</mtext></msub></mrow></mfrac></math></mjx-assistive-mml></mjx-container> <p>首先，从上面复制，正常的 1D 模型并行性会有 <d-math>T_\text{model parallel comms} = 4BD / (3 \cdot W_\text{ici})</d-math>，那么新的通信何时更小？我们有</p> <mjx-container class="MathJax CtxtMenu_Attached_0" ctxtmenu_counter="32" display="true" jax="CHTML" style="font-size: 116.9%; position: relative;" tabindex="0"><mjx-math aria-hidden="true" class="MJX-TEX" display="true" style="margin-left: 0px; margin-right: 0px;"><mjx-mtable style="min-width: 24.805em;"><mjx-table><mjx-itable><mjx-mtr><mjx-mtd style="text-align: right; padding-bottom: 0.15em;"><mjx-msub><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D447 TEX-I"></mjx-c></mjx-mi><mjx-script style="vertical-align: -0.15em; margin-left: -0.12em;"><mjx-mtext class="mjx-n" size="s"><mjx-c class="mjx-c6D"></mjx-c><mjx-c class="mjx-c6F"></mjx-c><mjx-c class="mjx-c64"></mjx-c><mjx-c class="mjx-c65"></mjx-c><mjx-c class="mjx-c6C"></mjx-c><mjx-c class="mjx-c20"></mjx-c><mjx-c class="mjx-c70"></mjx-c><mjx-c class="mjx-c61"></mjx-c><mjx-c class="mjx-c72"></mjx-c><mjx-c class="mjx-c61"></mjx-c><mjx-c class="mjx-c6C"></mjx-c><mjx-c class="mjx-c6C"></mjx-c><mjx-c class="mjx-c65"></mjx-c><mjx-c class="mjx-c6C"></mjx-c><mjx-c class="mjx-c20"></mjx-c><mjx-c class="mjx-c63"></mjx-c><mjx-c class="mjx-c6F"></mjx-c><mjx-c class="mjx-c6D"></mjx-c><mjx-c class="mjx-c6D"></mjx-c><mjx-c class="mjx-c73"></mjx-c></mjx-mtext></mjx-script></mjx-msub><mjx-mo class="mjx-n" space="4"><mjx-c class="mjx-c3E"></mjx-c></mjx-mo><mjx-msub space="4"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D447 TEX-I"></mjx-c></mjx-mi><mjx-script style="vertical-align: -0.15em; margin-left: -0.12em;"><mjx-mtext class="mjx-n" size="s"><mjx-c class="mjx-c32"></mjx-c><mjx-c class="mjx-c44"></mjx-c><mjx-c class="mjx-c20"></mjx-c><mjx-c class="mjx-c63"></mjx-c><mjx-c class="mjx-c6F"></mjx-c><mjx-c class="mjx-c6D"></mjx-c><mjx-c class="mjx-c6D"></mjx-c><mjx-c class="mjx-c73"></mjx-c></mjx-mtext></mjx-script></mjx-msub><mjx-mstyle><mjx-mspace style="width: 0.278em;"></mjx-mspace></mjx-mstyle><mjx-mo class="mjx-n" space="4"><mjx-c class="mjx-c27FA"></mjx-c></mjx-mo><mjx-mstyle><mjx-mspace style="width: 0.278em;"></mjx-mspace></mjx-mstyle><mjx-mfrac space="4"><mjx-frac type="d"><mjx-num><mjx-nstrut type="d"></mjx-nstrut><mjx-mrow><mjx-mn class="mjx-n"><mjx-c class="mjx-c34"></mjx-c></mjx-mn><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D435 TEX-I"></mjx-c></mjx-mi><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D437 TEX-I"></mjx-c></mjx-mi></mjx-mrow></mjx-num><mjx-dbox><mjx-dtable><mjx-line type="d"></mjx-line><mjx-row><mjx-den><mjx-dstrut type="d"></mjx-dstrut><mjx-mrow><mjx-mn class="mjx-n"><mjx-c class="mjx-c33"></mjx-c></mjx-mn><mjx-mo class="mjx-n" space="3"><mjx-c class="mjx-c22C5"></mjx-c></mjx-mo><mjx-msub space="3"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D44A TEX-I"></mjx-c></mjx-mi><mjx-script style="vertical-align: -0.15em; margin-left: -0.104em;"><mjx-mtext class="mjx-n" size="s"><mjx-c class="mjx-c69"></mjx-c><mjx-c class="mjx-c63"></mjx-c><mjx-c class="mjx-c69"></mjx-c></mjx-mtext></mjx-script></mjx-msub></mjx-mrow></mjx-den></mjx-row></mjx-dtable></mjx-dbox></mjx-frac></mjx-mfrac><mjx-mo class="mjx-n" space="4"><mjx-c class="mjx-c3E"></mjx-c></mjx-mo><mjx-mfrac space="4"><mjx-frac type="d"><mjx-num><mjx-nstrut type="d"></mjx-nstrut><mjx-mrow><mjx-msqrt><mjx-sqrt><mjx-surd><mjx-mo class="mjx-n"><mjx-c class="mjx-c221A"></mjx-c></mjx-mo></mjx-surd><mjx-box style="padding-top: 0.163em;"><mjx-mn class="mjx-n"><mjx-c class="mjx-c31"></mjx-c><mjx-c class="mjx-c32"></mjx-c><mjx-c class="mjx-c38"></mjx-c></mjx-mn></mjx-box></mjx-sqrt></mjx-msqrt><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D435 TEX-I"></mjx-c></mjx-mi><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D437 TEX-I"></mjx-c></mjx-mi></mjx-mrow></mjx-num><mjx-dbox><mjx-dtable><mjx-line type="d"></mjx-line><mjx-row><mjx-den><mjx-dstrut type="d"></mjx-dstrut><mjx-mrow><mjx-msqrt><mjx-sqrt><mjx-surd><mjx-mo class="mjx-n"><mjx-c class="mjx-c221A"></mjx-c></mjx-mo></mjx-surd><mjx-box style="padding-top: 0.166em;"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D441 TEX-I"></mjx-c></mjx-mi></mjx-box></mjx-sqrt></mjx-msqrt><mjx-mo class="mjx-n" space="3"><mjx-c class="mjx-c22C5"></mjx-c></mjx-mo><mjx-msub space="3"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D44A TEX-I"></mjx-c></mjx-mi><mjx-script style="vertical-align: -0.15em; margin-left: -0.104em;"><mjx-mtext class="mjx-n" size="s"><mjx-c class="mjx-c69"></mjx-c><mjx-c class="mjx-c63"></mjx-c><mjx-c class="mjx-c69"></mjx-c></mjx-mtext></mjx-script></mjx-msub></mjx-mrow></mjx-den></mjx-row></mjx-dtable></mjx-dbox></mjx-frac></mjx-mfrac><mjx-tstrut></mjx-tstrut></mjx-mtd></mjx-mtr><mjx-mtr><mjx-mtd style="text-align: right; padding-top: 0.15em;"><mjx-mstyle><mjx-mspace style="width: 0.278em;"></mjx-mspace></mjx-mstyle><mjx-mo class="mjx-n"><mjx-c class="mjx-c27FA"></mjx-c></mjx-mo><mjx-mstyle><mjx-mspace style="width: 0.278em;"></mjx-mspace></mjx-mstyle><mjx-mi class="mjx-i" space="4"><mjx-c class="mjx-c1D441 TEX-I"></mjx-c></mjx-mi><mjx-mo class="mjx-n" space="4"><mjx-c class="mjx-c3E"></mjx-c></mjx-mo><mjx-mn class="mjx-n" space="4"><mjx-c class="mjx-c31"></mjx-c><mjx-c class="mjx-c32"></mjx-c><mjx-c class="mjx-c38"></mjx-c></mjx-mn><mjx-mo class="mjx-n" space="3"><mjx-c class="mjx-c22C5"></mjx-c></mjx-mo><mjx-msup space="3"><mjx-mrow><mjx-mo class="mjx-s3"><mjx-c class="mjx-c28 TEX-S3"></mjx-c></mjx-mo><mjx-mfrac><mjx-frac type="d"><mjx-num><mjx-nstrut type="d"></mjx-nstrut><mjx-mn class="mjx-n"><mjx-c class="mjx-c33"></mjx-c></mjx-mn></mjx-num><mjx-dbox><mjx-dtable><mjx-line type="d"></mjx-line><mjx-row><mjx-den><mjx-dstrut type="d"></mjx-dstrut><mjx-mn class="mjx-n"><mjx-c class="mjx-c34"></mjx-c></mjx-mn></mjx-den></mjx-row></mjx-dtable></mjx-dbox></mjx-frac></mjx-mfrac><mjx-mo class="mjx-s3"><mjx-c class="mjx-c29 TEX-S3"></mjx-c></mjx-mo></mjx-mrow><mjx-script style="vertical-align: 1.177em;"><mjx-mn class="mjx-n" size="s"><mjx-c class="mjx-c32"></mjx-c></mjx-mn></mjx-script></mjx-msup><mjx-mo class="mjx-n" space="4"><mjx-c class="mjx-c3D"></mjx-c></mjx-mo><mjx-mn class="mjx-n" space="4"><mjx-c class="mjx-c38"></mjx-c><mjx-c class="mjx-c31"></mjx-c></mjx-mn><mjx-tstrut></mjx-tstrut></mjx-mtd></mjx-mtr></mjx-itable></mjx-table></mjx-mtable></mjx-math><mjx-assistive-mml display="block" unselectable="on"><math display="block" xmlns="http://www.w3.org/1998/Math/MathML"><mtable columnalign="right" columnspacing="" displaystyle="true" rowspacing="3pt"><mtr><mtd><msub><mi>T</mi><mtext>model parallel comms</mtext></msub><mo>&gt;</mo><msub><mi>T</mi><mtext>2D comms</mtext></msub><mstyle scriptlevel="0"><mspace width="0.278em"></mspace></mstyle><mo stretchy="false">⟺</mo><mstyle scriptlevel="0"><mspace width="0.278em"></mspace></mstyle><mfrac><mrow><mn>4</mn><mi>B</mi><mi>D</mi></mrow><mrow><mn>3</mn><mo>⋅</mo><msub><mi>W</mi><mtext>ici</mtext></msub></mrow></mfrac><mo>&gt;</mo><mfrac><mrow><msqrt><mn>128</mn></msqrt><mi>B</mi><mi>D</mi></mrow><mrow><msqrt><mi>N</mi></msqrt><mo>⋅</mo><msub><mi>W</mi><mtext>ici</mtext></msub></mrow></mfrac></mtd></mtr><mtr><mtd><mstyle scriptlevel="0"><mspace width="0.278em"></mspace></mstyle><mo stretchy="false">⟺</mo><mstyle scriptlevel="0"><mspace width="0.278em"></mspace></mstyle><mi>N</mi><mo>&gt;</mo><mn>128</mn><mo>⋅</mo><msup><mrow data-mjx-texclass="INNER"><mo data-mjx-texclass="OPEN">(</mo><mfrac><mn>3</mn><mn>4</mn></mfrac><mo data-mjx-texclass="CLOSE">)</mo></mrow><mn>2</mn></msup><mo>=</mo><mn>81</mn></mtd></mtr></mtable></math></mjx-assistive-mml></mjx-container> <p>对于一个通用的 <d-math>F</d-math>，我们声称这个条件是</p> <mjx-container class="MathJax CtxtMenu_Attached_0" ctxtmenu_counter="33" display="true" jax="CHTML" style="font-size: 116.9%; position: relative;" tabindex="0"><mjx-math aria-hidden="true" class="MJX-TEX" display="true" style="margin-left: 0px; margin-right: 0px;"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D441 TEX-I"></mjx-c></mjx-mi><mjx-mo class="mjx-n" space="4"><mjx-c class="mjx-c3E"></mjx-c></mjx-mo><mjx-mn class="mjx-n" space="4"><mjx-c class="mjx-c33"></mjx-c><mjx-c class="mjx-c32"></mjx-c></mjx-mn><mjx-mo class="mjx-n" space="3"><mjx-c class="mjx-c22C5"></mjx-c></mjx-mo><mjx-mrow space="3"><mjx-mo class="mjx-s3"><mjx-c class="mjx-c28 TEX-S3"></mjx-c></mjx-mo><mjx-mfrac><mjx-frac type="d"><mjx-num><mjx-nstrut type="d"></mjx-nstrut><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D439 TEX-I"></mjx-c></mjx-mi></mjx-num><mjx-dbox><mjx-dtable><mjx-line type="d"></mjx-line><mjx-row><mjx-den><mjx-dstrut type="d"></mjx-dstrut><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D437 TEX-I"></mjx-c></mjx-mi></mjx-den></mjx-row></mjx-dtable></mjx-dbox></mjx-frac></mjx-mfrac><mjx-mo class="mjx-s3"><mjx-c class="mjx-c29 TEX-S3"></mjx-c></mjx-mo></mjx-mrow><mjx-mo class="mjx-n" space="3"><mjx-c class="mjx-c22C5"></mjx-c></mjx-mo><mjx-msup space="3"><mjx-mrow><mjx-mo class="mjx-s3"><mjx-c class="mjx-c28 TEX-S3"></mjx-c></mjx-mo><mjx-mfrac><mjx-frac type="d"><mjx-num><mjx-nstrut type="d"></mjx-nstrut><mjx-mn class="mjx-n"><mjx-c class="mjx-c33"></mjx-c></mjx-mn></mjx-num><mjx-dbox><mjx-dtable><mjx-line type="d"></mjx-line><mjx-row><mjx-den><mjx-dstrut type="d"></mjx-dstrut><mjx-mn class="mjx-n"><mjx-c class="mjx-c34"></mjx-c></mjx-mn></mjx-den></mjx-row></mjx-dtable></mjx-dbox></mjx-frac></mjx-mfrac><mjx-mo class="mjx-s3"><mjx-c class="mjx-c29 TEX-S3"></mjx-c></mjx-mo></mjx-mrow><mjx-script style="vertical-align: 1.177em;"><mjx-mn class="mjx-n" size="s"><mjx-c class="mjx-c32"></mjx-c></mjx-mn></mjx-script></mjx-msup></mjx-math><mjx-assistive-mml display="block" unselectable="on"><math display="block" xmlns="http://www.w3.org/1998/Math/MathML"><mi>N</mi><mo>&gt;</mo><mn>32</mn><mo>⋅</mo><mrow data-mjx-texclass="INNER"><mo data-mjx-texclass="OPEN">(</mo><mfrac><mi>F</mi><mi>D</mi></mfrac><mo data-mjx-texclass="CLOSE">)</mo></mrow><mo>⋅</mo><msup><mrow data-mjx-texclass="INNER"><mo data-mjx-texclass="OPEN">(</mo><mfrac><mn>3</mn><mn>4</mn></mfrac><mo data-mjx-texclass="CLOSE">)</mo></mrow><mn>2</mn></msup></math></mjx-assistive-mml></mjx-container> <p>这告诉我们，如果我们有超过 81 个芯片，我们最好使用这个新方案。现在这是一个稍微奇怪的结果，因为我们历史上发现在大约 20 路张量并行性时就受 ICI 限制了。但在这里，即使我们受通信限制，我们的总通信量也会随着总芯片数量的增加而持续减少！这告诉我们，我们可以继续增加我们的芯片，增加我们的批量大小，做更多的参数扩展，并看到延迟降低。</p> </details> <h3 class="next-section">第 7 部分到此结束！关于第 8 部分，我们将探讨如何在 TPU 上服务 LLaMA 3，请点击<a href="applied-inference.html">这里</a>。</h3> <h2 id="appendix">附录</h2> <h3 id="appendix-a-how-real-is-the-batch-size--240-rule">附录 A：批量大小 &gt; 240 的规则有多真实？</h3> <p>我们上面提供的简单规则，即我们的批量大小必须大于 240 个词元才能达到计算密集型，这大致是正确的，但忽略了 TPU 在其他操作不使用所有可用 HBM 时（例如进行设备间通信时）预取权重的一些能力。</p> <p>这是一个小型 Transformer 的层时间（以微秒为单位）的经验图，其中 d<sub>model</sub> 为 8192，d<sub>ff</sub> 为 32768，每层只有 2 个矩阵乘法。这来自<a href="https://colab.sandbox.google.com/drive/1_6krERgtolH7hbUIo7ewAMLlbA4fqEF8?usp=sharing" rel="external nofollow noopener" target="_blank">这个 Colab 笔记本</a>。你会看到步长时间在批量大小达到 240 左右之前增长非常缓慢，然后呈线性增长。</p> <figure> <picture> <source class="responsive-img-srcset" sizes="95vw" srcset="https://jax-ml.github.io/scaling-book/assets/img/batch-scaling-latency-480.webp 480w, https://jax-ml.github.io/scaling-book/assets/img/batch-scaling-latency-800.webp 800w, https://jax-ml.github.io/scaling-book/assets/img/batch-scaling-latency-1400.webp 1400w" type="image/webp"/> <img class="img-fluid img-small" height="auto" loading="lazy" onerror="this.onerror=null; $('.responsive-img-srcset').remove();" src="https://jax-ml.github.io/scaling-book/assets/img/batch-scaling-latency.png" width="100%"/> </picture> </figure> <p>这是以词元/微秒为单位的实际吞吐量。这相当清楚地说明了论点。由于我们的层大约有 600M 参数，在这里进行了 4 路分片，我们预计最小延迟大约为 365 微秒。</p> <figure> <picture> <source class="responsive-img-srcset" sizes="95vw" srcset="https://jax-ml.github.io/scaling-book/assets/img/batch-scaling-throughput-480.webp 480w, https://jax-ml.github.io/scaling-book/assets/img/batch-scaling-throughput-800.webp 800w, https://jax-ml.github.io/scaling-book/assets/img/batch-scaling-throughput-1400.webp 1400w" type="image/webp"/> <img class="img-fluid img-small" height="auto" loading="lazy" onerror="this.onerror=null; $('.responsive-img-srcset').remove();" src="https://jax-ml.github.io/scaling-book/assets/img/batch-scaling-throughput.png" width="100%"/> </picture> </figure> <p>所以至少在这个模型中，我们确实看到吞吐量在每个数据并行分片的 BS 达到约 240 之前一直在增加。</p> <h3 id="appendix-b-2d-weight-stationary-sharding">附录 B：2D 权重固定分片</h3> <p>随着拓扑结构的增长，如果我们能接触到更高维度的网格（比如 TPU 的网格），就可以通过“<strong>2D 权重分片</strong>”进一步优化。通过引入第二个分片轴。我们称之为“<strong>2D 权重固定</strong>”，在<a href="https://arxiv.org/abs/2211.05102" rel="external nofollow noopener" target="_blank">高效扩展 Transformer 推理论文</a>中有更详细的描述。</p> <p>因为在 Megatron 中我们只分片隐藏的 <mjx-container class="MathJax CtxtMenu_Attached_0" ctxtmenu_counter="34" jax="CHTML" style="font-size: 116.9%; position: relative;" tabindex="0"><mjx-math aria-hidden="true" class="MJX-TEX"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D439 TEX-I"></mjx-c></mjx-mi></mjx-math><mjx-assistive-mml display="inline" unselectable="on"><math xmlns="http://www.w3.org/1998/Math/MathML"><mi>F</mi></math></mjx-assistive-mml></mjx-container> 维度，一旦芯片数量随着 1D 分片增长，它可能会变得比 <mjx-container class="MathJax CtxtMenu_Attached_0" ctxtmenu_counter="35" jax="CHTML" style="font-size: 116.9%; position: relative;" tabindex="0"><mjx-math aria-hidden="true" class="MJX-TEX"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D438 TEX-I"></mjx-c></mjx-mi></mjx-math><mjx-assistive-mml display="inline" unselectable="on"><math xmlns="http://www.w3.org/1998/Math/MathML"><mi>E</mi></math></mjx-assistive-mml></mjx-container>（<mjx-container class="MathJax CtxtMenu_Attached_0" ctxtmenu_counter="36" jax="CHTML" style="font-size: 116.9%; position: relative;" tabindex="0"><mjx-math aria-hidden="true" class="MJX-TEX"><mjx-msub><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D451 TEX-I"></mjx-c></mjx-mi><mjx-script style="vertical-align: -0.15em;"><mjx-mtext class="mjx-n" size="s"><mjx-c class="mjx-c6D"></mjx-c><mjx-c class="mjx-c6F"></mjx-c><mjx-c class="mjx-c64"></mjx-c><mjx-c class="mjx-c65"></mjx-c><mjx-c class="mjx-c6C"></mjx-c></mjx-mtext></mjx-script></mjx-msub></mjx-math><mjx-assistive-mml display="inline" unselectable="on"><math xmlns="http://www.w3.org/1998/Math/MathML"><msub><mi>d</mi><mtext>model</mtext></msub></math></mjx-assistive-mml></mjx-container> 维度）小得多。这意味着在较大的批量下，在应用 MLP 的第一层之后，在隐藏维度上执行一部分集合通信可能更经济。</p> <figure> <picture> <source class="responsive-img-srcset" sizes="95vw" srcset="https://jax-ml.github.io/scaling-book/assets/img/2d-weight-stationary-480.webp 480w, https://jax-ml.github.io/scaling-book/assets/img/2d-weight-stationary-800.webp 800w, https://jax-ml.github.io/scaling-book/assets/img/2d-weight-stationary-1400.webp 1400w" type="image/webp"/> <img class="img-fluid img-small" height="auto" loading="lazy" onerror="this.onerror=null; $('.responsive-img-srcset').remove();" src="https://jax-ml.github.io/scaling-book/assets/img/2d-weight-stationary.png" width="100%"/> </picture> </figure> <p>这张图显示：</p> <ol> <li>1D 权重固定分片，即纯 Megatron 分片，其中激活在 AllGather 后完全复制，权重在隐藏的 F 维度上完全分片。</li> <li>2D 权重固定分片，其中权重在隐藏的 F 维度和缩减的 E 维度上都进行分片，激活在 E 维度上分片。我们在第一层之前在 (yz) 轴上执行 AllGather，然后在 (x) 轴上执行 ReduceScatter。</li> </ol> <p>对于注意力层，对于较少数量的芯片，Megatron 风格的分片也相对简单。然而，Megatron 发生在 <mjx-container class="MathJax CtxtMenu_Attached_0" ctxtmenu_counter="37" jax="CHTML" style="font-size: 116.9%; position: relative;" tabindex="0"><mjx-math aria-hidden="true" class="MJX-TEX"><mjx-msub><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D45B TEX-I"></mjx-c></mjx-mi><mjx-script style="vertical-align: -0.15em;"><mjx-mtext class="mjx-n" size="s"><mjx-c class="mjx-c68"></mjx-c><mjx-c class="mjx-c65"></mjx-c><mjx-c class="mjx-c61"></mjx-c><mjx-c class="mjx-c64"></mjx-c><mjx-c class="mjx-c73"></mjx-c></mjx-mtext></mjx-script></mjx-msub></mjx-math><mjx-assistive-mml display="inline" unselectable="on"><math xmlns="http://www.w3.org/1998/Math/MathML"><msub><mi>n</mi><mtext>heads</mtext></msub></math></mjx-assistive-mml></mjx-container> 维度上，这对可能的分片量设置了限制。通过修改 2D 分片（不是分片隐藏维度，而是分片 <mjx-container class="MathJax CtxtMenu_Attached_0" ctxtmenu_counter="38" jax="CHTML" style="font-size: 116.9%; position: relative;" tabindex="0"><mjx-math aria-hidden="true" class="MJX-TEX"><mjx-msub><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D45B TEX-I"></mjx-c></mjx-mi><mjx-script style="vertical-align: -0.15em;"><mjx-mtext class="mjx-n" size="s"><mjx-c class="mjx-c68"></mjx-c><mjx-c class="mjx-c65"></mjx-c><mjx-c class="mjx-c61"></mjx-c><mjx-c class="mjx-c64"></mjx-c><mjx-c class="mjx-c73"></mjx-c></mjx-mtext></mjx-script></mjx-msub></mjx-math><mjx-assistive-mml display="inline" unselectable="on"><math xmlns="http://www.w3.org/1998/Math/MathML"><msub><mi>n</mi><mtext>heads</mtext></msub></math></mjx-assistive-mml></mjx-container> 维度），我们获得了进一步扩展的能力。</p> <h3 id="appendix-c-latency-bound-communications">附录 C：延迟限制的通信</h3> <p>作为回顾，在<a href="sharding.html">第 3 节</a>中，我们推导了在每个 TPU 上，通过 X 个芯片在全双工带宽为 WICI 和延迟为 Tmin 的 1D 环形链路上，对大小为 B 的张量执行 AllGather 所需的时间。</p><span> <mjx-container class="MathJax CtxtMenu_Attached_0" ctxtmenu_counter="39" display="true" jax="CHTML" style="font-size: 116.9%; position: relative;" tabindex="0"><mjx-math aria-hidden="true" class="MJX-TEX" display="true" style="margin-left: 0px; margin-right: 0px;"><mjx-msub><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D447 TEX-I"></mjx-c></mjx-mi><mjx-script style="vertical-align: -0.15em; margin-left: -0.12em;"><mjx-texatom size="s" texclass="ORD"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D461 TEX-I"></mjx-c></mjx-mi><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D45C TEX-I"></mjx-c></mjx-mi><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D461 TEX-I"></mjx-c></mjx-mi><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D44E TEX-I"></mjx-c></mjx-mi><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D459 TEX-I"></mjx-c></mjx-mi></mjx-texatom></mjx-script></mjx-msub><mjx-mo class="mjx-n" space="4"><mjx-c class="mjx-c3D"></mjx-c></mjx-mo><mjx-mo class="mjx-n" space="4"><mjx-c class="mjx-c6D"></mjx-c><mjx-c class="mjx-c61"></mjx-c><mjx-c class="mjx-c78"></mjx-c></mjx-mo><mjx-mrow space="2"><mjx-mo class="mjx-s3"><mjx-c class="mjx-c28 TEX-S3"></mjx-c></mjx-mo><mjx-mfrac><mjx-frac type="d"><mjx-num><mjx-nstrut type="d"></mjx-nstrut><mjx-mrow><mjx-msub><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D447 TEX-I"></mjx-c></mjx-mi><mjx-script style="vertical-align: -0.15em; margin-left: -0.12em;"><mjx-texatom size="s" texclass="ORD"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D45A TEX-I"></mjx-c></mjx-mi><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D456 TEX-I"></mjx-c></mjx-mi><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D45B TEX-I"></mjx-c></mjx-mi></mjx-texatom></mjx-script></mjx-msub><mjx-mo class="mjx-n" space="3"><mjx-c class="mjx-c22C5"></mjx-c></mjx-mo><mjx-texatom space="3" texclass="ORD"><mjx-mo class="mjx-n"><mjx-c class="mjx-c7C"></mjx-c></mjx-mo></mjx-texatom><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D44B TEX-I"></mjx-c></mjx-mi><mjx-mo class="mjx-n"><mjx-c class="mjx-c7C"></mjx-c></mjx-mo></mjx-mrow></mjx-num><mjx-dbox><mjx-dtable><mjx-line type="d"></mjx-line><mjx-row><mjx-den><mjx-dstrut type="d"></mjx-dstrut><mjx-mn class="mjx-n"><mjx-c class="mjx-c32"></mjx-c></mjx-mn></mjx-den></mjx-row></mjx-dtable></mjx-dbox></mjx-frac></mjx-mfrac><mjx-mo class="mjx-n"><mjx-c class="mjx-c2C"></mjx-c></mjx-mo><mjx-mfrac space="2"><mjx-frac type="d"><mjx-num><mjx-nstrut type="d"></mjx-nstrut><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D435 TEX-I"></mjx-c></mjx-mi></mjx-num><mjx-dbox><mjx-dtable><mjx-line type="d"></mjx-line><mjx-row><mjx-den><mjx-dstrut type="d"></mjx-dstrut><mjx-msub><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D44A TEX-I"></mjx-c></mjx-mi><mjx-script style="vertical-align: -0.15em; margin-left: -0.104em;"><mjx-texatom size="s" texclass="ORD"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D43C TEX-I"></mjx-c></mjx-mi><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D436 TEX-I"></mjx-c></mjx-mi><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D43C TEX-I"></mjx-c></mjx-mi></mjx-texatom></mjx-script></mjx-msub></mjx-den></mjx-row></mjx-dtable></mjx-dbox></mjx-frac></mjx-mfrac><mjx-mo class="mjx-s3"><mjx-c class="mjx-c29 TEX-S3"></mjx-c></mjx-mo></mjx-mrow></mjx-math><mjx-assistive-mml display="block" unselectable="on"><math display="block" xmlns="http://www.w3.org/1998/Math/MathML"><msub><mi>T</mi><mrow data-mjx-texclass="ORD"><mi>t</mi><mi>o</mi><mi>t</mi><mi>a</mi><mi>l</mi></mrow></msub><mo>=</mo><mo data-mjx-texclass="OP" movablelimits="true">max</mo><mrow data-mjx-texclass="INNER"><mo data-mjx-texclass="OPEN">(</mo><mfrac><mrow><msub><mi>T</mi><mrow data-mjx-texclass="ORD"><mi>m</mi><mi>i</mi><mi>n</mi></mrow></msub><mo>⋅</mo><mrow data-mjx-texclass="ORD"><mo stretchy="false">|</mo></mrow><mi>X</mi><mo stretchy="false">|</mo></mrow><mn>2</mn></mfrac><mo>,</mo><mfrac><mi>B</mi><msub><mi>W</mi><mrow data-mjx-texclass="ORD"><mi>I</mi><mi>C</mi><mi>I</mi></mrow></msub></mfrac><mo data-mjx-texclass="CLOSE">)</mo></mrow></math></mjx-assistive-mml></mjx-container> </span><p>对于大的 B，挂钟时间保持相对恒定，因为当你向系统中添加更多芯片时，你同时扩展了执行操作所需的数据移动量和可用的总带宽。</p> <figure> <picture> <source class="responsive-img-srcset" sizes="95vw" srcset="https://jax-ml.github.io/scaling-book/assets/img/all-gather-480.webp 480w, https://jax-ml.github.io/scaling-book/assets/img/all-gather-800.webp 800w, https://jax-ml.github.io/scaling-book/assets/img/all-gather-1400.webp 1400w" type="image/webp"/> <img class="img-fluid" height="auto" loading="lazy" onerror="this.onerror=null; $('.responsive-img-srcset').remove();" src="https://jax-ml.github.io/scaling-book/assets/img/all-gather.gif" width="100%"/> </picture> </figure> <p>由于在延迟优化的推理过程中移动的数据量相对较少，对激活的集合操作通常受延迟项的限制（特别是对于小批量大小）。通过计算完成操作所需的跳数，可以很容易地将延迟可视化。</p> <p>在 TPU 上，如果通信中依赖于张量大小的部分每跳小于 1 微秒（一跳是两个相邻设备之间的通信），我们可能会被实际分派集合操作的固定开销所瓶颈。在 <code class="language-plaintext highlighter-rouge">4.5e10</code> 单向 ICI 带宽下，当 <mjx-container class="MathJax CtxtMenu_Attached_0" ctxtmenu_counter="40" jax="CHTML" style="font-size: 116.9%; position: relative;" tabindex="0"><mjx-math aria-hidden="true" class="MJX-TEX"><mjx-mo class="mjx-n"><mjx-c class="mjx-c28"></mjx-c></mjx-mo><mjx-mtext class="mjx-n"><mjx-c class="mjx-c62"></mjx-c><mjx-c class="mjx-c79"></mjx-c><mjx-c class="mjx-c74"></mjx-c><mjx-c class="mjx-c65"></mjx-c><mjx-c class="mjx-c73"></mjx-c></mjx-mtext><mjx-texatom texclass="ORD"><mjx-mo class="mjx-n"><mjx-c class="mjx-c2F"></mjx-c></mjx-mo></mjx-texatom><mjx-msub><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D45B TEX-I"></mjx-c></mjx-mi><mjx-script style="vertical-align: -0.15em;"><mjx-mtext class="mjx-n" size="s"><mjx-c class="mjx-c73"></mjx-c><mjx-c class="mjx-c68"></mjx-c><mjx-c class="mjx-c61"></mjx-c><mjx-c class="mjx-c72"></mjx-c><mjx-c class="mjx-c64"></mjx-c><mjx-c class="mjx-c73"></mjx-c></mjx-mtext></mjx-script></mjx-msub><mjx-mo class="mjx-n"><mjx-c class="mjx-c29"></mjx-c></mjx-mo><mjx-texatom texclass="ORD"><mjx-mo class="mjx-n"><mjx-c class="mjx-c2F"></mjx-c></mjx-mo></mjx-texatom><mjx-mn class="mjx-n"><mjx-c class="mjx-c34"></mjx-c><mjx-c class="mjx-c2E"></mjx-c><mjx-c class="mjx-c35"></mjx-c></mjx-mn><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D452 TEX-I"></mjx-c></mjx-mi><mjx-mn class="mjx-n"><mjx-c class="mjx-c31"></mjx-c><mjx-c class="mjx-c30"></mjx-c></mjx-mn><mjx-mo class="mjx-n" space="4"><mjx-c class="mjx-c3C"></mjx-c></mjx-mo><mjx-mn class="mjx-n" space="4"><mjx-c class="mjx-c31"></mjx-c></mjx-mn><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D452 TEX-I"></mjx-c></mjx-mi><mjx-mo class="mjx-n" space="3"><mjx-c class="mjx-c2212"></mjx-c></mjx-mo><mjx-mn class="mjx-n" space="3"><mjx-c class="mjx-c36"></mjx-c></mjx-mn></mjx-math><mjx-assistive-mml display="inline" unselectable="on"><math xmlns="http://www.w3.org/1998/Math/MathML"><mo stretchy="false">(</mo><mtext>bytes</mtext><mrow data-mjx-texclass="ORD"><mo>/</mo></mrow><msub><mi>n</mi><mtext>shards</mtext></msub><mo stretchy="false">)</mo><mrow data-mjx-texclass="ORD"><mo>/</mo></mrow><mn>4.5</mn><mi>e</mi><mn>10</mn><mo>&lt;</mo><mn>1</mn><mi>e</mi><mo>−</mo><mn>6</mn></math></mjx-assistive-mml></mjx-container> 时，ICI 通信会受延迟限制。对于 8 路 Megatron 分片，这是当 <code class="language-plaintext highlighter-rouge">buffer_size &lt; 360kB</code> 时。<strong>这在推理过程中实际上并不小：</strong> 当 <code class="language-plaintext highlighter-rouge">BS=16</code> 且 <code class="language-plaintext highlighter-rouge">D=8192</code> 在 int8 中，我们的激活将使用 <code class="language-plaintext highlighter-rouge">16*8192=131kB</code>，所以我们已经受延迟限制了。</p> <p class="takeaway"><strong>要点：</strong> 当 <mjx-container class="MathJax CtxtMenu_Attached_0" ctxtmenu_counter="41" jax="CHTML" style="font-size: 116.9%; position: relative;" tabindex="0"><mjx-math aria-hidden="true" class="MJX-TEX"><mjx-mtext class="mjx-n"><mjx-c class="mjx-c74"></mjx-c><mjx-c class="mjx-c6F"></mjx-c><mjx-c class="mjx-c74"></mjx-c><mjx-c class="mjx-c61"></mjx-c><mjx-c class="mjx-c6C"></mjx-c><mjx-c class="mjx-c20"></mjx-c><mjx-c class="mjx-c62"></mjx-c><mjx-c class="mjx-c79"></mjx-c><mjx-c class="mjx-c74"></mjx-c><mjx-c class="mjx-c65"></mjx-c><mjx-c class="mjx-c73"></mjx-c></mjx-mtext><mjx-mo class="mjx-n" space="4"><mjx-c class="mjx-c3C"></mjx-c></mjx-mo><mjx-msub space="4"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D44A TEX-I"></mjx-c></mjx-mi><mjx-script style="vertical-align: -0.15em; margin-left: -0.104em;"><mjx-texatom size="s" texclass="ORD"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D43C TEX-I"></mjx-c></mjx-mi><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D436 TEX-I"></mjx-c></mjx-mi><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D43C TEX-I"></mjx-c></mjx-mi></mjx-texatom></mjx-script></mjx-msub><mjx-mo class="mjx-n" space="3"><mjx-c class="mjx-cD7"></mjx-c></mjx-mo><mjx-mn class="mjx-n" space="3"><mjx-c class="mjx-c31"></mjx-c></mjx-mn><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D452 TEX-I"></mjx-c></mjx-mi><mjx-mo class="mjx-n" space="3"><mjx-c class="mjx-c2212"></mjx-c></mjx-mo><mjx-mn class="mjx-n" space="3"><mjx-c class="mjx-c36"></mjx-c></mjx-mn></mjx-math><mjx-assistive-mml display="inline" unselectable="on"><math xmlns="http://www.w3.org/1998/Math/MathML"><mtext>total bytes</mtext><mo>&lt;</mo><msub><mi>W</mi><mrow data-mjx-texclass="ORD"><mi>I</mi><mi>C</mi><mi>I</mi></mrow></msub><mo>×</mo><mn>1</mn><mi>e</mi><mo>−</mo><mn>6</mn></math></mjx-assistive-mml></mjx-container> 时，我们的通信会受延迟限制。例如，在 <mjx-container class="MathJax CtxtMenu_Attached_0" ctxtmenu_counter="42" jax="CHTML" style="font-size: 116.9%; position: relative;" tabindex="0"><mjx-math aria-hidden="true" class="MJX-TEX"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D44C TEX-I"></mjx-c></mjx-mi></mjx-math><mjx-assistive-mml display="inline" unselectable="on"><math xmlns="http://www.w3.org/1998/Math/MathML"><mi>Y</mi></math></mjx-assistive-mml></mjx-container> 上进行模型并行性时，当 <mjx-container class="MathJax CtxtMenu_Attached_0" ctxtmenu_counter="43" jax="CHTML" style="font-size: 116.9%; position: relative;" tabindex="0"><mjx-math aria-hidden="true" class="MJX-TEX"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D44C TEX-I"></mjx-c></mjx-mi><mjx-mo class="mjx-n" space="4"><mjx-c class="mjx-c3E"></mjx-c></mjx-mo><mjx-mi class="mjx-i" space="4"><mjx-c class="mjx-c1D435 TEX-I"></mjx-c></mjx-mi><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D437 TEX-I"></mjx-c></mjx-mi><mjx-texatom texclass="ORD"><mjx-mo class="mjx-n"><mjx-c class="mjx-c2F"></mjx-c></mjx-mo></mjx-texatom><mjx-mn class="mjx-n"><mjx-c class="mjx-c34"></mjx-c><mjx-c class="mjx-c35"></mjx-c></mjx-mn><mjx-mo class="mjx-n"><mjx-c class="mjx-c2C"></mjx-c></mjx-mo><mjx-mn class="mjx-n" space="2"><mjx-c class="mjx-c30"></mjx-c><mjx-c class="mjx-c30"></mjx-c><mjx-c class="mjx-c30"></mjx-c></mjx-mn></mjx-math><mjx-assistive-mml display="inline" unselectable="on"><math xmlns="http://www.w3.org/1998/Math/MathML"><mi>Y</mi><mo>&gt;</mo><mi>B</mi><mi>D</mi><mrow data-mjx-texclass="ORD"><mo>/</mo></mrow><mn>45</mn><mo>,</mo><mn>000</mn></math></mjx-assistive-mml></mjx-container> 时，我们在 int8 中会受限。</p> <p>这里可以与计算屋顶线做一个类比——我们正在为一些小操作承担固定成本（通信的延迟，矩阵乘法的内存带宽）。</p> <h3 id="appendix-d-speculative-sampling">附录 D：推测采样</h3> <p>当我们<em>真正</em>关心端到端延迟时，还有一个额外的技巧我们可以使用，叫做推测采样<d-cite key="spec1"></d-cite><d-cite key="spec2"></d-cite>。回顾一下，我们通常从一个大的 Transformer 中逐个生成词元：</p> <figure> <picture> <source class="responsive-img-srcset" sizes="95vw" srcset="https://jax-ml.github.io/scaling-book/assets/img/spec-sampling1-480.webp 480w, https://jax-ml.github.io/scaling-book/assets/img/spec-sampling1-800.webp 800w, https://jax-ml.github.io/scaling-book/assets/img/spec-sampling1-1400.webp 1400w" type="image/webp"/> <img class="img-fluid" height="auto" loading="lazy" onerror="this.onerror=null; $('.responsive-img-srcset').remove();" src="https://jax-ml.github.io/scaling-book/assets/img/spec-sampling1.png" width="100%"/> </picture> </figure> <p>通过推测采样，我们使用一个更小、更便宜的模型来生成词元，然后用大模型检查结果。这在<em>贪婪解码</em>中最容易理解：</p> <figure> <picture> <source class="responsive-img-srcset" sizes="95vw" srcset="https://jax-ml.github.io/scaling-book/assets/img/spec-sampling2-480.webp 480w, https://jax-ml.github.io/scaling-book/assets/img/spec-sampling2-800.webp 800w, https://jax-ml.github.io/scaling-book/assets/img/spec-sampling2-1400.webp 1400w" type="image/webp"/> <img class="img-fluid" height="auto" loading="lazy" onerror="this.onerror=null; $('.responsive-img-srcset').remove();" src="https://jax-ml.github.io/scaling-book/assets/img/spec-sampling2.png" width="100%"/> </picture> </figure> <ol> <li>我们从某个更小、更便宜的模型中进行贪婪采样。理想情况下，我们使用一个经过训练以匹配较大模型的模型，例如通过蒸馏，但它也可以像使用 n-gram 或匹配一小部分文本语料库的词元一样简单。</li> <li>在我们生成了 K 个词元后，我们使用大模型计算我们到目前为止生成的所有词元的下一个词元 logits。</li> <li>由于我们是贪婪解码，我们可以简单地检查由较小模型生成的词元是否是所有可能词元中概率最高的。如果其中一个词元是错误的，我们取最长的正确前缀，并将第一个错误的词元替换为正确的词元，然后回到（1）。如果所有词元都是正确的，我们可以使用最后一个正确的 logit 来采样一个额外的词元，然后再回到（1）。</li> </ol> <p><strong>为什么这能赢得延迟？</strong> 这个方案仍然要求我们为每个词元做相当于大模型一次前向传播的 FLOPs，但因为我们可以将一堆词元批处理在一起，我们可以在一次前向传播中完成所有这些 FLOPs，并利用我们<em>不是</em><em>计算密集型</em>的优势来免费评分更多词元。</p> <p>平均而言，每个被接受的词元在 FLOPs 方面变得更昂贵（因为有些会被拒绝，而且我们必须调用一个草稿模型），但我们从硬件中榨取了更多的 FLOPs，而且小模型很便宜，所以我们总体上赢了。我们还在多个步骤中共享 KV 缓存加载，所以<strong>对于长上下文，推测解码也可以在吞吐量上获胜。</strong> 由于所有内容都经过了大模型的检查，我们完全没有改变采样分布（尽管对于非贪婪解码，确切的轨迹会有所不同）。</p> <p>传统上，推测解码依赖于存在一个与目标模型具有相似采样分布的较小模型，例如 LLaMA-2 2B 用于 LLaMA-2 70B，但这通常不存在。即使有，如果接受率低，较小的草稿模型仍然可能太昂贵。相反，将草稿模型嵌入到主模型中可能会有所帮助，例如通过在基础模型的较后层添加一个专用的草稿头<d-cite key="eagle"></d-cite><d-cite key="medusa"></d-cite><d-cite key="DeepSeek3"></d-cite>。因为这个头与主模型共享大部分参数，所以运行起来更快，并且更紧密地匹配采样分布。</p> <p>对于正常的自回归采样，词元/秒与步长时间相同。我们仍然受制于这里算术强度部分的理论最小步长时间（实际上，推测采样的步长时间通常比正常自回归采样慢得多，但因为我们平均每步得到超过 1 个词元，所以我们可以得到更好的词元/秒）。</p> <figure> <picture> <source class="responsive-img-srcset" sizes="95vw" srcset="https://jax-ml.github.io/scaling-book/assets/img/spec-sampling3-480.webp 480w, https://jax-ml.github.io/scaling-book/assets/img/spec-sampling3-800.webp 800w, https://jax-ml.github.io/scaling-book/assets/img/spec-sampling3-1400.webp 1400w" type="image/webp"/> <img class="img-fluid" height="auto" loading="lazy" onerror="this.onerror=null; $('.responsive-img-srcset').remove();" src="https://jax-ml.github.io/scaling-book/assets/img/spec-sampling3.png" width="100%"/> </picture> <figcaption class="caption"><b>图：</b>这张图显示了 Chinchilla（一个来自 DeepMind 的 70B 模型）和一个 4B 参数的草稿模型（小模型）的每步延迟和推测成功率。对于 XSum（一个自然语言数据集），理想的推测量大约是提前 3-4 个词元，而 HumanEval（一个编码数据集）更可预测，从更激进的推测中获益。</figcaption> </figure> <p><strong>这对于非贪婪解码是如何工作的？</strong> 这有点复杂，但基本上可以归结为一个受 Metropolis-Hastings 启发的算法，其中我们有从 logits 派生出的 <mjx-container class="MathJax CtxtMenu_Attached_0" ctxtmenu_counter="44" jax="CHTML" style="font-size: 116.9%; position: relative;" tabindex="0"><mjx-math aria-hidden="true" class="MJX-TEX"><mjx-msub><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D443 TEX-I"></mjx-c></mjx-mi><mjx-script style="vertical-align: -0.15em; margin-left: -0.109em;"><mjx-texatom size="s" texclass="ORD"><mjx-mtext class="mjx-n"><mjx-c class="mjx-c64"></mjx-c><mjx-c class="mjx-c72"></mjx-c><mjx-c class="mjx-c61"></mjx-c><mjx-c class="mjx-c66"></mjx-c><mjx-c class="mjx-c74"></mjx-c><mjx-c class="mjx-c20"></mjx-c><mjx-c class="mjx-c6D"></mjx-c><mjx-c class="mjx-c6F"></mjx-c><mjx-c class="mjx-c64"></mjx-c><mjx-c class="mjx-c65"></mjx-c><mjx-c class="mjx-c6C"></mjx-c></mjx-mtext></mjx-texatom></mjx-script></mjx-msub><mjx-mo class="mjx-n"><mjx-c class="mjx-c28"></mjx-c></mjx-mo><mjx-mtext class="mjx-n"><mjx-c class="mjx-c63"></mjx-c><mjx-c class="mjx-c68"></mjx-c><mjx-c class="mjx-c6F"></mjx-c><mjx-c class="mjx-c73"></mjx-c><mjx-c class="mjx-c65"></mjx-c><mjx-c class="mjx-c6E"></mjx-c><mjx-c class="mjx-c20"></mjx-c><mjx-c class="mjx-c74"></mjx-c><mjx-c class="mjx-c6F"></mjx-c><mjx-c class="mjx-c6B"></mjx-c><mjx-c class="mjx-c65"></mjx-c><mjx-c class="mjx-c6E"></mjx-c></mjx-mtext><mjx-mo class="mjx-n"><mjx-c class="mjx-c29"></mjx-c></mjx-mo></mjx-math><mjx-assistive-mml display="inline" unselectable="on"><math xmlns="http://www.w3.org/1998/Math/MathML"><msub><mi>P</mi><mrow data-mjx-texclass="ORD"><mtext>draft model</mtext></mrow></msub><mo stretchy="false">(</mo><mtext>chosen token</mtext><mo stretchy="false">)</mo></math></mjx-assistive-mml></mjx-container> 和 <mjx-container class="MathJax CtxtMenu_Attached_0" ctxtmenu_counter="45" jax="CHTML" style="font-size: 116.9%; position: relative;" tabindex="0"><mjx-math aria-hidden="true" class="MJX-TEX"><mjx-msub><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D443 TEX-I"></mjx-c></mjx-mi><mjx-script style="vertical-align: -0.15em; margin-left: -0.109em;"><mjx-texatom size="s" texclass="ORD"><mjx-mtext class="mjx-n"><mjx-c class="mjx-c74"></mjx-c><mjx-c class="mjx-c61"></mjx-c><mjx-c class="mjx-c72"></mjx-c><mjx-c class="mjx-c67"></mjx-c><mjx-c class="mjx-c65"></mjx-c><mjx-c class="mjx-c74"></mjx-c><mjx-c class="mjx-c20"></mjx-c><mjx-c class="mjx-c6D"></mjx-c><mjx-c class="mjx-c6F"></mjx-c><mjx-c class="mjx-c64"></mjx-c><mjx-c class="mjx-c65"></mjx-c><mjx-c class="mjx-c6C"></mjx-c></mjx-mtext></mjx-texatom></mjx-script></mjx-msub><mjx-mo class="mjx-n"><mjx-c class="mjx-c28"></mjx-c></mjx-mo><mjx-mtext class="mjx-n"><mjx-c class="mjx-c63"></mjx-c><mjx-c class="mjx-c68"></mjx-c><mjx-c class="mjx-c6F"></mjx-c><mjx-c class="mjx-c73"></mjx-c><mjx-c class="mjx-c65"></mjx-c><mjx-c class="mjx-c6E"></mjx-c><mjx-c class="mjx-c20"></mjx-c><mjx-c class="mjx-c74"></mjx-c><mjx-c class="mjx-c6F"></mjx-c><mjx-c class="mjx-c6B"></mjx-c><mjx-c class="mjx-c65"></mjx-c><mjx-c class="mjx-c6E"></mjx-c></mjx-mtext><mjx-mo class="mjx-n"><mjx-c class="mjx-c29"></mjx-c></mjx-mo></mjx-math><mjx-assistive-mml display="inline" unselectable="on"><math xmlns="http://www.w3.org/1998/Math/MathML"><msub><mi>P</mi><mrow data-mjx-texclass="ORD"><mtext>target model</mtext></mrow></msub><mo stretchy="false">(</mo><mtext>chosen token</mtext><mo stretchy="false">)</mo></math></mjx-assistive-mml></mjx-container>，如果这些概率的比率小于某个阈值，则以概率方式拒绝所选的词元。</p> <p>这<a href="https://arxiv.org/abs/2211.17192" rel="external nofollow noopener" target="_blank">两篇</a><a href="https://arxiv.org/abs/2302.01318" rel="external nofollow noopener" target="_blank">论文</a>同时推导出了这一点，并提供了很好的实际应用示例。</p> <p class="takeaway"><strong>要点：</strong> 推测采样是另一个强大的杠杆，用于以吞吐量换取更好的每词元延迟。然而，在批量大小受限的情况下（例如，硬件占用空间小或 KV 缓存大），它变成了双赢。</p> </d-article> <d-appendix>
<style>

d-appendix {
  contain: layout style;
  font-size: 0.8em;
  line-height: 1.7em;
  margin-top: 60px;
  margin-bottom: 0;
  border-top: 1px solid rgba(0, 0, 0, 0.1);
  color: rgba(0,0,0,0.5);
  padding-top: 60px;
  padding-bottom: 48px;
}

d-appendix h3 {
  grid-column: page-start / text-start;
  font-size: 15px;
  font-weight: 500;
  margin-top: 1em;
  margin-bottom: 0;
  color: rgba(0,0,0,0.65);
}

d-appendix h3 + * {
  margin-top: 1em;
}

d-appendix ol {
  padding: 0 0 0 15px;
}

@media (min-width: 768px) {
  d-appendix ol {
    padding: 0 0 0 30px;
    margin-left: -30px;
  }
}

d-appendix li {
  margin-bottom: 1em;
}

d-appendix a {
  color: rgba(0, 0, 0, 0.6);
}

d-appendix > * {
  grid-column: text;
}

d-appendix > d-footnote-list,
d-appendix > d-citation-list,
d-appendix > distill-appendix {
  grid-column: screen;
}

</style>
<d-footnote-list style="">
<style>

d-footnote-list {
  contain: layout style;
}

d-footnote-list > * {
  grid-column: text;
}

d-footnote-list a.footnote-backlink {
  color: rgba(0,0,0,0.3);
  padding-left: 0.5em;
}

</style>
<h3>脚注</h3>
<ol><li id="d-footnote-1-listing">从历史上看，你可以在完全不接触推理的情况下，对 Transformer 进行大量研究——LLM 损失、多项选择基准测试都可以在没有合适的 KV 缓存或生成循环实现的情况下高效运行。这意味着，尤其是在研究代码库中，推理代码路径上通常有很多容易摘取的低垂果实。<a class="footnote-backlink" href="#d-footnote-1">[↩]</a></li><li id="d-footnote-2-listing">在本节中，你会注意到一件事，那就是推理远不如训练那样宽容。我们通常拥有的 FLOPs 要少得多，批处理的机会也更少，而且对延迟的敏感度要高得多。KV 缓存也极大地复杂化了推理。<a class="footnote-backlink" href="#d-footnote-2">[↩]</a></li><li id="d-footnote-3-listing">我们在这里做了相当多的简化，忽略了应用 softmax、掩码等操作中的非矩阵乘法 FLOPs。它们应该与计算或 HBM 读取重叠，但在某些 TPU 代上实现起来可能不简单。这些细节不会改变主要信息，即 KV 缓存通常是受内存限制的。<a class="footnote-backlink" href="#d-footnote-3">[↩]</a></li><li id="d-footnote-4-listing">特别要感谢 Flash Attention，它避免了将我们的注意力矩阵实例化<a class="footnote-backlink" href="#d-footnote-4">[↩]</a></li><li id="d-footnote-5-listing">训练后不小心保留它是导致数量级性能下降的一个简单而常见的方式<a class="footnote-backlink" href="#d-footnote-5">[↩]</a></li><li id="d-footnote-6-listing">我们的意思是，以较小的批量大小启动多个带有模型副本的服务器。模型级别的数据并行性严格来说更差。<a class="footnote-backlink" href="#d-footnote-6">[↩]</a></li><li id="d-footnote-7-listing">意思是 FLOPs 时间不是我们的瓶颈，所以我们需要担心的是 ICI 时间超过参数加载时间。<a class="footnote-backlink" href="#d-footnote-7">[↩]</a></li></ol>
</d-footnote-list> <d-citation-list style=""><style>
d-citation-list {
  contain: style;
}

d-citation-list .references {
  grid-column: text;
}

d-citation-list .references .title {
  font-weight: 500;
}
</style><h3 id="references">参考文献</h3><ol class="references" id="references-list"><li id="esti"><span class="title">Efficiently scaling Transformer inference</span> <br/>Pope, R., Douglas, S., Chowdhery, A., Devlin, J., Bradbury, J., Levskaya, A., Heek, J., Xiao, K., Agrawal, S. and Dean, J., 2022. arXiv [cs.LG]. </li><li id="paged"><span class="title">Efficient memory management for large language model serving with PagedAttention</span> <br/>Kwon, W., Li, Z., Zhuang, S., Sheng, Y., Zheng, L., Yu, C.H., Gonzalez, J.E., Zhang, H. and Stoica, I., 2023. arXiv [cs.LG]. </li><li id="spec1"><span class="title">Fast inference from Transformers via speculative decoding</span> <br/>Leviathan, Y., Kalman, M. and Matias, Y., 2022. arXiv [cs.LG]. </li><li id="spec2"><span class="title">Accelerating large language model decoding with speculative sampling</span> <br/>Chen, C., Borgeaud, S., Irving, G., Lespiau, J., Sifre, L. and Jumper, J., 2023. arXiv [cs.CL]. </li><li id="eagle"><span class="title">EAGLE: Speculative Sampling Requires Rethinking Feature Uncertainty</span> <br/>Li, Y., Wei, F., Zhang, C. and Zhang, H., 2024. arXiv [cs.LG]. </li><li id="medusa"><span class="title">Medusa: Simple LLM Inference Acceleration Framework with Multiple Decoding Heads</span> <br/>Cai, T., Li, Y., Geng, Z., Peng, H., Lee, J., Chen, D. and Dao, T., 2024. arXiv [cs.LG]. </li><li id="DeepSeek3"><span class="title">DeepSeek-V3 Technical Report</span> <br/>{DeepSeek-AI},, Liu, A., Feng, B., Xue, B., Wang, B., Wu, B., Lu, C., Zhao, C., Deng, C., Zhang, C., Ruan, C., Dai, D., Guo, D., Yang, D., Chen, D., Ji, D., Li, E., Lin, F., Dai, F., Luo, F., Hao, G., Chen, G., Li, G., Zhang, H., Bao, H., Xu, H., Wang, H., Zhang, H., Ding, H., Xin, H., Gao, H., Li, H., Qu, H., Cai, J.L., Liang, J., Guo, J., Ni, J., Li, J., Wang, J., Chen, J., Chen, J., Yuan, J., Qiu, J., Li, J., Song, J., Dong, K., Hu, K., Gao, K., Guan, K., Huang, K., Yu, K., Wang, L., Zhang, L., Xu, L., Xia, L., Zhao, L., Wang, L., Zhang, L., Li, M., Wang, M., Zhang, M., Zhang, M., Tang, M., Li, M., Tian, N., Huang, P., Wang, P., Zhang, P., Wang, Q., Zhu, Q., Chen, Q., Du, Q., Chen, R.J., Jin, R.L., Ge, R., Zhang, R., Pan, R., Wang, R., Xu, R., Zhang, R., Chen, R., Li, S.S., Lu, S., Zhou, S., Chen, S., Wu, S., Ye, S., Ye, S., Ma, S., Wang, S., Zhou, S., Yu, S., Zhou, S., Pan, S., Wang, T., Yun, T., Pei, T., Sun, T., Xiao, W.L., Zeng, W., Zhao, W., An, W., Liu, W., Liang, W., Gao, W., Yu, W., Zhang, W., Li, X.Q., Jin, X., Wang, X., Bi, X., Liu, X., Wang, X., Shen, X., Chen, X., Zhang, X., Chen, X., Nie, X., Sun, X., Wang, X., Cheng, X., Liu, X., Xie, X., Liu, X., Yu, X., Song, X., Shan, X., Zhou, X., Yang, X., Li, X., Su, X., Lin, X., Li, Y.K., Wang, Y.Q., Wei, Y.X., Zhu, Y.X., Zhang, Y., Xu, Y., Xu, Y., Huang, Y., Li, Y., Zhao, Y., Sun, Y., Li, Y., Wang, Y., Yu, Y., Zheng, Y., Zhang, Y., Shi, Y., Xiong, Y., He, Y., Tang, Y., Piao, Y., Wang, Y., Tan, Y., Ma, Y., Liu, Y., Guo, Y., Wu, Y., Ou, Y., Zhu, Y., Wang, Y., Gong, Y., Zou, Y., He, Y., Zha, Y., Xiong, Y., Ma, Y., Yan, Y., Luo, Y., You, Y., Liu, Y., Zhou, Y., Wu, Z.F., Ren, Z.Z., Ren, Z., Sha, Z., Fu, Z., Xu, Z., Huang, Z., Zhang, Z., Xie, Z., Zhang, Z., Hao, Z., Gou, Z., Ma, Z., Yan, Z., Shao, Z., Xu, Z., Wu, Z., Zhang, Z., Li, Z., Gu, Z., Zhu, Z., Liu, Z., Li, Z., Xie, Z., Song, Z., Gao, Z. and Pan, Z., 2024. arXiv [cs.CL]. </li></ol></d-citation-list> <div class="base-grid appendix-entry"> <h3 style="grid-column: 0;">杂项</h3> <p class="author-footnote" style="grid-column: text;"><sup>*</sup>在 Google DeepMind 完成的工作，现就职于 MatX。</p> </div> <div class="base-grid appendix-entry"> <h3 style="grid-column: 0;">引用</h3> <p class="author-footnote">在学术背景下进行引用，请将此作品引用为：</p> <div class="author-footnote"> <div class="language-bibtex highlighter-rouge"><div class="highlight"><div class="code-display-wrapper"><pre class="highlight"><code>    <span class="c">Austin et al., "How to Scale Your Model", Google DeepMind, online, 2025.</span>
</code></pre><button aria-label="Copy code to clipboard" class="copy" type="button"><i class="fa-solid fa-clipboard"></i></button></div></div></div> </div> <p class="author-footnote">或作为 BibTeX 条目：</p> <div class="author-footnote"> <div class="language-bibtex highlighter-rouge"><div class="highlight"><div class="code-display-wrapper"><pre class="highlight"><code>    <span class="nc">@article</span><span class="p">{</span><span class="nl">scaling-book</span><span class="p">,</span>
      <span class="na">title</span> <span class="p">=</span> <span class="s">{How to Scale Your Model}</span><span class="p">,</span>
      <span class="na">author</span> <span class="p">=</span> <span class="s">{Austin, Jacob and Douglas, Sholto and Frostig, Roy and Levskaya, Anselm and Chen, Charlie and Vikram, Sharad
      and Lebron, Federico and Choy, Peter and Ramasesh, Vinay and Webson, Albert and Pope, Reiner}</span><span class="p">,</span>
      <span class="na">publisher</span> <span class="p">=</span> <span class="s">{Google DeepMind}</span><span class="p">,</span>
      <span class="na">howpublished</span> <span class="p">=</span> <span class="s">{Online}</span><span class="p">,</span>
      <span class="na">note</span> <span class="p">=</span> <span class="s">{Retrieved from https://jax-ml.github.io/scaling-book/}</span><span class="p">,</span>
      <span class="na">year</span> <span class="p">=</span> <span class="s">{2025}</span>
    <span class="p">}</span>
</code></pre><button aria-label="Copy code to clipboard" class="copy" type="button"><i class="fa-solid fa-clipboard"></i></button></div></div></div> </div> </div> </d-appendix> <d-bibliography src="/scaling-book/assets/bibliography/main.bib"></d-bibliography> <div id="giscus_thread" style="max-width: 930px; margin: 0 auto;"> <script>
      let giscusTheme = determineComputedTheme();
      let giscusAttributes = {
        src: 'https://giscus.app/client.js',
        'data-repo': 'jax-ml/scaling-book',
        'data-repo-id': '',
        'data-category': 'General',
        'data-category-id': '',
        'data-mapping': 'title',
        'data-strict': '0',
        'data-reactions-enabled': '1',
        'data-emit-metadata': '0',
        'data-input-position': 'bottom',
        'data-theme': giscusTheme,
        'data-loading': '1',
        'data-lang': 'en',
        crossorigin: 'anonymous',
        async: '',
      };

      let giscusScript = document.createElement('script');
      Object.entries(giscusAttributes).forEach(([key, value]) => giscusScript.setAttribute(key, value));
      document.getElementById('giscus_thread').appendChild(giscusScript);
    </script><script async="" crossorigin="anonymous" data-category="General" data-category-id="" data-emit-metadata="0" data-input-position="bottom" data-lang="en" data-loading="1" data-mapping="title" data-reactions-enabled="1" data-repo="jax-ml/scaling-book" data-repo-id="" data-strict="0" data-theme="light" src="https://giscus.app/client.js"></script><div class="giscus"><iframe allow="clipboard-write" class="giscus-frame giscus-frame--loading" scrolling="no" src="https://giscus.app/en/widget?origin=https%3A%2F%2Fjax-ml.github.io%2Fscaling-book%2Finference%2F&amp;session=&amp;theme=light&amp;reactionsEnabled=1&amp;emitMetadata=0&amp;inputPosition=bottom&amp;repo=jax-ml%2Fscaling-book&amp;repoId=&amp;category=General&amp;categoryId=&amp;strict=0&amp;description=Performing+inference+on+a+Transformer+can+be+very+different+from+training.+Partly+this+is+because+inference+adds+a+new+factor+to+consider%3A+latency.+In+this+section%2C+we+will+go+all+the+way+from+sampling+a+single+new+token+from+a+model+to+efficiently+scaling+a+large+Transformer+across+many+slices+of+accelerators+as+part+of+an+inference+engine.&amp;backLink=https%3A%2F%2Fjax-ml.github.io%2Fscaling-book%2Finference%2F&amp;term=All+About+Transformer+Inference+%7C+How+To+Scale+Your+Model" style="opacity: 0;" title="Comments"></iframe></div> <noscript>请启用 JavaScript 以查看由 giscus 驱动的<a href="http://giscus.app/?ref_noscript" rel="external nofollow noopener" target="_blank">评论。</a> </noscript> </div> </div> <footer class="sticky-bottom mt-5" role="contentinfo"> <div class="container"> © 版权所有 2025 。由 <a href="https://jekyllrb.com/" rel="external nofollow noopener" target="_blank">Jekyll</a> 和 <a href="https://github.com/alshedivat/al-folio" rel="external nofollow noopener" target="_blank">al-folio</a> 主题驱动。由 <a href="https://pages.github.com/" rel="external nofollow noopener" target="_blank">GitHub Pages</a> 托管。 </div> </footer> <script crossorigin="anonymous" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js"></script> <script src="https://jax-ml.github.io/scaling-book/assets/js/bootstrap.bundle.min.js"></script> <script crossorigin="anonymous" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js"></script> <script crossorigin="anonymous" defer="" integrity="sha256-ZgMyDAIYDYGxbcpJcfUnYwNevG/xi9OHKaR/8GK+jWc=" src="https://cdn.jsdelivr.net/npm/medium-zoom@1.1.0/dist/medium-zoom.min.js"></script> <script defer="" src="https://jax-ml.github.io/scaling-book/assets/js/zoom.js?85ddb88934d28b74e78031fd54cf8308"></script> <script src="https://jax-ml.github.io/scaling-book/assets/js/no_defer.js?2781658a0a2b13ed609542042a859126"></script> <script defer="" src="https://jax-ml.github.io/scaling-book/assets/js/common.js?e0514a05c5c95ac1a93a8dfd5249b92e"></script> <script defer="" src="https://jax-ml.github.io/scaling-book/assets/js/copy_code.js?12775fdf7f95e901d7119054556e495f" type="text/javascript"></script> <script defer="" src="https://jax-ml.github.io/scaling-book/assets/js/jupyter_new_tab.js?d9f17b6adc2311cbabd747f4538bb15f"></script> <script crossorigin="anonymous" defer="" id="MathJax-script" integrity="sha256-MASABpB4tYktI2Oitl4t+78w/lyA+D7b/s9GEP0JOGI=" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.2/es5/tex-mml-chtml.js" type="text/javascript"></script> <script src="https://jax-ml.github.io/scaling-book/assets/js/mathjax-setup.js?70d799092f862ad98c7876aa47712e20"></script> <script crossorigin="anonymous" defer="" src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6"></script> <script defer="" src="https://jax-ml.github.io/scaling-book/assets/js/progress-bar.js?2f30e0e6801ea8f5036fa66e1ab0a71a" type="text/javascript"></script> <script src="https://jax-ml.github.io/scaling-book/assets/js/vanilla-back-to-top.min.js?f40d453793ff4f64e238e420181a1d17"></script> <script>
    addBackToTop();
  </script><div class="hidden" id="back-to-top"><svg viewbox="0 0 24 24"><path d="M7.41 15.41L12 10.83l4.59 4.58L18 14l-6-6-6 6z"></path></svg></div> <div class="hiddendiv common"></div></body>
</html>