"""
HTMLç¿»è¯‘æ¨¡å—
ä½¿ç”¨Gemini APIè¿›è¡Œæ™ºèƒ½ç¿»è¯‘ï¼Œä¿æŒHTMLæ ¼å¼å®Œå…¨ä¸€è‡´

åˆ›å»ºæ—¶é—´ï¼š2024-12-19
é¡¹ç›®ï¼šç³»åˆ—æŠ€æœ¯æ–‡ç« ç¿»è¯‘
"""

import logging
import time
import json
import sys
import re
from pathlib import Path
from typing import Dict, Optional, Tuple, List
from pydantic import BaseModel, Field
from bs4 import BeautifulSoup, NavigableString, Comment

from gemini_api import GeminiAPI
from config.settings import OUTPUT_DIR, TRANS_DIR


class TranslationResponse(BaseModel):
    """ç¿»è¯‘å“åº”çš„ç»“æ„åŒ–æ¨¡å‹"""
    translated_html: str = Field(description="ç¿»è¯‘åçš„å®Œæ•´HTMLå†…å®¹ï¼Œä¿æŒåŸæ ¼å¼ä¸å˜")


class MetadataTranslationResponse(BaseModel):
    """å…ƒæ•°æ®ç¿»è¯‘å“åº”çš„ç»“æ„åŒ–æ¨¡å‹"""
    translated_title: str = Field(description="ç¿»è¯‘åçš„é¡µé¢æ ‡é¢˜")
    translated_description: str = Field(description="ç¿»è¯‘åçš„é¡µé¢æè¿°")


class HTMLParts(BaseModel):
    """HTMLå„éƒ¨åˆ†çš„ç»“æ„åŒ–æ¨¡å‹"""
    head_content: str = Field(description="headéƒ¨åˆ†çš„å®Œæ•´å†…å®¹")
    body_content: str = Field(description="bodyéƒ¨åˆ†çš„å®Œæ•´å†…å®¹")
    original_title: str = Field(description="åŸå§‹é¡µé¢æ ‡é¢˜")
    original_description: str = Field(description="åŸå§‹é¡µé¢æè¿°")
    html_attrs: str = Field(description="htmlæ ‡ç­¾çš„å±æ€§")
    doctype: str = Field(description="æ–‡æ¡£ç±»å‹å£°æ˜")


class HTMLTranslator:
    """HTMLç¿»è¯‘å™¨ï¼Œä½¿ç”¨Gemini APIè¿›è¡Œæ™ºèƒ½ç¿»è¯‘"""

    def __init__(self):
        """åˆå§‹åŒ–ç¿»è¯‘å™¨"""
        self.logger = logging.getLogger(__name__)

        # åˆå§‹åŒ–Gemini API
        try:
            self.gemini_api = GeminiAPI()
            self.logger.info("Gemini APIåˆå§‹åŒ–æˆåŠŸ")
        except Exception as e:
            self.logger.error(f"Gemini APIåˆå§‹åŒ–å¤±è´¥: {str(e)}")
            raise

        # ç¡®ä¿è¾“å‡ºç›®å½•å­˜åœ¨
        Path(TRANS_DIR).mkdir(parents=True, exist_ok=True)

        # æ•°å­¦å†…å®¹å­˜å‚¨ï¼ˆç”¨äºå ä½ç¬¦æœºåˆ¶ï¼‰
        self.math_content_store: Dict[str, str] = {}

        # ä¸“ä¸šæœ¯è¯­è¯å…¸
        self.terminology = {
            "TPU": "TPU",
            "TensorCore": "TensorCore",
            "systolic array": "è„‰åŠ¨é˜µåˆ—",
            "matrix multiplication": "çŸ©é˜µä¹˜æ³•",
            "HBM": "HBM",
            "bandwidth": "å¸¦å®½",
            "FLOPs": "FLOPs",
            "bfloat16": "bfloat16",
            "int8": "int8",
            "MXU": "MXU",
            "VPU": "VPU",
            "VMEM": "VMEM",
            "ICI": "ICI",
            "PCIe": "PCIe",
            "DCN": "DCN",
            "roofline": "å±‹é¡¶çº¿",
            "sharding": "åˆ†ç‰‡",
            "JAX": "JAX",
            "scaling": "æ‰©å±•",
            "inference": "æ¨ç†",
            "training": "è®­ç»ƒ",
            "transformer": "Transformer",
            "attention": "æ³¨æ„åŠ›",
            "GPU": "GPU",
            "CUDA": "CUDA",
            "parallelism": "å¹¶è¡Œæ€§",
            "Footnotes": "è„šæ³¨",
            "References": "å‚è€ƒæ–‡çŒ®",
            "Citation": "å¼•ç”¨",
            "Authors": "ä½œè€…",
            "Published": "å‘å¸ƒæ—¥æœŸ",
            "Contents": "ç›®å½•"
        }

        self.logger.info("HTMLç¿»è¯‘å™¨åˆå§‹åŒ–å®Œæˆ")

    def extract_html_parts(self, html_content: str) -> HTMLParts:
        """
        æå–HTMLçš„å„ä¸ªéƒ¨åˆ†

        Args:
            html_content (str): å®Œæ•´çš„HTMLå†…å®¹

        Returns:
            HTMLParts: åˆ†ç¦»åçš„HTMLå„éƒ¨åˆ†
        """
        try:
            # è§£æHTML
            soup = BeautifulSoup(html_content, 'html.parser')

            # æå–doctype
            doctype = "<!DOCTYPE html>"  # é»˜è®¤HTML5 DOCTYPE
            for item in soup.contents:
                if hasattr(item, 'name') and item.name is None:
                    doctype_str = str(item).strip()
                    if doctype_str.upper().startswith('<!DOCTYPE'):
                        doctype = doctype_str
                        break

            # è·å–htmlæ ‡ç­¾å±æ€§
            html_tag = soup.find('html')
            html_attrs = ""
            if html_tag and html_tag.attrs:
                attrs_list = [f'{k}="{v}"' if isinstance(v, str) else f'{k}="{" ".join(v)}"'
                             for k, v in html_tag.attrs.items()]
                html_attrs = " " + " ".join(attrs_list)

            # æå–headå†…å®¹
            head_tag = soup.find('head')
            head_content = str(head_tag) if head_tag else "<head></head>"

            # æå–bodyå†…å®¹
            body_tag = soup.find('body')
            body_content = str(body_tag) if body_tag else "<body></body>"

            # æå–æ ‡é¢˜
            title_tag = soup.find('title')
            original_title = title_tag.get_text() if title_tag else ""

            # æå–æè¿°
            desc_tag = soup.find('meta', attrs={'name': 'description'})
            original_description = desc_tag.get('content', '') if desc_tag else ""

            parts = HTMLParts(
                head_content=head_content,
                body_content=body_content,
                original_title=original_title,
                original_description=original_description,
                html_attrs=html_attrs,
                doctype=doctype
            )

            return parts

        except Exception as e:
            self.logger.error(f"HTMLè§£æå¤±è´¥: {str(e)}")
            raise

    def _clean_body_for_translation(self, body_content: str) -> str:
        """
        æ¸…ç†bodyå†…å®¹ï¼Œç§»é™¤ä¸éœ€è¦ç¿»è¯‘çš„éƒ¨åˆ†ï¼Œå¹¶ä½¿ç”¨å ä½ç¬¦æ›¿æ¢æ•°å­¦å†…å®¹

        Args:
            body_content (str): åŸå§‹bodyå†…å®¹

        Returns:
            str: æ¸…ç†åçš„bodyå†…å®¹
        """
        try:
            soup = BeautifulSoup(body_content, 'html.parser')

            # ç§»é™¤æ³¨é‡Š
            for comment in soup.find_all(string=lambda text: isinstance(text, Comment)):
                comment.extract()

            # æ¸…ç©ºæ•°å­¦å†…å®¹å­˜å‚¨ï¼Œå¼€å§‹æ–°çš„ç¿»è¯‘ä»»åŠ¡
            self.math_content_store.clear()

            # æå–å¹¶æ›¿æ¢ <mjx-container> æ ‡ç­¾
            mjx_containers = soup.find_all('mjx-container')
            for i, container in enumerate(mjx_containers):
                placeholder = f"MATH_PLACEHOLDER_{i:03d}"
                # ä¿å­˜å®Œæ•´çš„æ ‡ç­¾å†…å®¹
                self.math_content_store[placeholder] = str(container)
                # åˆ›å»ºå ä½ç¬¦æ ‡ç­¾
                placeholder_tag = soup.new_tag('span', **{'data-math-placeholder': placeholder})
                placeholder_tag.string = placeholder
                # æ›¿æ¢åŸæ ‡ç­¾
                container.replace_with(placeholder_tag)

            self.logger.info(f"æå–äº† {len(mjx_containers)} ä¸ªæ•°å­¦å…¬å¼æ ‡ç­¾")

            return str(soup)

        except Exception as e:
            self.logger.error(f"å†…å®¹æ¸…ç†å¤±è´¥: {str(e)}")
            return body_content

    def _translate_metadata(self, title: str, description: str) -> Optional[Dict[str, str]]:
        """
        ç¿»è¯‘é¡µé¢æ ‡é¢˜å’Œæè¿°

        Args:
            title (str): åŸå§‹æ ‡é¢˜
            description (str): åŸå§‹æè¿°

        Returns:
            Optional[Dict[str, str]]: ç¿»è¯‘åçš„æ ‡é¢˜å’Œæè¿°
        """
        if not title and not description:
            return None

        try:
            terminology_list = "\n".join([f"- {en}: {zh}" for en, zh in self.terminology.items()])

            prompt = f"""ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„æŠ€æœ¯æ–‡æ¡£ç¿»è¯‘ä¸“å®¶ï¼Œè¯·ç¿»è¯‘ä»¥ä¸‹é¡µé¢å…ƒæ•°æ®ï¼š

ä¸“ä¸šæœ¯è¯­å¯¹ç…§è¡¨ï¼š
{terminology_list}

ç¿»è¯‘è¦æ±‚ï¼š
1. ä¿æŒæŠ€æœ¯æœ¯è¯­çš„ä¸€è‡´æ€§
2. æ ‡é¢˜è¦ç®€æ´æ˜äº†ï¼Œç¬¦åˆä¸­æ–‡ä¹ æƒ¯
3. æè¿°è¦å‡†ç¡®ä¼ è¾¾åŸæ–‡å«ä¹‰ï¼Œä¿æŒä¸“ä¸šæ€§

åŸå§‹æ ‡é¢˜: {title}
åŸå§‹æè¿°: {description}

è¯·åªè¿”å›ç¿»è¯‘åçš„æ ‡é¢˜å’Œæè¿°ï¼Œä¸è¦æ·»åŠ ä»»ä½•è§£é‡Šã€‚"""

            response = self.gemini_api.generate_structured_content(
                prompt=prompt,
                response_schema=MetadataTranslationResponse
            )

            if response:
                return {
                    'title': response.translated_title,
                    'description': response.translated_description
                }
            else:
                return None

        except Exception as e:
            self.logger.error(f"å…ƒæ•°æ®ç¿»è¯‘å¤±è´¥: {str(e)}")
            return None

    def _restore_math_content(self, translated_html: str) -> str:
        """
        å°†å ä½ç¬¦æ›¿æ¢å›åŸå§‹çš„æ•°å­¦å†…å®¹

        Args:
            translated_html (str): åŒ…å«å ä½ç¬¦çš„ç¿»è¯‘åHTML

        Returns:
            str: æ¢å¤æ•°å­¦å†…å®¹åçš„HTML
        """
        try:
            if not self.math_content_store:
                return translated_html

            soup = BeautifulSoup(translated_html, 'html.parser')

            # æŸ¥æ‰¾æ‰€æœ‰å ä½ç¬¦æ ‡ç­¾
            placeholders = soup.find_all('span', attrs={'data-math-placeholder': True})
            restored_count = 0

            for placeholder_tag in placeholders:
                placeholder_key = placeholder_tag.get('data-math-placeholder')
                if placeholder_key in self.math_content_store:
                    # è·å–åŸå§‹æ•°å­¦å†…å®¹
                    original_math = self.math_content_store[placeholder_key]
                    # è§£æåŸå§‹æ•°å­¦æ ‡ç­¾
                    math_soup = BeautifulSoup(original_math, 'html.parser')
                    math_tag = math_soup.find('mjx-container')
                    if math_tag:
                        # æ›¿æ¢å ä½ç¬¦
                        placeholder_tag.replace_with(math_tag)
                        restored_count += 1

            self.logger.info(f"æ¢å¤äº† {restored_count} ä¸ªæ•°å­¦å…¬å¼æ ‡ç­¾")
            return str(soup)

        except Exception as e:
            self.logger.error(f"æ¢å¤æ•°å­¦å†…å®¹å¤±è´¥: {str(e)}")
            return translated_html

    def reassemble_html(self, parts: HTMLParts, translated_body: str,
                       translated_title: str = "", translated_description: str = "") -> str:
        """
        é‡æ–°ç»„è£…HTML

        Args:
            parts (HTMLParts): åŸå§‹HTMLå„éƒ¨åˆ†
            translated_body (str): ç¿»è¯‘åçš„bodyå†…å®¹
            translated_title (str): ç¿»è¯‘åçš„æ ‡é¢˜
            translated_description (str): ç¿»è¯‘åçš„æè¿°

        Returns:
            str: å®Œæ•´çš„ç¿»è¯‘åHTML
        """
        try:
            # é¦–å…ˆæ¢å¤æ•°å­¦å†…å®¹
            translated_body_with_math = self._restore_math_content(translated_body)

            # è§£æheadå†…å®¹ä»¥æ›´æ–°æ ‡é¢˜å’Œæè¿°
            head_soup = BeautifulSoup(parts.head_content, 'html.parser')

            # æ›´æ–°æ ‡é¢˜
            if translated_title:
                title_tag = head_soup.find('title')
                if title_tag:
                    title_tag.string = translated_title
                else:
                    # å¦‚æœæ²¡æœ‰titleæ ‡ç­¾ï¼Œåˆ›å»ºä¸€ä¸ª
                    new_title = head_soup.new_tag('title')
                    new_title.string = translated_title
                    if head_soup.head:
                        head_soup.head.insert(0, new_title)

            # æ›´æ–°æè¿°
            if translated_description:
                desc_tag = head_soup.find('meta', attrs={'name': 'description'})
                if desc_tag:
                    desc_tag['content'] = translated_description
                else:
                    # å¦‚æœæ²¡æœ‰description metaæ ‡ç­¾ï¼Œåˆ›å»ºä¸€ä¸ª
                    if head_soup.head:
                        new_desc = head_soup.new_tag('meta', name='description', content=translated_description)
                        head_soup.head.append(new_desc)

            # æ›´æ–°è¯­è¨€å±æ€§
            html_attrs_updated = parts.html_attrs
            if 'lang=' in html_attrs_updated:
                html_attrs_updated = re.sub(r'lang="[^"]*"', 'lang="zh-CN"', html_attrs_updated)
            elif html_attrs_updated:
                html_attrs_updated += ' lang="zh-CN"'
            else:
                html_attrs_updated = ' lang="zh-CN"'

            # ç»„è£…å®Œæ•´HTML - ä¿®å¤headå†…å®¹æå–
            doctype = parts.doctype if parts.doctype else "<!DOCTYPE html>"

            # ç¡®ä¿åªæå–headæ ‡ç­¾çš„å†…å®¹ï¼Œä¸åŒ…å«å¤šä½™çš„æ–‡æœ¬
            if head_soup.head:
                updated_head = str(head_soup.head)
            else:
                # å¦‚æœæ²¡æœ‰æ‰¾åˆ°headæ ‡ç­¾ï¼Œä½¿ç”¨åŸå§‹å†…å®¹
                updated_head = parts.head_content

            complete_html = f"""{doctype}
<html{html_attrs_updated}>
{updated_head}
{translated_body_with_math}
</html>"""

            # æ£€æŸ¥å¹¶ä¿®å¤HTMLå¼€å¤´çš„å¤šä½™æ–‡æœ¬
            complete_html = self._fix_html_prefix(complete_html)

            return complete_html

        except Exception as e:
            self.logger.error(f"HTMLç»„è£…å¤±è´¥: {str(e)}")
            raise

    def _fix_html_prefix(self, html_content: str) -> str:
        """
        ä¿®å¤HTMLå¼€å¤´çš„å¤šä½™æ–‡æœ¬é—®é¢˜ï¼Œå¹¶ç¡®ä¿æœ‰æ­£ç¡®çš„DOCTYPEå£°æ˜

        Args:
            html_content (str): HTMLå†…å®¹

        Returns:
            str: ä¿®å¤åçš„HTMLå†…å®¹
        """
        try:
            lines = html_content.split('\n')
            fixed_lines = []
            has_doctype = False

            for i, line in enumerate(lines):
                # æ£€æŸ¥ç¬¬ä¸€è¡Œæ˜¯å¦åªåŒ…å«"html"æ–‡æœ¬
                if i == 0 and line.strip().lower() == 'html':
                    self.logger.warning("æ£€æµ‹åˆ°HTMLå¼€å¤´å¤šä½™çš„'html'æ–‡æœ¬ï¼Œå·²ç§»é™¤")
                    continue
                # æ£€æŸ¥æ˜¯å¦æœ‰å…¶ä»–ç±»ä¼¼çš„å¤šä½™æ–‡æœ¬
                elif i == 0 and line.strip() and not line.strip().startswith('<!DOCTYPE'):
                    # å¦‚æœç¬¬ä¸€è¡Œä¸æ˜¯DOCTYPEå£°æ˜ï¼Œæ£€æŸ¥æ˜¯å¦æ˜¯å¤šä½™çš„æ–‡æœ¬
                    if not line.strip().startswith('<'):
                        self.logger.warning(f"æ£€æµ‹åˆ°HTMLå¼€å¤´å¤šä½™æ–‡æœ¬: '{line.strip()}'ï¼Œå·²ç§»é™¤")
                        continue

                # æ£€æŸ¥æ˜¯å¦æœ‰DOCTYPEå£°æ˜
                if line.strip().upper().startswith('<!DOCTYPE'):
                    has_doctype = True

                fixed_lines.append(line)

            # å¦‚æœæ²¡æœ‰DOCTYPEå£°æ˜ï¼Œæ·»åŠ ä¸€ä¸ª
            if not has_doctype:
                self.logger.warning("æ£€æµ‹åˆ°ç¼ºå°‘DOCTYPEå£°æ˜ï¼Œå·²æ·»åŠ ")
                fixed_lines.insert(0, '<!DOCTYPE html>')

            return '\n'.join(fixed_lines)

        except Exception as e:
            self.logger.error(f"ä¿®å¤HTMLå‰ç¼€å¤±è´¥: {str(e)}")
            return html_content

    def _build_translation_prompt(self, html_content: str) -> str:
        """
        æ„å»ºç¿»è¯‘æç¤ºè¯

        Args:
            html_content (str): è¦ç¿»è¯‘çš„HTMLå†…å®¹

        Returns:
            str: æ„å»ºå¥½çš„æç¤ºè¯
        """
        terminology_list = "\n".join([f"- {en}: {zh}" for en, zh in self.terminology.items()])

        prompt = f"""ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„æŠ€æœ¯æ–‡æ¡£ç¿»è¯‘ä¸“å®¶ï¼Œä¸“é—¨ç¿»è¯‘æœºå™¨å­¦ä¹ å’Œæ·±åº¦å­¦ä¹ ç›¸å…³çš„æŠ€æœ¯æ–‡ç« ã€‚

è¯·å°†ä»¥ä¸‹HTMLå†…å®¹ä»è‹±æ–‡ç¿»è¯‘æˆä¸­æ–‡ï¼Œè¦æ±‚ï¼š

1. **æ ¼å¼ä¿æŒ**ï¼šå®Œå…¨ä¿æŒåŸHTMLç»“æ„ã€æ ‡ç­¾ã€å±æ€§ã€CSSç±»åã€IDç­‰ä¸å˜
2. **å†…å®¹ç¿»è¯‘**ï¼šåªç¿»è¯‘HTMLæ ‡ç­¾å†…çš„æ–‡æœ¬å†…å®¹ï¼Œä¸ç¿»è¯‘HTMLæ ‡ç­¾æœ¬èº«
3. **æœ¯è¯­ä¸€è‡´æ€§**ï¼šä½¿ç”¨ä»¥ä¸‹ä¸“ä¸šæœ¯è¯­å¯¹ç…§è¡¨ä¿æŒç¿»è¯‘ä¸€è‡´æ€§ï¼š
{terminology_list}

4. **ç¿»è¯‘è´¨é‡**ï¼š
   - å‡†ç¡®ä¼ è¾¾åŸæ–‡æŠ€æœ¯å«ä¹‰
   - ä¿æŒä¸­æ–‡è¡¨è¾¾çš„æµç•…æ€§å’Œè‡ªç„¶æ€§
   - ä¿æŒæŠ€æœ¯æ–‡æ¡£çš„ä¸“ä¸šæ€§å’Œä¸¥è°¨æ€§
   - æ•°å­¦å…¬å¼ã€ä»£ç ç‰‡æ®µã€URLé“¾æ¥ä¿æŒä¸å˜

5. **ç‰¹æ®Šå¤„ç†**ï¼š
   - HTMLæ³¨é‡Šä¸ç¿»è¯‘
   - JavaScriptä»£ç ä¸ç¿»è¯‘
   - CSSæ ·å¼ä¸ç¿»è¯‘
   - å±æ€§å€¼ä¸ç¿»è¯‘ï¼ˆå¦‚classåã€idç­‰ï¼‰
   - é”šç‚¹é“¾æ¥ï¼ˆ#å¼€å¤´ï¼‰ä¸ç¿»è¯‘
   - æ•°å­¦å…¬å¼å ä½ç¬¦ï¼ˆMATH_PLACEHOLDER_XXXï¼‰ä¸ç¿»è¯‘ï¼Œä¿æŒåŸæ ·

è¯·åªè¿”å›ç¿»è¯‘åçš„å®Œæ•´HTMLå†…å®¹ï¼Œä¸è¦æ·»åŠ ä»»ä½•è§£é‡Šæˆ–é¢å¤–ä¿¡æ¯ã€‚

åŸHTMLå†…å®¹ï¼š
{html_content}"""

        return prompt

    async def _translate_body_content(self, body_content: str, context: str = "") -> Optional[Dict]:
        """
        ç¿»è¯‘bodyå†…å®¹ï¼ˆå†…éƒ¨æ–¹æ³•ï¼‰

        Args:
            body_content (str): è¦ç¿»è¯‘çš„bodyå†…å®¹
            context (str): ç¿»è¯‘ä¸Šä¸‹æ–‡ï¼ˆå¯é€‰ï¼‰

        Returns:
            Optional[Dict]: ç¿»è¯‘ç»“æœå­—å…¸ï¼Œå¤±è´¥æ—¶è¿”å›None
        """
        if not body_content:
            return None

        try:
            # æ„å»ºç¿»è¯‘æç¤ºè¯
            prompt = self._build_translation_prompt(body_content)

            # è°ƒç”¨Gemini APIè¿›è¡Œç»“æ„åŒ–ç¿»è¯‘
            start_time = time.time()

            response = self.gemini_api.generate_structured_content_with_stream(
                prompt=prompt,
                response_schema=TranslationResponse
            )

            translation_time = time.time() - start_time

            if response and response.translated_html:
                translation_result = {
                    'original_html': body_content,
                    'translated_html': response.translated_html,
                    'original_length': len(body_content),
                    'translated_length': len(response.translated_html),
                    'translation_time': translation_time,
                    'success': True,
                    'timestamp': time.time(),
                    'context': context
                }

                return translation_result
            else:
                return None

        except Exception as e:
            self.logger.error(f"ç¿»è¯‘å¤±è´¥: {str(e)}")
            return None

    async def translate_html(self, html_content: str, context: str = "") -> Optional[str]:
        """
        HTMLç¿»è¯‘æ–¹æ³•ï¼šåˆ†ç¦»headå’Œbodyï¼Œåªç¿»è¯‘å¿…è¦å†…å®¹ï¼Œç¿»è¯‘å…ƒæ•°æ®

        Args:
            html_content (str): å®Œæ•´çš„HTMLå†…å®¹
            context (str): ç¿»è¯‘ä¸Šä¸‹æ–‡ï¼ˆå¯é€‰ï¼‰

        Returns:
            Optional[str]: ç¿»è¯‘åä¿å­˜çš„æ–‡ä»¶è·¯å¾„ï¼Œå¤±è´¥æ—¶è¿”å›None
        """
        if not html_content:
            return None

        self.logger.info(f"å¼€å§‹ç¿»è¯‘: {len(html_content):,}å­—ç¬¦")
        start_time = time.time()

        try:
            # 1. æå–HTMLå„éƒ¨åˆ†
            parts = self.extract_html_parts(html_content)

            # 2. ç¿»è¯‘å…ƒæ•°æ®ï¼ˆæ ‡é¢˜å’Œæè¿°ï¼‰
            translated_metadata = self._translate_metadata(
                parts.original_title,
                parts.original_description
            )

            translated_title = ""
            translated_description = ""
            if translated_metadata:
                translated_title = translated_metadata.get('title', '')
                translated_description = translated_metadata.get('description', '')

            # 3. æ¸…ç†å¹¶ç¿»è¯‘bodyå†…å®¹
            cleaned_body = self._clean_body_for_translation(parts.body_content)
            body_reduction = len(parts.body_content) - len(cleaned_body)

            body_translation_result = await self._translate_body_content(cleaned_body, f"Bodyéƒ¨åˆ† - {context}")

            if not body_translation_result or not body_translation_result.get('success'):
                return None

            translated_body = body_translation_result['translated_html']

            # 4. é‡æ–°ç»„è£…HTML
            complete_translated_html = self.reassemble_html(
                parts,
                translated_body,
                translated_title,
                translated_description
            )

            translation_time = time.time() - start_time

            # ç›´æ¥ä¿å­˜ç¿»è¯‘åçš„HTMLå¹¶è¿”å›æ–‡ä»¶è·¯å¾„
            trans_dir = Path(TRANS_DIR)
            trans_dir.mkdir(parents=True, exist_ok=True)

            # ä»contextä¸­æå–æ–‡ä»¶åï¼Œæˆ–ä½¿ç”¨é»˜è®¤åç§°
            if "æ–‡ä»¶:" in context:
                input_file = context.split("æ–‡ä»¶:")[1].strip()
                filename = Path(input_file).name
            else:
                filename = "translated.html"

            file_path = trans_dir / filename

            # ä¿å­˜ç¿»è¯‘åçš„HTML
            with open(file_path, 'w', encoding='utf-8') as f:
                f.write(complete_translated_html)

            self.logger.info(f"ç¿»è¯‘å®Œæˆ: {filename} ({translation_time:.1f}s, èŠ‚çœ{body_reduction/len(parts.body_content)*100:.0f}%å†…å®¹)")

            return str(file_path)

        except Exception as e:
            self.logger.error(f"ç¿»è¯‘å¤±è´¥: {str(e)}")
            return None

    async def translate_article(self, content: str, title: str = "", url: str = "") -> Optional[str]:
        """
        ç¿»è¯‘å®Œæ•´æ–‡ç« 

        Args:
            content (str): æ–‡ç« HTMLå†…å®¹
            title (str): æ–‡ç« æ ‡é¢˜ï¼ˆå¯é€‰ï¼‰
            url (str): æ–‡ç« URLï¼ˆå¯é€‰ï¼‰

        Returns:
            Optional[str]: ç¿»è¯‘åä¿å­˜çš„æ–‡ä»¶è·¯å¾„
        """
        context = f"æ–‡ç« æ ‡é¢˜: {title}, URL: {url}" if title or url else ""
        return await self.translate_html(content, context)




# ä¾¿æ·å‡½æ•°
async def translate_html_content(html_content: str, context: str = "") -> Optional[str]:
    """ä¾¿æ·å‡½æ•°ï¼šç¿»è¯‘HTMLå†…å®¹ï¼Œè¿”å›ä¿å­˜çš„æ–‡ä»¶è·¯å¾„"""
    translator = HTMLTranslator()
    return await translator.translate_html(html_content, context)


async def translate_html_file(input_file: str, force_translate: bool = False) -> Optional[str]:
    """ä¾¿æ·å‡½æ•°ï¼šç¿»è¯‘HTMLæ–‡ä»¶ï¼Œä½¿ç”¨åŸå§‹æ–‡ä»¶åä¿å­˜åˆ°output/transç›®å½•"""
    try:
        input_path = Path(input_file)
        trans_dir = Path(TRANS_DIR)
        target_file = trans_dir / input_path.name

        # æ£€æŸ¥ç›®æ ‡æ–‡ä»¶æ˜¯å¦å·²å­˜åœ¨
        if target_file.exists() and not force_translate:
            logging.getLogger(__name__).info(f"â­ï¸  è·³è¿‡å·²ç¿»è¯‘æ–‡ä»¶: {input_path.name}")
            return str(target_file)

        # è¯»å–è¾“å…¥æ–‡ä»¶
        with open(input_file, 'r', encoding='utf-8') as f:
            html_content = f.read()

        # ç¿»è¯‘å†…å®¹å¹¶ä¿å­˜
        translator = HTMLTranslator()
        saved_path = await translator.translate_html(html_content, f"æ–‡ä»¶: {input_file}", force_translate)

        return saved_path

    except Exception as e:
        logging.getLogger(__name__).error(f"ç¿»è¯‘æ–‡ä»¶å¤±è´¥: {str(e)}")
        return None



# ä¸»å‡½æ•°å’Œæµ‹è¯•åŠŸèƒ½
async def test_translation():
    """æµ‹è¯•ç¿»è¯‘åŠŸèƒ½"""
    print("=== æµ‹è¯•HTMLç¿»è¯‘åŠŸèƒ½ ===")

    # ä½¿ç”¨å®é™…çš„HTMLæ–‡ä»¶è¿›è¡Œæµ‹è¯•
    html_file_path = "output/origin/tpus.html"

    try:
        # è¯»å–HTMLæ–‡ä»¶
        print(f"ğŸ“– æ­£åœ¨è¯»å–æ–‡ä»¶: {html_file_path}")
        with open(html_file_path, 'r', encoding='utf-8') as f:
            html_content = f.read()

        print(f"âœ… æ–‡ä»¶è¯»å–æˆåŠŸï¼Œé•¿åº¦: {len(html_content):,} å­—ç¬¦")

        # ç¿»è¯‘HTMLå†…å®¹
        print("ğŸ”„ å¼€å§‹ç¿»è¯‘HTMLå†…å®¹...")
        translator = HTMLTranslator()
        saved_path = await translator.translate_html(html_content, f"æ–‡ä»¶: {html_file_path}")

        if saved_path:
            print("âœ… ç¿»è¯‘æˆåŠŸ!")
            print(f"ğŸ’¾ ç¿»è¯‘æ–‡ä»¶å·²ä¿å­˜: {saved_path}")
        else:
            print("âŒ ç¿»è¯‘å¤±è´¥")

    except FileNotFoundError:
        print(f"âŒ æ–‡ä»¶ä¸å­˜åœ¨: {html_file_path}")
        print("è¯·ç¡®ä¿æ–‡ä»¶è·¯å¾„æ­£ç¡®")
    except Exception as e:
        print(f"âŒ æµ‹è¯•è¿‡ç¨‹å‡ºé”™: {str(e)}")


async def test_batch():
    """æ‰¹é‡ç¿»è¯‘output/originç›®å½•ä¸‹çš„æ‰€æœ‰HTMLæ–‡ä»¶"""
    print("=== æ‰¹é‡ç¿»è¯‘HTMLæ–‡ä»¶ ===")

    origin_dir = Path("output/origin")
    trans_dir = Path(TRANS_DIR)

    if not origin_dir.exists():
        print(f"âŒ æºç›®å½•ä¸å­˜åœ¨: {origin_dir}")
        return

    # è·å–æ‰€æœ‰HTMLæ–‡ä»¶
    html_files = list(origin_dir.glob("*.html"))

    if not html_files:
        print("âŒ æœªæ‰¾åˆ°HTMLæ–‡ä»¶")
        return

    print(f"ğŸ“ æ‰¾åˆ° {len(html_files)} ä¸ªHTMLæ–‡ä»¶")

    translator = HTMLTranslator()
    success_count = 0
    skip_count = 0
    error_count = 0

    for html_file in html_files:
        try:
            # æ£€æŸ¥ç›®æ ‡æ–‡ä»¶æ˜¯å¦å·²å­˜åœ¨
            target_file = trans_dir / html_file.name
            if target_file.exists():
                print(f"â­ï¸  è·³è¿‡å·²ç¿»è¯‘æ–‡ä»¶: {html_file.name}")
                skip_count += 1
                continue

            print(f"\nğŸ”„ å¼€å§‹ç¿»è¯‘: {html_file.name}")

            # è¯»å–HTMLæ–‡ä»¶
            with open(html_file, 'r', encoding='utf-8') as f:
                html_content = f.read()

            # ç¿»è¯‘HTMLå†…å®¹
            saved_path = await translator.translate_html(html_content, f"æ–‡ä»¶: {html_file}")

            if saved_path:
                print(f"âœ… ç¿»è¯‘æˆåŠŸ: {html_file.name}")
                success_count += 1
            else:
                print(f"âŒ ç¿»è¯‘å¤±è´¥: {html_file.name}")
                error_count += 1

        except Exception as e:
            print(f"âŒ å¤„ç†æ–‡ä»¶ {html_file.name} æ—¶å‡ºé”™: {str(e)}")
            error_count += 1

    # æ‰“å°ç»Ÿè®¡ç»“æœ
    print(f"\nğŸ“Š æ‰¹é‡ç¿»è¯‘å®Œæˆ:")
    print(f"   âœ… æˆåŠŸç¿»è¯‘: {success_count} ä¸ªæ–‡ä»¶")
    print(f"   â­ï¸  è·³è¿‡æ–‡ä»¶: {skip_count} ä¸ªæ–‡ä»¶")
    print(f"   âŒ ç¿»è¯‘å¤±è´¥: {error_count} ä¸ªæ–‡ä»¶")
    print(f"   ğŸ“ æ€»æ–‡ä»¶æ•°: {len(html_files)} ä¸ªæ–‡ä»¶")


async def main():
    """ä¸»æµ‹è¯•å‡½æ•°"""
    from config.logging_config import setup_logging
    import sys

    # è®¾ç½®æ—¥å¿—
    setup_logging('INFO')

    print("HTMLç¿»è¯‘å·¥å…·")
    print("=" * 50)

    await test_batch()
    # await test_translation()


    print("\nå®Œæˆ!")


if __name__ == "__main__":
    import asyncio
    asyncio.run(main())
